---
title: "Ecosystem Service Change & Hotspot Extraction"
subtitle: "v{{< meta analysis_version >}}"
author: "Jerónimo Rodríguez Escobar"
email: "jeronimo.rodriguez@wwfus.org"
date: last-modified
date-format: "YYYY-MM-DD HH:mm zzz"
analysis_version: "v0.5.0"
format:
  html:
    toc: true
    number-sections: true
    code-fold: false
    toc-title: "Contents"
    theme: cosmo
  pdf:
    toc: true
    number-sections: true
    geometry: margin=1in
    df-print: kable
editor: source

params:
  analysis_version: "v0.5.0"
---

## Overview

Prepares the processed 10 km grid, derives hotspot flags, and produces the bar/violin plots that summarize signed and absolute change by group (region, income, biome). Key steps: load helpers and paths, attach grouping attributes, pivot change fields to long form, define hotspots using the configured thresholds, export hotspot layers, and write the latest plots to `outputs/plots/latest/`.

## Setup and Libraries

Load all core packages (tidyverse, spatial, plotting helpers) and initialize reproducibility settings. This chunk also sources `R/paths.R` and runs `devtools::load_all()` so downstream chunks can reuse helper functions.

```{r}
#| label: setup
#| message: false
#| warning: false
#| echo: false

# Core tidy + spatial
library(dplyr)
library(tidyr)
library(purrr)
library(stringr)
library(forcats)
library(ggplot2)
library(scales)
library(sf)
library(terra)
library(exactextractr)
library(here)

# Plot helpers
library(viridisLite)
library(ggnewscale)
library(ragg)

# Dev/project helpers
library(devtools)   # for load_all()
# Paths helper (set GLOBAL_NCP_DATA in ~/.Renviron first)
knitr::opts_knit$set(root.dir = here::here())
source(here::here("R","paths.R"))
# Optional viewers (enable only if you use them)
# library(httpgd)
# library(leaflet)
# library(htmltools)

# ---- Global options / performance ---------------------------------------
options(dplyr.summarise.inform = FALSE)
sf::sf_use_s2(TRUE)
Sys.setenv(GDAL_NUM_THREADS = "ALL_CPUS", PROJ_NETWORK = "ON")
terraOptions(tempdir = file.path(tempdir(), "terra_tmp"))

set.seed(1)

# ---- Project wiring ------------------------------------------------------
# Load package-style functions from R/ (if this is a package-ish repo)
devtools::load_all(quiet = TRUE)



# ---- Python (enable when needed) ----------------------------------------
# library(reticulate)
# use_virtualenv("/home/jeronimo/venvs/coastal_snap_env", required = TRUE)

```

## Metadata Banner

Published: `r format(Sys.time(), "%Y-%m-%d %H:%M %Z")`

```{r}
#| label: run-metadata
#| echo: false
#| message: false
#| warning: false
#| results: 'asis'

# Prints version/time/git/data-root info so renders are traceable (no heavy compute).

analysis_version <- tryCatch(params$analysis_version, error = function(e) NULL)
if (is.null(analysis_version) || is.na(analysis_version)) {
  analysis_version <- Sys.getenv("ANALYSIS_VERSION", unset = "dev")
}

# Git info (robust to non-git folders)
git_branch <- tryCatch(
  system2("git", c("rev-parse", "--abbrev-ref", "HEAD"), stdout = TRUE),
  error = function(e) NA_character_
)
git_commit <- tryCatch(
  system2("git", c("rev-parse", "--short", "HEAD"), stdout = TRUE),
  error = function(e) NA_character_
)

# Data root from your paths helper, with fallbacks
data_root <- tryCatch(data_dir(), error = function(e) NULL)
if (is.null(data_root)) {
  data_root <- Sys.getenv("GLOBAL_NCP_DATA", unset = "")
}
message("data_dir(): ", data_dir())
message("Outputs root: ", out_plots())
cat(paste0(
  "::: callout-note\n",
  "**Run metadata**\n\n",
  "- Analysis version: ", analysis_version, "\n",
  "- Rendered: ", format(Sys.time(), "%Y-%m-%d %H:%M %Z"), "\n",
  "- Git: ", if (!is.na(git_branch)) git_branch else "NA", " @ ",
                 if (!is.na(git_commit)) git_commit else "NA", "\n",
  "- Data root: ", if (nzchar(data_root)) data_root else "unset", "\n",
  ":::"
))
```

```{r}
#| label: svc-order-global
#| include: false
#| echo: false
if (!exists("svc_order", inherits = TRUE)) {
  svc_order <- c(
    "C_Risk","N_export","Sed_export",
    "C_Risk_Red_Ratio","N_Ret_Ratio","Sed_Ret_Ratio",
    "Pollination","Nature_Access"
  )
}
```

```{r}
#| label: svc-canonical-global
#| include: false
#| echo: false
if (!exists("canonical_lookup", inherits = TRUE)) {
  canonical_lookup <- c(
    sed_export       = "Sed_export",
    n_export         = "N_export",
    n_retention      = "N_retention",
    nature_access    = "Nature_Access",
    pollination      = "Pollination",
    usle             = "USLE",
    n_ret_ratio      = "N_Ret_Ratio",
    sed_ret_ratio    = "Sed_Ret_Ratio",
    rt_ratio         = "C_Risk_Red_Ratio",
    rt               = "C_Risk",
    c_risk           = "C_Risk",
    c_risk_red_ratio = "C_Risk_Red_Ratio",
    rt_service       = "C_Prot_service",
    rt_nohab         = "Rt_nohab"
  )
}
```

## Add regional attributes to Grid (countries & biomes)

Attach country and biome IDs to the 10 km grid (`sf_f`) so downstream aggregation/hotspot steps can group by region. This chunk only runs if the processed GPKG is missing.

The input 10 km grid (`sf_f`) is enriched with country and WWF biome IDs to allow aggregation and comparisons of change by subregions (World Bank region, income group, continent, UN region, and biome). We use a point-on-surface join to avoid sliver/overlap issues, keep only the needed fields, and write a single enriched GPKG for downstream grouping, hotspot extraction, and plotting.

::: callout-tip
**What this step does**

-   Reads country and biome layers from `vectors/`.
-   Joins them to the 10 km grid via point-on-surface.
-   Writes `processed/10k_change_calc.gpkg` for downstream analysis (pivoting, hotspots, plots). **Inputs:** `sf_f` grid; `vectors/cartographic_ee_ee_r264_correspondence.gpkg`; `vectors/Biome.gpkg`\
    **Output:** `processed/10k_change_calc.gpkg` (grid + regional attributes)

**Why point-on-surface?** It’s robust for odd cell shapes and avoids polygon–polygon sliver issues.

<!-- NOTE (keep in source only): When to bump the version? If the joined attributes change schema/meaning (e.g., new grouping columns), bump MINOR; if file name/structure changes in a breaking way, bump MAJOR. -->
:::

```{r}
#| label: attach-region-attrs
#| eval: true
#| echo: false
# Purpose:
# Attach country & biome attributes to the 10 km grid (sf_f) so we can group by
# income_grp, region_wb, BIOME, etc. This writes a processed GPKG for downstream use.

# Preconditions:
# - sf_f (grid polygons) in memory with at least: fid, c_fid, geometry
# - paths.R available and data_dir() points to your data root (GLOBAL_NCP_DATA)

out_gpkg <- file.path(data_dir(), "processed", "10k_change_calc.gpkg")
if (!file.exists(out_gpkg)) {
  stopifnot(inherits(sf_f, "sf"))
  stopifnot(all(c("fid","c_fid") %in% names(sf_f)))

  # Inputs
  ct_path  <- file.path(data_dir(), "vectors", "cartographic_ee_ee_r264_correspondence.gpkg")
  bio_path <- file.path(data_dir(), "vectors", "Biome.gpkg")
  stopifnot(file.exists(ct_path), file.exists(bio_path))

  ct <- sf::st_read(ct_path, quiet = TRUE) |>
    dplyr::select(id, ee_r264_name, iso3, continent, income_grp, region_un, region_wb, subregion)

  biomes <- sf::st_read(bio_path, quiet = TRUE) |>
    dplyr::select(BIOME, WWF_biome)

  # CRS harmonization (note the != instead of ! ==)
  crs_grid <- sf::st_crs(sf_f)
  if (sf::st_crs(ct)     != crs_grid) ct     <- sf::st_transform(ct, crs_grid)
  if (sf::st_crs(biomes) != crs_grid) biomes <- sf::st_transform(biomes, crs_grid)

  # Lightweight template (keeps geometry)
  sf_template <- sf_f |>
    dplyr::select(fid, c_fid)

  # Representative point per cell; more robust than centroids
  pts <- sf::st_point_on_surface(sf_template)

  # Spatial joins
  pts_ct    <- sf::st_join(pts, ct,     left = TRUE)
  pts_biome <- sf::st_join(pts, biomes, left = TRUE)

  # Drop geometry and merge attrs by fid
  pts_ctdf <- sf::st_drop_geometry(pts_ct)
  pts_bmdf <- sf::st_drop_geometry(pts_biome)

  out_attrs <- pts_ctdf |>
    dplyr::left_join(pts_bmdf, by = "fid", suffix = c("", "_biome"))

  # Enforce uniqueness by fid (defensive)
  if (anyDuplicated(out_attrs$fid)) {
    out_attrs <- out_attrs |>
      dplyr::arrange(fid) |>
      dplyr::distinct(fid, .keep_all = TRUE)
  }

  # Bring attributes back to the grid
  sf_f_joined <- sf_f |>
    dplyr::left_join(out_attrs, by = "fid")

  stopifnot(nrow(sf_f_joined) == nrow(sf_f), inherits(sf_f_joined, "sf"))

  dir.create(dirname(out_gpkg), recursive = TRUE, showWarnings = FALSE)
  sf::st_write(sf_f_joined, out_gpkg, quiet = TRUE)
} else {
  message("Skipping join: ", out_gpkg, " already exists.")
}

# TODO (run later): quick QA tables
# dplyr::count(sf_f_joined, is.na(iso3))
# dplyr::count(sf_f_joined, is.na(BIOME))
# dplyr::count(sf_f_joined, income_grp, sort = TRUE)

```


## Produce signed bars (direct; no pivot)

Bars are computed directly from `processed/10k_change_calc.gpkg`; no pivot needed. We output two variants—zeros kept vs zeros dropped—both with trimmed tails and a dashed global mean. `plt_long` is only loaded later for hotspots/KS.

```{r}
#| label: make-signed-bars-direct
#| eval: true
#| message: false
#| warning: false

library(sf)
library(dplyr)
library(ggplot2)
library(stringr)

services <- svc_order
groupings <- c("income_grp","region_wb","continent","region_un","WWF_biome")
cut_q <- 0.999
handle_inf <- "na"  # options: "na", "cap"
verbose <- TRUE

vmsg <- function(...) if (isTRUE(verbose)) message(...)

gpkg <- file.path(Sys.getenv("GLOBAL_NCP_DATA"), "processed", "10k_change_calc.gpkg")
stopifnot(file.exists(gpkg))

vmsg("Reading: ", gpkg, " [layer: 10k_change_calc]")
sf_f <- sf::st_read(gpkg, layer = "10k_change_calc", quiet = TRUE)
sf_f <- sf::st_drop_geometry(sf_f)
if (!"fid" %in% names(sf_f)) sf_f$fid <- seq_len(nrow(sf_f))
if (!"c_fid" %in% names(sf_f)) {
  if ("c_fid.x" %in% names(sf_f)) sf_f <- dplyr::rename(sf_f, c_fid = c_fid.x)
  else if ("c_fid.y" %in% names(sf_f)) sf_f <- dplyr::rename(sf_f, c_fid = c_fid.y)
  else if ("id" %in% names(sf_f))      sf_f <- dplyr::rename(sf_f, c_fid = id)
}
sf_f <- dplyr::select(sf_f, -dplyr::any_of(c("c_fid.x","c_fid.y")))

# build mapping; include both raw base and no-_mean base, with ready-to-use columns
chg_cols <- grep("_(abs|pct)_chg$", names(sf_f), value = TRUE)
vmsg("Found ", length(chg_cols), " change columns; mapping services...")
services_raw   <- unique(sub("_(abs|pct)_chg$", "", chg_cols))     # as in file (may include _mean)
services_clean <- stringr::str_remove(services_raw, "_mean$")
services_lower <- tolower(services_clean)
svc_map <- tibble::tibble(
  col_base  = c(services_raw, services_clean),
  canonical = dplyr::recode(c(services_lower, services_lower),
                            !!!canonical_lookup, .default = c(services_clean, services_clean))
) |>
  dplyr::distinct() |>
  dplyr::mutate(col_pct = paste0(col_base, "_pct_chg"),
                col_abs = paste0(col_base, "_abs_chg"))

agg_by_group <- function(df, services, groupings, cut_q = 0.999,
                         handle_inf = c("na","cap"), drop_zero = FALSE) {
  handle_inf <- match.arg(handle_inf)
  groupings <- intersect(groupings, names(df))
  vmsg("Groupings available: ", paste(groupings, collapse = ", "))
  out <- list()
  for (g in groupings) {
    vmsg("  Grouping: ", g)
    for (svc in services) {
      map_rows <- dplyr::filter(svc_map, canonical == svc)
      if (!nrow(map_rows)) next
      cols_pct <- map_rows$col_pct[map_rows$col_pct %in% names(df)]
      cols_abs <- map_rows$col_abs[map_rows$col_abs %in% names(df)]
      if (!length(cols_pct) && !length(cols_abs)) next

      add_one <- function(col, metric) {
        v <- df[[col]]
        if (metric == "pct" && any(is.infinite(v))) {
          if (handle_inf == "na") v[is.infinite(v)] <- NA_real_
        }
        if (isTRUE(drop_zero)) v[v == 0] <- NA_real_
        cap <- stats::quantile(abs(v), cut_q, na.rm = TRUE)
        v_trim <- pmax(pmin(v, cap), -cap)
        tibble::tibble(
          service = svc,
          group   = df[[g]],
          metric  = metric,
          val     = v_trim
        )
      }

      rows <- list()
      if (length(cols_pct)) rows[[length(rows)+1]] <- add_one(cols_pct[1], "pct")
      if (length(cols_abs)) rows[[length(rows)+1]] <- add_one(cols_abs[1], "abs")
      rows <- dplyr::bind_rows(rows)
      if (!nrow(rows)) next
      rows <- rows |>
        dplyr::filter(!is.na(group)) |>
        dplyr::group_by(service, metric, group) |>
        dplyr::summarise(mean_chg = mean(val, na.rm = TRUE), .groups = "drop") |>
        dplyr::mutate(grouping = g)
      out[[length(out)+1]] <- rows
    }
  }
  dplyr::bind_rows(out)
}

signed_keep0 <- agg_by_group(sf_f, services, groupings, cut_q = cut_q,
                             handle_inf = handle_inf, drop_zero = FALSE)
signed_drop0 <- agg_by_group(sf_f, services, groupings, cut_q = cut_q,
                             handle_inf = handle_inf, drop_zero = TRUE)
print(dplyr::count(signed_keep0, grouping, metric, service))
print(dplyr::count(signed_drop0, grouping, metric, service))

compute_global_refs <- function(df, services, cut_q = 0.999,
                                handle_inf = c("na","cap"), drop_zero = FALSE) {
  handle_inf <- match.arg(handle_inf)
  out <- list()
  for (svc in services) {
    map_rows <- dplyr::filter(svc_map, canonical == svc)
    if (!nrow(map_rows)) next
    for (metric in c("pct","abs")) {
      cols <- if (metric == "pct") map_rows$col_pct else map_rows$col_abs
      cols <- cols[cols %in% names(df)]
      if (!length(cols)) next
      v <- df[[cols[1]]]
      if (metric == "pct" && any(is.infinite(v))) {
        if (handle_inf == "na") v[is.infinite(v)] <- NA_real_
      }
      if (isTRUE(drop_zero)) v[v == 0] <- NA_real_
      cap <- stats::quantile(abs(v), cut_q, na.rm = TRUE)
      v_trim <- pmax(pmin(v, cap), -cap)
      out[[length(out)+1]] <- tibble::tibble(
        service = svc,
        metric  = metric,
        ref     = mean(v_trim, na.rm = TRUE)
      )
    }
  }
  dplyr::bind_rows(out)
}

glob_keep0 <- compute_global_refs(sf_f, services, cut_q = cut_q,
                                  handle_inf = handle_inf, drop_zero = FALSE)
glob_drop0 <- compute_global_refs(sf_f, services, cut_q = cut_q,
                                  handle_inf = handle_inf, drop_zero = TRUE)

plot_signed_alt <- function(df, grouping, metric,
                            refs,
                            variant_label = "keep0",
                            variant_desc  = "Zeros kept",
                            out_dir = "outputs/plots/signed_alt") {
  d <- dplyr::filter(df, grouping == !!grouping, metric == !!metric)
  if (!nrow(d)) return(invisible(NULL))
  d$service <- factor(d$service, levels = services)
  d$group   <- factor(d$group, levels = sort(unique(d$group)))
  refs_use <- dplyr::filter(refs, metric == !!metric)
  refs_use$service <- factor(refs_use$service, levels = services)
  p <- ggplot(d, aes(group, mean_chg, fill = group)) +
    geom_col(show.legend = FALSE) +
    geom_hline(yintercept = 0, color = "#7f7f7f", linewidth = 0.6) +
    geom_hline(data = refs_use, aes(yintercept = ref),
               linetype = "dashed", color = "#4a4a4a", linewidth = 0.5) +
    facet_wrap(~ service, scales = "free_y", ncol = 3) +
    labs(title = paste0("Signed mean change (alt) — ", grouping, " [", metric, "]"),
         subtitle = variant_desc,
         x = grouping,
         y = if (metric == "pct") "Mean % change (trimmed, signed)" else "Mean absolute change (trimmed, signed)") +
    theme_minimal(base_size = 12) +
    theme(strip.background = element_rect(fill = "#f3f4f6", color = NA),
          strip.text = element_text(face = "bold"),
          axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))
  dir.create(out_dir, recursive = TRUE, showWarnings = FALSE)
  fp <- file.path(out_dir, paste0("bars_signed_alt_", variant_label, "_", tolower(grouping), "_", metric, ".png"))
  ggsave(fp, p, width = 12, height = 8, dpi = 300, bg = "white")
  message("Saved alt bars: ", fp)
}

# Write both variants without touching current outputs
for (g in unique(signed_keep0$grouping)) {
  for (m in unique(signed_keep0$metric)) {
    vmsg("Writing alt bars (keep zeros): ", g, " / ", m)
    plot_signed_alt(signed_keep0, g, m,
                    refs = glob_keep0,
                    variant_label = "keep0",
                    variant_desc  = "Zeros kept; dashed = global mean",
                    out_dir = "outputs/plots/signed_alt_keep0")
    vmsg("Writing alt bars (drop zeros): ", g, " / ", m)
    plot_signed_alt(signed_drop0, g, m,
                    refs = glob_drop0,
                    variant_label = "drop0",
                    variant_desc  = "Zeros dropped; dashed = global mean",
                    out_dir = "outputs/plots/signed_alt_drop0")
  }
}
```

## Reshape grid data to a service-long table

Pivot the processed grid into a tidy `plt_long` table (one row per cell × service) and standardize service labels/factor order. Cached so we only rebuild when inputs change.

Start by turning the wide grid table (one row per 10 km cell with many \*\_abs_chg / \*\_pct_chg columns) into an **analysis-ready long format**: one row per **cell × service** with two value columns: `abs_chg` and `pct_chg`. This makes it easy to rank, filter, and facet by service in later hotspot steps.

**What this chunk does** 1) Reads the processed grid from `processed/10k_change_calc.gpkg` and ensures a unique `fid`.\
2) Splits “ID/grouping” columns from change columns.\
3) Pivots \*\_abs_chg / \*\_pct_chg to long, then back to wide as `abs_chg` / `pct_chg` per service.\
4) Cleans obvious issues (drops `Inf`/`NA` where appropriate) so plots and tests won’t choke.\
5) Applies a human-readable service label mapping (e.g., `n_export → N_export`).\
6) Sets a canonical facet order (`svc_order`) so plots are consistent across the report.

**Inputs:** `processed/10k_change_calc.gpkg` (contains `fid`, `c_fid`, service change fields, and sub-regional tags like `region_wb`, `income_grp`, `BIOME`, etc.).\
**Output:** `plt_long` (tidy tibble) with columns\
`fid, c_fid, service, abs_chg, pct_chg, <grouping/socio vars>`.

::: callout-tip
**Why long format?**\
Ranking, percentile cuts, ECDFs, and faceted plots are all simpler and faster when each **service** is a row attribute rather than a separate column.
:::

```{r}
#| label: pivot
#| eval: false
#| include: false
#| echo: false
#| results: hide
#| cache: false
# ---- Produce plt_long once (skip if already present) ---------------- ----

if (!exists("plt_long", inherits = TRUE)) {

gpkg <- file.path(data_dir(), "processed", "10k_change_calc.gpkg")
stopifnot(file.exists(gpkg))

# Read the calc layer explicitly; normalize id columns
sf_f <- sf::st_read(gpkg, layer = "10k_change_calc", quiet = TRUE)
if (!"fid" %in% names(sf_f)) {
  sf_f$fid <- seq_len(nrow(sf_f))
}
if (!"c_fid" %in% names(sf_f)) {
  if ("c_fid.x" %in% names(sf_f)) sf_f <- dplyr::rename(sf_f, c_fid = c_fid.x)
  else if ("c_fid.y" %in% names(sf_f)) sf_f <- dplyr::rename(sf_f, c_fid = c_fid.y)
  else if ("id" %in% names(sf_f))       sf_f <- dplyr::rename(sf_f, c_fid = id)
}
if ("c_fid.x" %in% names(sf_f)) sf_f <- dplyr::select(sf_f, -c_fid.x)
if ("c_fid.y" %in% names(sf_f)) sf_f <- dplyr::select(sf_f, -c_fid.y)

# Ensure fid exists (idempotent)

## Load cached long table (plt_long)

Hotspot export still expects `plt_long`. To avoid the heavy pivot here, we load the cached table from `outputs/tables/plt_long.rds`. If it’s missing, run `scratch/pivot_long.qmd` (or `scratch/pivot_long.R`) to regenerate it.

```{r}
#| label: pivot
#| echo: false
#| message: false
#| warning: false
#| cache: false

if (!exists("plt_long", inherits = TRUE)) {
  rds_path <- here::here("outputs","tables","plt_long.rds")
  if (file.exists(rds_path)) {
    plt_long <- readRDS(rds_path)
    message("Loaded cached plt_long from ", rds_path)
  } else {
    stop("plt_long not found. Run scratch/pivot_long.qmd (or scratch/pivot_long.R) to build outputs/tables/plt_long.rds")
  }
}
```

## Load cached long table (plt_long) for hotspots/KS

Hotspot export and KS still expect `plt_long`. To avoid the heavy pivot here, we load the cached table from `outputs/tables/plt_long.rds`. If it’s missing, run `scratch/pivot_long.qmd` (or `scratch/pivot_long.R`) to regenerate it.

```{r}
#| label: pivot
#| echo: false
#| message: false
#| warning: false
#| cache: false

if (!exists("plt_long", inherits = TRUE)) {
  rds_path <- here::here("outputs","tables","plt_long.rds")
  if (file.exists(rds_path)) {
    plt_long <- readRDS(rds_path)
    message("Loaded cached plt_long from ", rds_path)
  } else {
    stop("plt_long not found. Run scratch/pivot_long.qmd (or scratch/pivot_long.R) to build outputs/tables/plt_long.rds")
  }
}
```

## Hotspot extraction workflow (global + subregional)

We identify per-service hotspots using a 5% percentile rule and **direction vectors**: - `loss_services` (e.g., Nature_Access, Pollination, N/Sed_Ret_Ratio, C_Risk_Red_Ratio) → we flag the **lowest** values; - `gain_services` (Sed_export, N_export, C_Risk) → we flag the **highest** values.

We run this **once globally** and then **once per subregion** (World Bank region, income group, continent, UN region, WWF biome). For each run and for each metric (absolute and percent change) we write a compact **GPKG** containing only the hotspot cells, plus a CSV index:

-   Output root: `processed/hotspots/`
    -   `abs/global/hotspots_global_abs.gpkg`
    -   `pct/global/hotspots_global_pct.gpkg`
    -   `abs/<group_col>/hotspots_<group_col>_<group_val>_abs.gpkg`
    -   `pct/<group_col>/hotspots_<group_col>_<group_val>_pct.gpkg`
-   Index: `processed/hotspots/_hotspots_index.csv` (columns: scope, group_col, group_val, metric, n_hot, gpkg).

These files are meant for QGIS/QA and downstream stats (e.g., KS) without recomputing hotspots.

### Hotspot rules & export configuration

The analysis uses a single, central configuration so the hotspot rules are consistent everywhere:

Thresholding: we flag hotspots using the top/bottom tails of the distribution per service. Here we use a percentile cutoff (e.g., 5%) rather than a fixed count.

Direction of concern: services in loss are “worse when they go down” (we keep the lowest tail); services in gain are “worse when they go up” (we keep the highest tail).

Combos (optional): grouped service sets that we count per cell for quick composite summaries.

Export switches: choose whether to write GPKGs and/or the CSV index.

```{r}
#| label: hotspots_config
#| include: true
#| eval: true
HOTS_CFG <- list(
  analysis_name   = "global_NCP_hotspots",
  pct_cutoff      = 0.05,
  threshold_mode  = "percent",
  rule_mode       = "vectors",
  loss = c("Nature_Access","Pollination","N_Ret_Ratio","Sed_Ret_Ratio","C_Risk_Red_Ratio"),
  gain = c("Sed_export","N_export","C_Risk"),
  combos = list(
    deg_combo = c("Nature_Access","Pollination","N_export","Sed_export","C_Risk"),
    rec_combo = c("Nature_Access","Pollination","N_Ret_Ratio","Sed_Ret_Ratio","C_Risk_Red_Ratio")
  ),
# centralize the grouping columns here
  groupings = c("income_grp","region_wb","continent","region_un","WWF_biome"),
  # IO
  write_layers = TRUE,
  write_index  = TRUE,
  out_dir      = file.path(data_dir(), "processed", "hotspots")
)
```

```{r}
#| label: show_hotspots_config
#| echo: false
loss_txt <- paste(HOTS_CFG$loss, collapse = ", ")
gain_txt <- paste(HOTS_CFG$gain, collapse = ", ")
grp_txt <- paste(HOTS_CFG$groupings, collapse = ", ")
combo_txt <- if (length(HOTS_CFG$combos))
  paste(paste0("**", names(HOTS_CFG$combos), "**: ",
               vapply(HOTS_CFG$combos, \(v) paste(v, collapse=", "), "")),
        collapse = "<br>") else "None"

cat(paste0(
"::: callout-note\n",
"**Hotspot configuration**\n\n",
"- Cutoff: ", HOTS_CFG$pct_cutoff * 100, "% (", HOTS_CFG$threshold_mode, ")\n",
"- Rule mode: ", HOTS_CFG$rule_mode, "\n",
"- Loss services: ", loss_txt, "\n",
"- Gain services: ", gain_txt, "\n",
"- Combos: ", combo_txt, "\n",
"…\n- Groupings: ", grp_txt, "\n…",
"- Write layers: ", HOTS_CFG$write_layers, " | Write index: ", HOTS_CFG$write_index, "\n",
"- Output dir: `", HOTS_CFG$out_dir, "`\n",
":::"
))
```

### Validate hotspot configuration

```{r}
#| label: validate_hotspots_config
#| message: false
#| warning: false
#| eval: false
# stopifnot(exists("plt_long"))
# svc_all <- unique(plt_long$service)
# if (length(intersect(HOTS_CFG$loss, HOTS_CFG$gain)) > 0) {
#   stop("A service appears in BOTH `loss` and `gain`. Fix HOTS_CFG.")
# }
# miss_loss <- setdiff(HOTS_CFG$loss, svc_all)
# miss_gain <- setdiff(HOTS_CFG$gain, svc_all)
# if (length(miss_loss) > 0 || length(miss_gain) > 0) {
#   warning("Services in HOTS_CFG not found in `plt_long$service`:\n",
#           if (length(miss_loss)) paste0("  - missing loss: ", paste(miss_loss, collapse=", "), "\n"),
#           if (length(miss_gain)) paste0("  - missing gain: ", paste(miss_gain, collapse=", "), "\n"))
# }
```

### Export hotspot layers

::: callout-note
**Hotspot export module**\
- Computes hotspot cells once (global + by subregion) for ABS and PCT change.\
- Writes compact GPKGs for mapping/QA and maintains `_hotspots_index.csv`.\
- Prereqs: `plt_long` in memory, `HOTS_CFG` defined (loss/gain/combos/etc.).
:::

```{r}
#| label: hotspots_export
#| message: false
#| warning: false
#| echo: false
#| include: false
#| cache: false
#| eval: false

stopifnot(exists("plt_long"))

# ---- Geometry: prefer an in-memory slim grid, else build it --------------
if (exists("grid_sf") && inherits(grid_sf, "sf")) {
  geom_sf <- dplyr::select(grid_sf, fid, c_fid)
} else {
  gpkg_grid <- file.path(data_dir(), "processed", "10k_change_calc.gpkg")
  stopifnot(file.exists(gpkg_grid))
  geom_sf <- sf::st_read(gpkg_grid, quiet = TRUE) |>
    dplyr::select(dplyr::any_of(c("fid","c_fid")), dplyr::everything())
  if (!"fid" %in% names(geom_sf)) {
    geom_sf$fid <- seq_len(nrow(geom_sf))
  }
  geom_sf <- dplyr::select(geom_sf, fid, c_fid)  # keep it slim
}
stopifnot("fid" %in% names(geom_sf), !any(duplicated(geom_sf$fid)))

# ---- Helper: safe slug for filenames -------------------------------------
slug <- function(x) {
  x <- gsub("[^A-Za-z0-9]+", "_", x)
  x <- gsub("_+", "_", x)
  sub("^_|_$", "", x)
}

# ---- Core runner (uses central HOTS_CFG) ----------------------------------
run_one_hotset <- function(df, value_col, scope,
                           group_col = NA_character_, group_val = NA_character_,
                           sf_obj = geom_sf,
                           cfg = HOTS_CFG) {
  # Optional subsetting by a specific group value
  if (!is.na(group_col) && !is.na(group_val)) {
    df <- df[df[[group_col]] %in% group_val, , drop = FALSE]
  }
  if (nrow(df) == 0L) {
    return(tibble::tibble(scope, group_col, group_val = as.character(group_val),
                          metric = if (identical(value_col, "abs_chg")) "abs" else "pct",
                          n_hot = 0L, gpkg = NA_character_))
  }

  # Safety: geometry must have all fids present in df
  stopifnot("fid" %in% names(df), "fid" %in% names(sf_obj))
  if (!all(df$fid %in% sf_obj$fid)) {
    missing <- setdiff(unique(df$fid), sf_obj$fid)
    stop(sprintf("Geometry is missing %d fid(s), e.g. %s",
                 length(missing), paste(head(missing, 5), collapse = ", ")))
  }

  # Single source of truth for rules/directions/combos
  hs <- extract_hotspots(
    df             = df,
    value_col      = value_col,
    pct_cutoff     = cfg$pct_cutoff,
    threshold_mode = cfg$threshold_mode,
    rule_mode      = cfg$rule_mode,
    loss_services  = cfg$loss,
    gain_services  = cfg$gain,
    combos         = cfg$combos,
    id_cols        = c("c_fid"),
    sf_obj         = sf_obj,
    write_sf_path  = NULL,
    clean_names    = TRUE
  )

  # Output layout
  out_root <- file.path(data_dir(), "processed", "hotspots")
  metric_stub <- if (identical(value_col, "abs_chg")) "abs" else "pct"
  folder <- if (is.na(group_col)) file.path(out_root, metric_stub, "global")
            else                   file.path(out_root, metric_stub, tolower(group_col))
  dir.create(folder, recursive = TRUE, showWarnings = FALSE)

  file_stub <- if (is.na(group_col)) {
    sprintf("hotspots_global_%s", metric_stub)
  } else {
    sprintf("hotspots_%s_%s_%s", tolower(group_col), slug(group_val), metric_stub)
  }
  out_gpkg <- file.path(folder, paste0(file_stub, ".gpkg"))

  # Write only hotspot features
  if (!is.null(hs$hotspots_sf) && nrow(hs$hotspots_sf) > 0) {
    sf::st_write(hs$hotspots_sf, out_gpkg, quiet = TRUE, delete_dsn = TRUE)
    n_hot <- nrow(hs$hotspots_sf)
  } else {
    out_gpkg <- NA_character__; n_hot <- 0L
  }

  tibble::tibble(
    scope      = scope,
    group_col  = ifelse(is.na(group_col), NA_character_, group_col),
    group_val  = ifelse(is.na(group_val), NA_character_, as.character(group_val)),
    metric     = metric_stub,
    n_hot      = n_hot,
    gpkg       = out_gpkg
  )
}

# ---- Execute: global + subregional runs -----------------------------------

# Pull groupings from config, with a safe fallback
groupings <- if (!is.null(HOTS_CFG$groupings)) {
  HOTS_CFG$groupings
} else {
  c("income_grp","region_wb","continent","region_un","WWF_biome")
}

# Run both metrics
metrics <- c("abs_chg","pct_chg")
index_rows <- lapply(metrics, function(m) run_one_hotset(plt_long, value_col = m, scope = "global"))

# Subregional runs
for (gc in groupings) {
  if (!gc %in% names(plt_long)) next
  vals_chr <- as.character(stats::na.omit(unique(plt_long[[gc]])))
  if (!length(vals_chr)) next

  for (m in metrics) {
    index_rows <- append(index_rows, list(
      purrr::map_dfr(vals_chr, \(v) run_one_hotset(
        df        = plt_long,
        value_col = m,
        scope     = "by_group",
        group_col = gc,
        group_val = v
      ))
    ))
  }
}

hot_index <- dplyr::bind_rows(index_rows)

# Ensure the output dir exists before writing the CSV index
csv_dir <- file.path(data_dir(), "processed", "hotspots")
dir.create(csv_dir, recursive = TRUE, showWarnings = FALSE)
readr::write_csv(hot_index, file.path(csv_dir, "_hotspots_index.csv"))

# Small console summary
dplyr::glimpse(hot_index, width = 120)

```

## Checkpoint recap

Wired the project with a metadata banner (version, git, data root) for reproducibility.

Enriched the 10 km grid with country/biome tags (documented chunk, eval: false) and standardized the working input at processed/10k_change_calc.gpkg.

Reshaped to analysis-ready long format (plt_long), cleaned basic issues, harmonized service labels, and set a canonical facet order.

Centralized hotspot rules in HOTS_CFG (loss/gain, combos, cutoff, groupings, IO).

Exported hotspots once (global + by subregion, for abs/pct change) to compact GPKGs under processed/hotspots/, and wrote a manifest: processed/hotspots/\_hotspots_index.csv.

Why this structure? Heavy work (ranking/thresholding/joining) is done once. The manifest gives us traceability and fast loading for downstream steps (bar plots, violins, KS tests) without re-computation.

## Trimmed change bar plots

::: callout-note
**How to read these bars**

-   Each bar shows the **trimmed mean absolute change** (\|Δ\|) per service within each group; facet axes are free.
-   Bars are **always positive** by design: height = **magnitude of change**, not direction.
-   Direction-of-concern used elsewhere in the analysis:
    -   Worse when **up** ➜ `Sed_export`, `N_export`, `C_Risk`.
    -   Worse when **down** ➜ `Nature_Access`, `Pollination`, `N_Ret_Ratio`, `Sed_Ret_Ratio`, `C_Risk_Red_Ratio`.
-   These bars answer **“where is change largest?”**. See hotspot maps/violins for **up vs. down** patterns.
:::

Short answer: your current barplots use all grid cells (the full 10-km population), not just hotspots. They summarize trimmed means per subregion/global from plt_long via aggregate_change_simple(), with cut_q=0.999 to cap outliers and (optionally) drop_zeros=TRUE. That’s why every bar is positive—those bars are the magnitude of change, not the direction.

Outputs: PNGs land in `outputs/plots/{abs|pct}/<group_col>/bars_*.png` plus a flat copy in `outputs/plots/latest/bars/` for embedding here. The legacy global-only single-bar chart was removed to keep the gallery focused on grouped views.

```{r}
#| label: bars_by_region
#| message: false
#| warning: false
#| echo: false
#| eval: false
#| cache: false

# --- knobs you can tweak quickly -----------------------------------------
group_col         <- "region_wb"   # e.g. "income_grp","continent","region_un","WWF_biome"
metric            <- "pct"         # "pct" or "abs"
cut_q             <- 0.999         # trim extreme 0.1% so bars aren't dominated by outliers
include_global    <- FALSE         # TRUE to add a "Global" bar into each facet
keep_only_ordered <- TRUE          # show only the 8 services in your svc_order
save_plot         <- TRUE
out_dir           <- file.path("outputs","plots")
out_stub          <- paste0("bars_", tolower(group_col), "_", metric)

# --- facet order (your canonical 8 first) ---------------------------------
svc_order <- c(
  "C_Risk","N_export","Sed_export",
  "C_Risk_Red_Ratio","N_Ret_Ratio","Sed_Ret_Ratio",
  "Pollination","Nature_Access"
)

# --- compute trimmed mean magnitude by region -----------------------------
stopifnot(group_col %in% names(plt_long))
gc <- group_col

df_trim <- plt_long |>
  dplyr::filter(!is.na(.data[[gc]])) |>
  dplyr::mutate(
    abs_cell = abs(.data$abs_chg),
    pct_cell = abs(.data$pct_chg)
  ) |>
  dplyr::group_by(.data$service) |>
  dplyr::mutate(
    abs_cap = stats::quantile(.data$abs_cell, cut_q, na.rm = TRUE),
    pct_cap = stats::quantile(.data$pct_cell, cut_q, na.rm = TRUE)
  ) |>
  dplyr::ungroup() |>
  dplyr::mutate(
    abs_trim = pmin(.data$abs_cell, .data$abs_cap),
    pct_trim = pmin(.data$pct_cell, .data$pct_cap)
  ) |>
  dplyr::group_by(.data$service, .data[[gc]]) |>
  dplyr::summarise(
    abs_mean = mean(.data$abs_trim, na.rm = TRUE),
    pct_mean = mean(.data$pct_trim, na.rm = TRUE),
    .groups = "drop"
  )

# optional: add a "Global" reference row per service
if (isTRUE(include_global)) {
  glob <- plt_long |>
    dplyr::mutate(
      abs_cell = abs(.data$abs_chg),
      pct_cell = abs(.data$pct_chg)
    ) |>
    dplyr::group_by(.data$service) |>
    dplyr::mutate(
      abs_cap = stats::quantile(.data$abs_cell, cut_q, na.rm = TRUE),
      pct_cap = stats::quantile(.data$pct_cell, cut_q, na.rm = TRUE)
    ) |>
    dplyr::ungroup() |>
    dplyr::mutate(
      abs_trim = pmin(.data$abs_cell, .data$abs_cap),
      pct_trim = pmin(.data$pct_cell, .data$pct_cap)
    ) |>
    dplyr::group_by(.data$service) |>
    dplyr::summarise(
      abs_mean = mean(.data$abs_trim, na.rm = TRUE),
      pct_mean = mean(.data$pct_trim, na.rm = TRUE),
      .groups = "drop"
    )
  glob[[gc]] <- factor("Global")
  df_trim <- dplyr::bind_rows(df_trim, glob)
}

# order facets and, by default, drop services not in svc_order
if (keep_only_ordered) df_trim <- dplyr::filter(df_trim, .data$service %in% svc_order)
extras <- setdiff(unique(df_trim$service), svc_order)
df_trim <- dplyr::mutate(df_trim,
  service = factor(.data$service, levels = c(svc_order, sort(extras)))
)

# x order: put "Global" first if present, else alphabetical by group
if (isTRUE(include_global)) {
  df_trim[[gc]] <- forcats::fct_relevel(as.factor(df_trim[[gc]]), "Global", after = 0)
} else {
  df_trim[[gc]] <- as.factor(df_trim[[gc]])
}

yvar <- if (identical(metric, "abs")) "abs_mean" else "pct_mean"

p_bars <- ggplot2::ggplot(df_trim, ggplot2::aes(x = .data[[gc]], y = .data[[yvar]])) +
  ggplot2::geom_col() +
  ggplot2::facet_wrap(~ service, ncol = 3, scales = "free_y", drop = FALSE) +
  ggplot2::labs(
    title = paste0("Magnitude of change by ", gc, " (", metric, ")"),
    x = NULL,
    y = if (identical(metric, "abs")) "Mean |Δ| (service units)" else "Mean |Δ| (%)"
  ) +
  ggplot2::theme_minimal(base_size = 11) +
  ggplot2::theme(
    axis.text.x = ggplot2::element_text(angle = 45, hjust = 1),
    panel.grid.major.x = ggplot2::element_blank()
  )

if (isTRUE(save_plot)) {
  # put plots in outputs/plots/<metric>/<group_col>/
  out_root <- out_plots()
  out_dir <- file.path(out_root, metric, tolower(group_col))
  dir.create(out_dir, recursive = TRUE, showWarnings = FALSE)

  # encode key params in the base name
  file_base <- paste(
    "bars",
    tolower(group_col),
    metric,
    paste0("cut", gsub("\\.", "", as.character(cut_q))),
    if (include_global) "with-global" else "no-global",
    sep = "_"
  )

  # avoid overwrite by adding _v02, _v03, …
  final_path <- file.path(out_dir, paste0(file_base, ".png"))
  i <- 2
  while (file.exists(final_path)) {
    final_path <- file.path(out_dir, sprintf("%s_v%02d.png", file_base, i))
    i <- i + 1
  }

  ggplot2::ggsave(
    filename = final_path,
    plot = p_bars,
    width = 12, height = 8, dpi = 300,
    device = ragg::agg_png,  # crisp text
    bg = "white"             # <- NO transparency
  )
  message("Saved plot to: ", normalizePath(final_path))
}

p_bars

```

Generate trimmed-mean bar plots (abs & pct) for each grouping. Plots save to `outputs/plots/...` and are embedded below.

```{r}
#| label: make-all-barplots-inputs
#| message: false
#| warning: false
#| echo: false
#| cache: false
#| results: "hold"
#| eval: false

# svc_order <- c(
#   "C_Risk","N_export","Sed_export",
#   "C_Risk_Red_Ratio","N_Ret_Ratio","Sed_Ret_Ratio",
#   "Pollination","Nature_Access"
# )
# groupings <- if (!is.null(HOTS_CFG$groupings)) HOTS_CFG$groupings else
#   c("income_grp","region_wb","continent","region_un","WWF_biome")
# missing_groupings <- setdiff(groupings, names(plt_long))
# if (length(missing_groupings)) {
#   warning("Grouping column(s) not found in plt_long and will be skipped: ",
#           paste(missing_groupings, collapse = ", "))
# }
# groupings <- intersect(groupings, names(plt_long))
# message("make-all-barplots groupings: ", if (length(groupings)) paste(groupings, collapse = ", ") else "none")
# metrics <- c("pct","abs")                # will map to pct_mean / abs_mean below
# cut_q   <- 0.999
# keep_only_ordered <- TRUE
```

```{r}
#| label: make-all-barplots-helper
#| message: false
#| warning: false
#| echo: false
#| cache: false
#| results: "hold"

plot_change_bars <- function(df, group_col, metric = c("pct","abs"),
                             include_global = FALSE,
                             out_dir = NULL, out_stub = NULL,
                             global_outline = "black",   # <-- outline color for Global
                             global_fill    = NULL) {    # <-- set e.g. "#444444" if you also want a different fill

  metric <- match.arg(metric)
  ycol   <- rlang::sym(if (metric == "pct") "pct_mean" else "abs_mean")

  regs <- agg_change(
    plt_long        = df,
    group_col       = group_col,
    cut_q           = 0.999,
    drop_zeros      = TRUE,
    svc_order       = svc_order,
    svc_order_only  = keep_only_ordered,
    include_global  = include_global
  )

  # sanity guards: need data and the target column
  if (!nrow(regs)) {
    message("No data returned for ", group_col, " (", metric, "); skipping.")
    return(invisible(NULL))
  }
  if (!rlang::as_string(ycol) %in% names(regs)) {
    message("Missing column ", rlang::as_string(ycol), " in agg_change output for ", group_col, "; skipping.")
    return(invisible(NULL))
  }

  # Clean + facet order
  regs <- regs |>
    dplyr::filter(!is.na(service)) |>
    dplyr::mutate(service = forcats::fct_relevel(as.character(service), !!!svc_order, after = Inf))

  # Make grouping factor & push "Global" to the rightmost position
  gsym <- rlang::sym(group_col)
  regs <- regs |>
    dplyr::mutate(
      grp_chr   = as.character(!!gsym),
      is_global = grp_chr == "Global"
    )

  lvl <- sort(unique(regs$grp_chr))
  if ("Global" %in% lvl) lvl <- c(setdiff(lvl, "Global"), "Global")  # shove to end
  regs <- regs |> dplyr::mutate(.grp = factor(grp_chr, levels = lvl))

  p <- ggplot2::ggplot(regs, ggplot2::aes(x = .grp, y = !!ycol)) +
    ggplot2::geom_col() +
    # Overlay the Global bar so it has a subtle outline (and optional fill)
    {
      gdat <- dplyr::filter(regs, is_global)
      if (nrow(gdat)) {
        if (is.null(global_fill)) {
          ggplot2::geom_col(
            data = gdat, fill = NA, color = global_outline, linewidth = 0.8
          )
        } else {
          ggplot2::geom_col(
            data = gdat, fill = global_fill, color = global_outline, linewidth = 0.8
          )
        }
      } else NULL
    } +
    ggplot2::facet_wrap(
      ~ service, ncol = 3, nrow = 3, scales = "free_y", drop = TRUE
    ) +
    ggplot2::labs(
      x = group_col,
      y = if (metric == "pct") "Mean |Δ| (%), trimmed" else "Mean |Δ| (units), trimmed",
      title = paste0("Aggregate change by ", group_col,
                     if (include_global) " (with Global reference)" else "")
    ) +
    ggplot2::theme_minimal(base_size = 12) +
    ggplot2::theme(
      plot.background   = ggplot2::element_rect(fill = "white", color = NA),
      panel.background  = ggplot2::element_rect(fill = "white", color = NA),
      strip.background  = ggplot2::element_rect(fill = "#f3f4f6", color = NA),
      strip.text        = ggplot2::element_text(face = "bold"),
      axis.text.x       = ggplot2::element_text(angle = 45, hjust = 1, vjust = 1),
      panel.grid.minor  = ggplot2::element_blank()
    )

  # Save
  if (is.null(out_dir)) out_dir <- out_plots()
  dir.create(file.path(out_dir, metric, group_col), recursive = TRUE, showWarnings = FALSE)
  if (is.null(out_stub)) {
    out_stub <- paste0("bars_", tolower(group_col), "_", metric,
                       if (include_global) "_wglobal" else "")
  }
  final_path <- file.path(out_dir, metric, group_col, paste0(out_stub, ".png"))
  tryCatch({
    ragg::agg_png(final_path, width = 12, height = 8, units = "in", res = 300, background = "white")
    print(p)
    grDevices::dev.off()
    message("Saved: ", normalizePath(final_path))
  }, error = function(e) {
    message("ERROR while saving ", final_path, ": ", e$message)
    if (grDevices::dev.cur() > 1) grDevices::dev.off()
  })
}

# Signed bar view with global reference as dotted line (no Global bar)
plot_signed_bars <- function(df, group_col, metric = c("pct","abs"),
                             include_global = TRUE,
                             cut_q = 0.999,
                             svc_order = NULL,
                             out_dir = NULL,
                             out_stub = NULL) {
  metric <- match.arg(metric)
  ycol <- if (metric == "pct") "pct_signed" else "abs_signed"
  vcol <- if (metric == "pct") "pct_chg" else "abs_chg"

  stopifnot(group_col %in% names(df))
  gsym <- rlang::sym(group_col)

  df_trim <- df |>
    dplyr::filter(!is.na(.data[[group_col]])) |>
    dplyr::group_by(.data$service) |>
    dplyr::mutate(
      cap      = stats::quantile(abs(.data[[vcol]]), cut_q, na.rm = TRUE),
      val_trim = pmax(pmin(.data[[vcol]], cap), -cap)
    ) |>
    dplyr::ungroup() |>
    dplyr::group_by(.data$service, .data[[group_col]]) |>
    dplyr::summarise(
      !!ycol := mean(.data$val_trim, na.rm = TRUE),
      .groups = "drop"
    )
  # Drop any pre-existing "Global" rows; we show it via line only
  df_trim <- df_trim |> dplyr::filter(.data[[group_col]] != "Global")

  glob_ref <- NULL
  if (isTRUE(include_global)) {
    glob_ref <- df |>
      dplyr::group_by(.data$service) |>
      dplyr::mutate(
        cap      = stats::quantile(abs(.data[[vcol]]), cut_q, na.rm = TRUE),
        val_trim = pmax(pmin(.data[[vcol]], cap), -cap)
      ) |>
      dplyr::ungroup() |>
      dplyr::group_by(.data$service) |>
      dplyr::summarise(ref = mean(.data$val_trim, na.rm = TRUE), .groups = "drop")
  }

  if (!is.null(svc_order)) {
    df_trim <- df_trim |>
      dplyr::filter(.data$service %in% svc_order) |>
      dplyr::mutate(service = factor(.data$service, levels = svc_order))
    if (!is.null(glob_ref)) {
      glob_ref <- glob_ref |>
        dplyr::filter(.data$service %in% svc_order) |>
        dplyr::mutate(service = factor(.data$service, levels = svc_order))
    }
  }

  lvl <- sort(unique(df_trim[[group_col]]))
  df_trim[[group_col]] <- factor(df_trim[[group_col]], levels = lvl)

  p <- ggplot2::ggplot(df_trim, ggplot2::aes(x = !!gsym, y = !!rlang::sym(ycol), fill = !!gsym)) +
    ggplot2::geom_col(show.legend = FALSE) +
    ggplot2::geom_hline(yintercept = 0, color = "#d9d9d9") +
    {
      if (!is.null(glob_ref) && nrow(glob_ref)) {
        ggplot2::geom_hline(data = glob_ref, ggplot2::aes(yintercept = ref),
                            linetype = "dashed", color = "black", linewidth = 0.8)
      } else NULL
    } +
    ggplot2::facet_wrap(~ service, ncol = 3, scales = "free_y", drop = TRUE) +
    ggplot2::labs(
      x = group_col,
      y = if (metric == "pct") "Mean % change (trimmed, signed)" else "Mean absolute change (trimmed, signed)",
      title = paste0("Signed mean change by ", group_col,
                     if (include_global) " (global dotted reference)" else "")
    ) +
    ggplot2::theme_minimal(base_size = 12) +
    ggplot2::theme(
      strip.background = ggplot2::element_rect(fill = "#f3f4f6", color = NA),
      strip.text = ggplot2::element_text(face = "bold"),
      axis.text.x = ggplot2::element_text(angle = 45, hjust = 1, vjust = 1)
    )

  if (is.null(out_dir)) out_dir <- out_plots()
  grp_dir <- tolower(group_col)
  dir.create(file.path(out_dir, paste0("signed_", metric), grp_dir), recursive = TRUE, showWarnings = FALSE)
  if (is.null(out_stub)) {
    out_stub <- paste0("bars_signedline_", tolower(group_col), "_", metric)
  }
  final_path <- file.path(out_dir, paste0("signed_", metric), grp_dir, paste0(out_stub, ".png"))
  tryCatch({
    ggplot2::ggsave(final_path, p, width = 12, height = 8, dpi = 300, bg = "white")
    message("Saved signed bars: ", normalizePath(final_path))
  }, error = function(e) {
    message("ERROR while saving signed bars ", final_path, ": ", e$message)
  })
}
```

```{r}
#| label: make-all-barplots-run
#| message: false
#| warning: false
#| echo: false
#| cache: false
#| eval: false
#| results: "hold"

if (length(groupings) == 0) {
  warning("No grouping columns found in plt_long; skipping bar plots.")
} else {
  for (gc in groupings) {
    for (m in metrics) {
      plot_change_bars(plt_long, group_col = gc, metric = m,
                       include_global = FALSE)
      plot_change_bars(plt_long, group_col = gc, metric = m,
                       include_global = TRUE)
      plot_signed_bars(plt_long, group_col = gc, metric = m,
                       include_global = TRUE, cut_q = cut_q,
                       svc_order = svc_order)
    }
  }
}

latest_dir_bars <- file.path("outputs","plots","latest","bars")
dir.create(latest_dir_bars, recursive = TRUE, showWarnings = FALSE)
old_latest_bars <- list.files(latest_dir_bars, full.names = TRUE, all.files = FALSE)
if (length(old_latest_bars)) invisible(file.remove(old_latest_bars))
# Clean up legacy global-only bar charts so they don't get recopied
stale_global_bars <- list.files(out_plots(), pattern = "bars_global_.*\\.png$",
                                recursive = TRUE, full.names = TRUE)
if (length(stale_global_bars)) file.remove(stale_global_bars)

all_new_bars <- list.files(out_plots(), pattern = "bars_.*\\.png$",
                           recursive = TRUE, full.names = TRUE)
all_new_bars <- all_new_bars[!grepl("/latest/", all_new_bars)]
all_new_bars <- all_new_bars[!grepl("/global/", all_new_bars)]
all_new_bars <- all_new_bars[!grepl("bars_global_", basename(all_new_bars))]
good_bars <- all_new_bars[file.info(all_new_bars)$size > 0]
if (length(good_bars)) {
  invisible(file.copy(good_bars, latest_dir_bars, overwrite = TRUE))
}
```

```{r}
#| label: display-barplots
#| echo: false
#| results: 'asis'
#| cache: false
bar_dir  <- file.path("outputs","plots","latest","bars")
pngs <- list.files(bar_dir, pattern = "^bars_signed_alt_.*\\.png$", full.names = FALSE)

if (length(pngs)) {
  # Show keep0 first, then drop0
  pngs <- pngs[order(grepl("drop0", pngs))]
  rel_paths <- file.path("..", bar_dir, pngs)
  md <- c(
    "### Signed means (alt variants: keep0 vs drop0; dashed = global mean)",
    paste(sprintf("![](%s)", rel_paths), collapse = "\n\n")
  )
  knitr::asis_output(paste(md, collapse = "\n\n"))
} else {
  knitr::asis_output("> No signed bar plots were generated; check upstream chunks.")
}
```

## Hotspot violin plots

Summarize hotspot distributions by group using saved PNGs; skip computation if group columns are absent. Helper `run_hotspot_violins_by()` now lives in `R/hotspot_violins.R`, so we just call it from this report.

Outputs: PNGs are written to `outputs/plots/{abs|pct}/<group_col>/violins_*.png` and mirrored into `outputs/plots/latest/violins/` for embedding.

```{r}
#| label: make-hotspot-violins
#| message: false
#| warning: false
#| echo: false
#| cache: false
#| results: "hold"
#| eval: false

# stopifnot(exists("plt_long"))
# groupings <- if (!is.null(HOTS_CFG$groupings) && length(HOTS_CFG$groupings) > 0) {
#   HOTS_CFG$groupings
# } else {
#   c("income_grp","region_wb","continent","region_un","WWF_biome")
# }
# missing_groupings <- setdiff(groupings, names(plt_long))
# if (length(missing_groupings)) {
#   warning("Grouping column(s) not found in plt_long and will be skipped: ",
#           paste(missing_groupings, collapse = ", "))
# }
# groupings <- intersect(groupings, names(plt_long))
# message("make-hotspot-violins groupings: ", if (length(groupings)) paste(groupings, collapse = ", ") else "none")
# violin_order <- levels(plt_long$service)
# if (is.null(violin_order)) {
#   violin_order <- unique(plt_long$service)
# }
# violin_order <- as.character(violin_order)
# if (length(groupings) == 0) {
#   warning("No grouping columns found in plt_long; skipping hotspot violins.")
# } else {
#   for (gc in groupings) {
#     message("Rendering hotspot violins for: ", gc)
#     run_hotspot_violins_by(
#       df_long          = plt_long,
#       group_col         = gc,
#       loss              = HOTS_CFG$loss,
#       gain              = HOTS_CFG$gain,
#       pct_cutoff        = HOTS_CFG$pct_cutoff,
#       threshold_mode    = HOTS_CFG$threshold_mode,
#       svc_order         = violin_order,
#       cut_q             = 0.999,
#       keep_only_ordered = TRUE
#     )
#   }
# }
# latest_dir_violins <- file.path("outputs","plots","latest","violins")
# dir.create(latest_dir_violins, recursive = TRUE, showWarnings = FALSE)
# old_latest_violins <- list.files(latest_dir_violins, full.names = TRUE, all.files = FALSE)
# if (length(old_latest_violins)) invisible(file.remove(old_latest_violins))
# all_new_violins <- list.files(out_plots(), pattern = "violins_.*\\.png$",
#                               recursive = TRUE, full.names = TRUE)
# all_new_violins <- all_new_violins[!grepl("/latest/", all_new_violins)]
# good_violins <- all_new_violins[file.info(all_new_violins)$size > 0]
# if (length(good_violins)) {
#   invisible(file.copy(good_violins, latest_dir_violins, overwrite = TRUE))
# }

```

```{r}
#| label: display-violins
#| echo: false
#| results: 'asis'
#| cache: false
vio_dir   <- file.path("outputs","plots","latest","violins")
vio_files <- list.files(vio_dir, pattern = "violins_.*\\.png$", full.names = FALSE)
if (length(vio_files)) {
  rel_paths <- file.path("..", vio_dir, sort(vio_files))
  md <- paste(sprintf("![](%s)", rel_paths), collapse = "\n\n")
  knitr::asis_output(md)
} else {
  knitr::asis_output("> No violin plots were generated; check upstream chunks.")
}
```
