---
title: "Hotspot Extraction"
subtitle: "v{{< meta analysis_version >}}"
author: "Jerónimo Rodríguez Escobar"
email: "jeronimo.rodriguez@wwfus.org"
date: today
date-format: iso
analysis_version: "v0.4.1"
format:
  html:
    toc: true
    number-sections: true
    code-fold: false
    toc-title: "Contents"
    theme: cosmo
editor: source

params:
  analysis_version: "v0.4.1"
---

## Setup and Libraries

Load all core packages (tidyverse, spatial, plotting helpers) and initialize reproducibility settings. This chunk also sources `R/paths.R` and runs `devtools::load_all()` so downstream chunks can reuse helper functions.

```{r}
#| label: setup
#| message: false
#| warning: false
#| echo: false

# Core tidy + spatial
library(dplyr)
library(tidyr)
library(purrr)
library(stringr)
library(forcats)
library(ggplot2)
library(scales)
library(sf)
library(terra)
library(exactextractr)
library(here)

# Plot helpers
library(viridisLite)
library(ggnewscale)
library(ragg)

# Dev/project helpers
library(devtools)   # for load_all()
# Paths helper (set GLOBAL_NCP_DATA in ~/.Renviron first)
knitr::opts_knit$set(root.dir = here::here())
source(here::here("R","paths.R"))
# Optional viewers (enable only if you use them)
# library(httpgd)
# library(leaflet)
# library(htmltools)

# ---- Global options / performance ---------------------------------------
options(dplyr.summarise.inform = FALSE)
sf::sf_use_s2(TRUE)
Sys.setenv(GDAL_NUM_THREADS = "ALL_CPUS", PROJ_NETWORK = "ON")
terraOptions(tempdir = file.path(tempdir(), "terra_tmp"))

set.seed(1)

# ---- Project wiring ------------------------------------------------------
# Load package-style functions from R/ (if this is a package-ish repo)
devtools::load_all(quiet = TRUE)



# ---- Python (enable when needed) ----------------------------------------
# library(reticulate)
# use_virtualenv("/home/jeronimo/venvs/coastal_snap_env", required = TRUE)

```

## Run Metadata Banner

Print run metadata (analysis version, timestamp, git commit, data root) so exported reports remain traceable.

Published: `r format(Sys.time(), "%Y-%m-%d %H:%M %Z")`

```{r}
#| label: run-metadata
#| echo: false
#| message: false
#| warning: false
#| results: 'asis'

# Prints version/time/git/data-root info so renders are traceable (no heavy compute).

analysis_version <- tryCatch(params$analysis_version, error = function(e) NULL)
if (is.null(analysis_version) || is.na(analysis_version)) {
  analysis_version <- Sys.getenv("ANALYSIS_VERSION", unset = "dev")
}

# Git info (robust to non-git folders)
git_branch <- tryCatch(
  system2("git", c("rev-parse", "--abbrev-ref", "HEAD"), stdout = TRUE),
  error = function(e) NA_character_
)
git_commit <- tryCatch(
  system2("git", c("rev-parse", "--short", "HEAD"), stdout = TRUE),
  error = function(e) NA_character_
)

# Data root from your paths helper, with fallbacks
data_root <- tryCatch(data_dir(), error = function(e) NULL)
if (is.null(data_root)) {
  data_root <- Sys.getenv("GLOBAL_NCP_DATA", unset = "")
}
message("data_dir(): ", data_dir())
message("Outputs root: ", out_plots())
cat(paste0(
  "::: callout-note\n",
  "**Run metadata**\n\n",
  "- Analysis version: ", analysis_version, "\n",
  "- Rendered: ", format(Sys.time(), "%Y-%m-%d %H:%M %Z"), "\n",
  "- Git: ", if (!is.na(git_branch)) git_branch else "NA", " @ ",
                 if (!is.na(git_commit)) git_commit else "NA", "\n",
  "- Data root: ", if (nzchar(data_root)) data_root else "unset", "\n",
  ":::"
))
```

## Add regional attributes to Grid (countries & biomes)

Attach country and biome IDs to the 10 km grid (`sf_f`) so downstream aggregation/hotspot steps can group by region. This chunk only runs if the processed GPKG is missing.

We enrich the 10 km grid (`sf_f`) with country and WWF biome IDs so we can aggregate and compare change by subregions (World Bank region, income group, continent, UN region, and biome). We use a point-on-surface join to avoid sliver/overlap issues, keep only the needed fields, and write a single enriched GPKG for downstream grouping, hotspot extraction, and plotting.

::: callout-tip
**What this step does**

-   Reads country and biome layers from `vectors/`.
-   Joins them to the 10 km grid via point-on-surface.
-   Writes `processed/10k_change_calc.gpkg` for downstream analysis (pivoting, hotspots, plots). **Inputs:** `sf_f` grid; `vectors/cartographic_ee_ee_r264_correspondence.gpkg`; `vectors/Biome.gpkg`\
    **Output:** `processed/10k_change_calc.gpkg` (grid + regional attributes)

**Why point-on-surface?** It’s robust for odd cell shapes and avoids polygon–polygon sliver issues.

**When to bump the version?** If the joined attributes change schema/meaning (e.g., new grouping columns), bump **MINOR**; if file name/structure changes in a breaking way, bump **MAJOR**.
:::

```{r}
#| label: attach-region-attrs
#| eval: false
#| echo: false
# Purpose:
# Attach country & biome attributes to the 10 km grid (sf_f) so we can group by
# income_grp, region_wb, BIOME, etc. This writes a processed GPKG for downstream use.

# Preconditions:
# - sf_f (grid polygons) in memory with at least: fid, c_fid, geometry
# - paths.R available and data_dir() points to your data root (GLOBAL_NCP_DATA)

out_gpkg <- file.path(data_dir(), "processed", "10k_change_calc.gpkg")
if (!file.exists(out_gpkg)) {
  stopifnot(inherits(sf_f, "sf"))
  stopifnot(all(c("fid","c_fid") %in% names(sf_f)))

  # Inputs
  ct_path  <- file.path(data_dir(), "vectors", "cartographic_ee_ee_r264_correspondence.gpkg")
  bio_path <- file.path(data_dir(), "vectors", "Biome.gpkg")
  stopifnot(file.exists(ct_path), file.exists(bio_path))

  ct <- sf::st_read(ct_path, quiet = TRUE) |>
    dplyr::select(id, ee_r264_name, iso3, continent, income_grp, region_un, region_wb, subregion)

  biomes <- sf::st_read(bio_path, quiet = TRUE) |>
    dplyr::select(BIOME, WWF_biome)

  # CRS harmonization (note the != instead of ! ==)
  crs_grid <- sf::st_crs(sf_f)
  if (sf::st_crs(ct)     != crs_grid) ct     <- sf::st_transform(ct, crs_grid)
  if (sf::st_crs(biomes) != crs_grid) biomes <- sf::st_transform(biomes, crs_grid)

  # Lightweight template (keeps geometry)
  sf_template <- sf_f |>
    dplyr::select(fid, c_fid)

  # Representative point per cell; more robust than centroids
  pts <- sf::st_point_on_surface(sf_template)

  # Spatial joins
  pts_ct    <- sf::st_join(pts, ct,     left = TRUE)
  pts_biome <- sf::st_join(pts, biomes, left = TRUE)

  # Drop geometry and merge attrs by fid
  pts_ctdf <- sf::st_drop_geometry(pts_ct)
  pts_bmdf <- sf::st_drop_geometry(pts_biome)

  out_attrs <- pts_ctdf |>
    dplyr::left_join(pts_bmdf, by = "fid", suffix = c("", "_biome"))

  # Enforce uniqueness by fid (defensive)
  if (anyDuplicated(out_attrs$fid)) {
    out_attrs <- out_attrs |>
      dplyr::arrange(fid) |>
      dplyr::distinct(fid, .keep_all = TRUE)
  }

  # Bring attributes back to the grid
  sf_f_joined <- sf_f |>
    dplyr::left_join(out_attrs, by = "fid")

  stopifnot(nrow(sf_f_joined) == nrow(sf_f), inherits(sf_f_joined, "sf"))

  dir.create(dirname(out_gpkg), recursive = TRUE, showWarnings = FALSE)
  sf::st_write(sf_f_joined, out_gpkg, quiet = TRUE)
} else {
  message("Skipping join: ", out_gpkg, " already exists.")
}

# TODO (run later): quick QA tables
# dplyr::count(sf_f_joined, is.na(iso3))
# dplyr::count(sf_f_joined, is.na(BIOME))
# dplyr::count(sf_f_joined, income_grp, sort = TRUE)

```

## Reshape grid data to a service-long table

Pivot the processed grid into a tidy `plt_long` table (one row per cell × service) and standardize service labels/factor order. Cached so we only rebuild when inputs change.

Start by turning the wide grid table (one row per 10 km cell with many \*\_abs_chg / \*\_pct_chg columns) into an **analysis-ready long format**: one row per **cell × service** with two value columns: `abs_chg` and `pct_chg`. This makes it easy to rank, filter, and facet by service in later hotspot steps.

**What this chunk does** 1) Reads the processed grid from `processed/10k_change_calc.gpkg` and ensures a unique `fid`.\
2) Splits “ID/grouping” columns from change columns.\
3) Pivots \*\_abs_chg / \*\_pct_chg to long, then back to wide as `abs_chg` / `pct_chg` per service.\
4) Cleans obvious issues (drops `Inf`/`NA` where appropriate) so plots and tests won’t choke.\
5) Applies a human-readable service label mapping (e.g., `n_export → N_export`).\
6) Sets a canonical facet order (`svc_order`) so plots are consistent across the report.

**Inputs:** `processed/10k_change_calc.gpkg` (contains `fid`, `c_fid`, service change fields, and sub-regional tags like `region_wb`, `income_grp`, `BIOME`, etc.).\
**Output:** `plt_long` (tidy tibble) with columns\
`fid, c_fid, service, abs_chg, pct_chg, <grouping/socio vars>`.

::: callout-tip
**Why long format?**\
Ranking, percentile cuts, ECDFs, and faceted plots are all simpler and faster when each **service** is a row attribute rather than a separate column.
:::

```{r}
#| label: pivot
#| eval: true
#| include: false
#| echo: false
#| results: hide
#| cache: true
# ---- Produce plt_long once (skip if already present) ---------------- ----

if (!exists("plt_long", inherits = TRUE)) {

gpkg <- file.path(data_dir(), "processed", "10k_change_calc.gpkg")
stopifnot(file.exists(gpkg))

sf_f <- sf::st_read(gpkg, quiet = TRUE)

# Ensure fid exists (idempotent)

if (!"fid" %in% names(sf_f)) {
sf_f$fid <- seq_len(nrow(sf_f))
}

plt <- sf::st_drop_geometry(sf_f)

# IDs + change columns

id_cols  <- c("fid", "c_fid")
chg_cols <- grep("_(abs|pct)_chg$", names(plt), value = TRUE)

# Socio/grouping columns = everything else

socio_vars <- setdiff(names(plt), c(id_cols, chg_cols))

# Long -> Wide (abs_chg / pct_chg)

plt_long <- plt |>
tidyr::pivot_longer(
cols = tidyselect::all_of(chg_cols),
names_to = c("service", "chg_type"),
names_pattern = "^(.*)_(abs|pct)_chg$",
values_to = "chg_value"
) |>
dplyr::mutate(service = stringr::str_remove(service, "_mean$")) |>
tidyr::pivot_wider(
names_from  = chg_type,
values_from = chg_value,
names_vary  = "slowest"
) |> # clean column names
dplyr::rename(abs_chg = abs, pct_chg = pct) |>
dplyr::select(fid, c_fid, service, abs_chg, pct_chg, dplyr::any_of(socio_vars)) |>
dplyr::filter(!is.na(c_fid)) |> # remove cells outside any country.
dplyr::filter(!(is.infinite(abs_chg) | is.infinite(pct_chg))) |>
dplyr::filter(!is.na(abs_chg) | !is.na(pct_chg))


# TODO: externalize label mapping (and loss/gain tags) to a config:
# analysis_configs/service_meta.csv with columns:
# raw,label,direction,pref_metric
# Load once and join, so we don’t hard-code names here.
service_lookup <- c(
sed_export     = "Sed_export",
n_export       = "N_export",
n_retention    = "N_retention",
nature_access  = "Nature_Access",
pollination    = "Pollination",
usle           = "USLE",
n_ret_ratio    = "N_Ret_Ratio",
sed_ret_ratio  = "Sed_Ret_Ratio",
Rt_ratio       = "C_Risk_Red_Ratio",
Rt             = "C_Risk",
Rt_service     = "C_Prot_service",
Rt_nohab       = "Rt_nohab"
)
plt_long <- plt_long |>
dplyr::mutate(service = dplyr::recode(service, !!!service_lookup, .default = service))


}# Canonical ordering (don’t drop anything here)

# Canonical facet order: your 8, then any extras
svc_order <- c(
  "C_Risk","N_export","Sed_export",
  "C_Risk_Red_Ratio","N_Ret_Ratio","Sed_Ret_Ratio",
  "Pollination","Nature_Access"
)

extras <- setdiff(unique(plt_long$service), svc_order)
plt_long <- plt_long |>
  mutate(service = factor(service, levels = c(svc_order, sort(extras))))

# after creating plt_long from sf_f ...
grid_sf <- sf_f %>% dplyr::select(fid, c_fid)  # geometry is "sticky" and kept
rm(plt, sf_f); gc()                             # free the big attribute table + full sf

```

### QA: sanity checks on `plt_long`

Before ranking/thresholding, a lightweight QA helps catch silent problems (e.g., an empty service, unexpected sparsity, or leftover `Inf`s):

-   Confirm `plt_long` exists and peek the structure.
-   Count rows per `service` to spot outliers in coverage (e.g., a service that only exists in a few countries).

#### Inspect pivot output

```{r}
#| label: sanity-check-pivot
# ---- Quick sanity --------------------------------------------------------

stopifnot(exists("plt_long"))

# Peek a few rows & structure

dplyr::glimpse(head(plt_long, 5), width = 80)

# Counts per service (helps spot weird sparsity)

plt_long |>
dplyr::count(service, name = "rows") |>
dplyr::arrange(dplyr::desc(rows)) |>
print(n = 50)
```

## Hotspot extraction workflow (global + subregional)

We identify per-service hotspots using a 5% percentile rule and **direction vectors**: - `loss_services` (e.g., Nature_Access, Pollination, N/Sed_Ret_Ratio, C_Risk_Red_Ratio) → we flag the **lowest** values; - `gain_services` (Sed_export, N_export, C_Risk) → we flag the **highest** values.

We run this **once globally** and then **once per subregion** (World Bank region, income group, continent, UN region, WWF biome). For each run and for each metric (absolute and percent change) we write a compact **GPKG** containing only the hotspot cells, plus a CSV index:

-   Output root: `processed/hotspots/`
    -   `abs/global/hotspots_global_abs.gpkg`
    -   `pct/global/hotspots_global_pct.gpkg`
    -   `abs/<group_col>/hotspots_<group_col>_<group_val>_abs.gpkg`
    -   `pct/<group_col>/hotspots_<group_col>_<group_val>_pct.gpkg`
-   Index: `processed/hotspots/_hotspots_index.csv` (columns: scope, group_col, group_val, metric, n_hot, gpkg).

These files are meant for QGIS/QA and downstream stats (e.g., KS) without recomputing hotspots.

### Hotspot rules & export configuration

The analysis uses a single, central configuration so the hotspot rules are consistent everywhere:

Thresholding: we flag hotspots using the top/bottom tails of the distribution per service. Here we use a percentile cutoff (e.g., 5%) rather than a fixed count.

Direction of concern: services in loss are “worse when they go down” (we keep the lowest tail); services in gain are “worse when they go up” (we keep the highest tail).

Combos (optional): grouped service sets that we count per cell for quick composite summaries.

Export switches: choose whether to write GPKGs and/or the CSV index.

```{r}
#| label: hotspots_config
#| include: true
#| eval: true
HOTS_CFG <- list(
  analysis_name   = "global_NCP_hotspots",
  pct_cutoff      = 0.05,
  threshold_mode  = "percent",
  rule_mode       = "vectors",
  loss = c("Nature_Access","Pollination","N_Ret_Ratio","Sed_Ret_Ratio","C_Risk_Red_Ratio"),
  gain = c("Sed_export","N_export","C_Risk"),
  combos = list(
    deg_combo = c("Nature_Access","Pollination","N_export","Sed_export","C_Risk"),
    rec_combo = c("Nature_Access","Pollination","N_Ret_Ratio","Sed_Ret_Ratio","C_Risk_Red_Ratio")
  ),
# centralize the grouping columns here
  groupings = c("income_grp","region_wb","continent","region_un","WWF_biome"),
  # IO
  write_layers = TRUE,
  write_index  = TRUE,
  out_dir      = file.path(data_dir(), "processed", "hotspots")
)
```

```{r}
#| label: show_hotspots_config
#| echo: false
loss_txt <- paste(HOTS_CFG$loss, collapse = ", ")
gain_txt <- paste(HOTS_CFG$gain, collapse = ", ")
grp_txt <- paste(HOTS_CFG$groupings, collapse = ", ")
combo_txt <- if (length(HOTS_CFG$combos))
  paste(paste0("**", names(HOTS_CFG$combos), "**: ",
               vapply(HOTS_CFG$combos, \(v) paste(v, collapse=", "), "")),
        collapse = "<br>") else "None"

cat(paste0(
"::: callout-note\n",
"**Hotspot configuration**\n\n",
"- Cutoff: ", HOTS_CFG$pct_cutoff * 100, "% (", HOTS_CFG$threshold_mode, ")\n",
"- Rule mode: ", HOTS_CFG$rule_mode, "\n",
"- Loss services: ", loss_txt, "\n",
"- Gain services: ", gain_txt, "\n",
"- Combos: ", combo_txt, "\n",
"…\n- Groupings: ", grp_txt, "\n…",
"- Write layers: ", HOTS_CFG$write_layers, " | Write index: ", HOTS_CFG$write_index, "\n",
"- Output dir: `", HOTS_CFG$out_dir, "`\n",
":::"
))
```

### Validate hotspot configuration

```{r}
#| label: validate_hotspots_config
#| message: false
#| warning: false

stopifnot(exists("plt_long"))
svc_all <- unique(plt_long$service)

# No service should be in both loss and gain
if (length(intersect(HOTS_CFG$loss, HOTS_CFG$gain)) > 0) {
  stop("A service appears in BOTH `loss` and `gain`. Fix HOTS_CFG.")
}

miss_loss <- setdiff(HOTS_CFG$loss, svc_all)
miss_gain <- setdiff(HOTS_CFG$gain, svc_all)
if (length(miss_loss) > 0 || length(miss_gain) > 0) {
  warning("Services in HOTS_CFG not found in `plt_long$service`:\n",
          if (length(miss_loss)) paste0("  - missing loss: ", paste(miss_loss, collapse=", "), "\n"),
          if (length(miss_gain)) paste0("  - missing gain: ", paste(miss_gain, collapse=", "), "\n"))
}
```

### Export hotspot layers

::: callout-note
**Hotspot export module**\
- Computes hotspot cells once (global + by subregion) for ABS and PCT change.\
- Writes compact GPKGs for mapping/QA and maintains `_hotspots_index.csv`.\
- Prereqs: `plt_long` in memory, `HOTS_CFG` defined (loss/gain/combos/etc.).
:::

```{r}
#| label: hotspots_export
#| message: false
#| warning: false
#| echo: false
#| include: false
#| cache: true

stopifnot(exists("plt_long"))

# ---- Geometry: prefer an in-memory slim grid, else build it --------------
if (exists("grid_sf") && inherits(grid_sf, "sf")) {
  geom_sf <- dplyr::select(grid_sf, fid, c_fid)
} else {
  gpkg_grid <- file.path(data_dir(), "processed", "10k_change_calc.gpkg")
  stopifnot(file.exists(gpkg_grid))
  geom_sf <- sf::st_read(gpkg_grid, quiet = TRUE) |>
    dplyr::select(dplyr::any_of(c("fid","c_fid")), dplyr::everything())
  if (!"fid" %in% names(geom_sf)) {
    geom_sf$fid <- seq_len(nrow(geom_sf))
  }
  geom_sf <- dplyr::select(geom_sf, fid, c_fid)  # keep it slim
}
stopifnot("fid" %in% names(geom_sf), !any(duplicated(geom_sf$fid)))

# ---- Helper: safe slug for filenames -------------------------------------
slug <- function(x) {
  x <- gsub("[^A-Za-z0-9]+", "_", x)
  x <- gsub("_+", "_", x)
  sub("^_|_$", "", x)
}

# ---- Core runner (uses central HOTS_CFG) ----------------------------------
run_one_hotset <- function(df, value_col, scope,
                           group_col = NA_character_, group_val = NA_character_,
                           sf_obj = geom_sf,
                           cfg = HOTS_CFG) {
  # Optional subsetting by a specific group value
  if (!is.na(group_col) && !is.na(group_val)) {
    df <- df[df[[group_col]] %in% group_val, , drop = FALSE]
  }
  if (nrow(df) == 0L) {
    return(tibble::tibble(scope, group_col, group_val = as.character(group_val),
                          metric = if (identical(value_col, "abs_chg")) "abs" else "pct",
                          n_hot = 0L, gpkg = NA_character_))
  }

  # Safety: geometry must have all fids present in df
  stopifnot("fid" %in% names(df), "fid" %in% names(sf_obj))
  if (!all(df$fid %in% sf_obj$fid)) {
    missing <- setdiff(unique(df$fid), sf_obj$fid)
    stop(sprintf("Geometry is missing %d fid(s), e.g. %s",
                 length(missing), paste(head(missing, 5), collapse = ", ")))
  }

  # Single source of truth for rules/directions/combos
  hs <- extract_hotspots(
    df             = df,
    value_col      = value_col,
    pct_cutoff     = cfg$pct_cutoff,
    threshold_mode = cfg$threshold_mode,
    rule_mode      = cfg$rule_mode,
    loss_services  = cfg$loss,
    gain_services  = cfg$gain,
    combos         = cfg$combos,
    id_cols        = c("c_fid"),
    sf_obj         = sf_obj,
    write_sf_path  = NULL,
    clean_names    = TRUE
  )

  # Output layout
  out_root <- file.path(data_dir(), "processed", "hotspots")
  metric_stub <- if (identical(value_col, "abs_chg")) "abs" else "pct"
  folder <- if (is.na(group_col)) file.path(out_root, metric_stub, "global")
            else                   file.path(out_root, metric_stub, tolower(group_col))
  dir.create(folder, recursive = TRUE, showWarnings = FALSE)

  file_stub <- if (is.na(group_col)) {
    sprintf("hotspots_global_%s", metric_stub)
  } else {
    sprintf("hotspots_%s_%s_%s", tolower(group_col), slug(group_val), metric_stub)
  }
  out_gpkg <- file.path(folder, paste0(file_stub, ".gpkg"))

  # Write only hotspot features
  if (!is.null(hs$hotspots_sf) && nrow(hs$hotspots_sf) > 0) {
    sf::st_write(hs$hotspots_sf, out_gpkg, quiet = TRUE, delete_dsn = TRUE)
    n_hot <- nrow(hs$hotspots_sf)
  } else {
    out_gpkg <- NA_character__; n_hot <- 0L
  }

  tibble::tibble(
    scope      = scope,
    group_col  = ifelse(is.na(group_col), NA_character_, group_col),
    group_val  = ifelse(is.na(group_val), NA_character_, as.character(group_val)),
    metric     = metric_stub,
    n_hot      = n_hot,
    gpkg       = out_gpkg
  )
}

# ---- Execute: global + subregional runs -----------------------------------

# Pull groupings from config, with a safe fallback
groupings <- if (!is.null(HOTS_CFG$groupings)) {
  HOTS_CFG$groupings
} else {
  c("income_grp","region_wb","continent","region_un","WWF_biome")
}

# Run both metrics
metrics <- c("abs_chg","pct_chg")
index_rows <- lapply(metrics, function(m) run_one_hotset(plt_long, value_col = m, scope = "global"))

# Subregional runs
for (gc in groupings) {
  if (!gc %in% names(plt_long)) next
  vals_chr <- as.character(stats::na.omit(unique(plt_long[[gc]])))
  if (!length(vals_chr)) next

  for (m in metrics) {
    index_rows <- append(index_rows, list(
      purrr::map_dfr(vals_chr, \(v) run_one_hotset(
        df        = plt_long,
        value_col = m,
        scope     = "by_group",
        group_col = gc,
        group_val = v
      ))
    ))
  }
}

hot_index <- dplyr::bind_rows(index_rows)

# Ensure the output dir exists before writing the CSV index
csv_dir <- file.path(data_dir(), "processed", "hotspots")
dir.create(csv_dir, recursive = TRUE, showWarnings = FALSE)
readr::write_csv(hot_index, file.path(csv_dir, "_hotspots_index.csv"))

# Small console summary
dplyr::glimpse(hot_index, width = 120)

```

## Checkpoint recap

Wired the project with a metadata banner (version, git, data root) for reproducibility.

Enriched the 10 km grid with country/biome tags (documented chunk, eval: false) and standardized the working input at processed/10k_change_calc.gpkg.

Reshaped to analysis-ready long format (plt_long), cleaned basic issues, harmonized service labels, and set a canonical facet order.

Centralized hotspot rules in HOTS_CFG (loss/gain, combos, cutoff, groupings, IO).

Exported hotspots once (global + by subregion, for abs/pct change) to compact GPKGs under processed/hotspots/, and wrote a manifest: processed/hotspots/\_hotspots_index.csv.

Why this structure? Heavy work (ranking/thresholding/joining) is done once. The manifest gives us traceability and fast loading for downstream steps (bar plots, violins, KS tests) without re-computation.

## Trimmed change bar plots

::: callout-note
**How to read these bars**

-   Each bar shows the **trimmed mean absolute change** (\|Δ\|) per service within each group; facet axes are free.
-   Bars are **always positive** by design: height = **magnitude of change**, not direction.
-   Direction-of-concern used elsewhere in the analysis:
    -   Worse when **up** ➜ `Sed_export`, `N_export`, `C_Risk`.
    -   Worse when **down** ➜ `Nature_Access`, `Pollination`, `N_Ret_Ratio`, `Sed_Ret_Ratio`, `C_Risk_Red_Ratio`.
-   These bars answer **“where is change largest?”**. See hotspot maps/violins for **up vs. down** patterns.
:::

Short answer: your current barplots use all grid cells (the full 10-km population), not just hotspots. They summarize trimmed means per subregion/global from plt_long via aggregate_change_simple(), with cut_q=0.999 to cap outliers and (optionally) drop_zeros=TRUE. That’s why every bar is positive—those bars are the magnitude of change, not the direction.

```{r}
#| label: bars_by_region
#| message: false
#| warning: false
#| echo: false
#| eval: false

# --- knobs you can tweak quickly -----------------------------------------
group_col         <- "region_wb"   # e.g. "income_grp","continent","region_un","WWF_biome"
metric            <- "pct"         # "pct" or "abs"
cut_q             <- 0.999         # trim extreme 0.1% so bars aren't dominated by outliers
include_global    <- FALSE         # TRUE to add a "Global" bar into each facet
keep_only_ordered <- TRUE          # show only the 8 services in your svc_order
save_plot         <- TRUE
out_dir           <- file.path("outputs","plots")
out_stub          <- paste0("bars_", tolower(group_col), "_", metric)

# --- facet order (your canonical 8 first) ---------------------------------
svc_order <- c(
  "C_Risk","N_export","Sed_export",
  "C_Risk_Red_Ratio","N_Ret_Ratio","Sed_Ret_Ratio",
  "Pollination","Nature_Access"
)

# --- compute trimmed mean magnitude by region -----------------------------
stopifnot(group_col %in% names(plt_long))
gc <- group_col

df_trim <- plt_long |>
  dplyr::filter(!is.na(.data[[gc]])) |>
  dplyr::mutate(
    abs_cell = abs(.data$abs_chg),
    pct_cell = abs(.data$pct_chg)
  ) |>
  dplyr::group_by(.data$service) |>
  dplyr::mutate(
    abs_cap = stats::quantile(.data$abs_cell, cut_q, na.rm = TRUE),
    pct_cap = stats::quantile(.data$pct_cell, cut_q, na.rm = TRUE)
  ) |>
  dplyr::ungroup() |>
  dplyr::mutate(
    abs_trim = pmin(.data$abs_cell, .data$abs_cap),
    pct_trim = pmin(.data$pct_cell, .data$pct_cap)
  ) |>
  dplyr::group_by(.data$service, .data[[gc]]) |>
  dplyr::summarise(
    abs_mean = mean(.data$abs_trim, na.rm = TRUE),
    pct_mean = mean(.data$pct_trim, na.rm = TRUE),
    .groups = "drop"
  )

# optional: add a "Global" reference row per service
if (isTRUE(include_global)) {
  glob <- plt_long |>
    dplyr::mutate(
      abs_cell = abs(.data$abs_chg),
      pct_cell = abs(.data$pct_chg)
    ) |>
    dplyr::group_by(.data$service) |>
    dplyr::mutate(
      abs_cap = stats::quantile(.data$abs_cell, cut_q, na.rm = TRUE),
      pct_cap = stats::quantile(.data$pct_cell, cut_q, na.rm = TRUE)
    ) |>
    dplyr::ungroup() |>
    dplyr::mutate(
      abs_trim = pmin(.data$abs_cell, .data$abs_cap),
      pct_trim = pmin(.data$pct_cell, .data$pct_cap)
    ) |>
    dplyr::group_by(.data$service) |>
    dplyr::summarise(
      abs_mean = mean(.data$abs_trim, na.rm = TRUE),
      pct_mean = mean(.data$pct_trim, na.rm = TRUE),
      .groups = "drop"
    )
  glob[[gc]] <- factor("Global")
  df_trim <- dplyr::bind_rows(df_trim, glob)
}

# order facets and, by default, drop services not in svc_order
if (keep_only_ordered) df_trim <- dplyr::filter(df_trim, .data$service %in% svc_order)
extras <- setdiff(unique(df_trim$service), svc_order)
df_trim <- dplyr::mutate(df_trim,
  service = factor(.data$service, levels = c(svc_order, sort(extras)))
)

# x order: put "Global" first if present, else alphabetical by group
if (isTRUE(include_global)) {
  df_trim[[gc]] <- forcats::fct_relevel(as.factor(df_trim[[gc]]), "Global", after = 0)
} else {
  df_trim[[gc]] <- as.factor(df_trim[[gc]])
}

yvar <- if (identical(metric, "abs")) "abs_mean" else "pct_mean"

p_bars <- ggplot2::ggplot(df_trim, ggplot2::aes(x = .data[[gc]], y = .data[[yvar]])) +
  ggplot2::geom_col() +
  ggplot2::facet_wrap(~ service, ncol = 3, scales = "free_y", drop = FALSE) +
  ggplot2::labs(
    title = paste0("Magnitude of change by ", gc, " (", metric, ")"),
    x = NULL,
    y = if (identical(metric, "abs")) "Mean |Δ| (service units)" else "Mean |Δ| (%)"
  ) +
  ggplot2::theme_minimal(base_size = 11) +
  ggplot2::theme(
    axis.text.x = ggplot2::element_text(angle = 45, hjust = 1),
    panel.grid.major.x = ggplot2::element_blank()
  )

if (isTRUE(save_plot)) {
  # put plots in outputs/plots/<metric>/<group_col>/
  out_root <- out_plots()
  out_dir <- file.path(out_root, metric, tolower(group_col))
  dir.create(out_dir, recursive = TRUE, showWarnings = FALSE)

  # encode key params in the base name
  file_base <- paste(
    "bars",
    tolower(group_col),
    metric,
    paste0("cut", gsub("\\.", "", as.character(cut_q))),
    if (include_global) "with-global" else "no-global",
    sep = "_"
  )

  # avoid overwrite by adding _v02, _v03, …
  final_path <- file.path(out_dir, paste0(file_base, ".png"))
  i <- 2
  while (file.exists(final_path)) {
    final_path <- file.path(out_dir, sprintf("%s_v%02d.png", file_base, i))
    i <- i + 1
  }

  ggplot2::ggsave(
    filename = final_path,
    plot = p_bars,
    width = 12, height = 8, dpi = 300,
    device = ragg::agg_png,  # crisp text
    bg = "white"             # <- NO transparency
  )
  message("Saved plot to: ", normalizePath(final_path))
}

p_bars

```

Generate trimmed-mean bar plots (abs & pct) for each grouping. Plots save to `outputs/plots/...` and are embedded below.

```{r}
#| label: make-all-barplots-inputs
#| message: false
#| warning: false
#| echo: false
#| cache: false
#| results: "hold"

svc_order <- c(
  "C_Risk","N_export","Sed_export",
  "C_Risk_Red_Ratio","N_Ret_Ratio","Sed_Ret_Ratio",
  "Pollination","Nature_Access"
)
groupings <- if (!is.null(HOTS_CFG$groupings)) HOTS_CFG$groupings else
  c("income_grp","region_wb","continent","region_un","WWF_biome")
missing_groupings <- setdiff(groupings, names(plt_long))
if (length(missing_groupings)) {
  warning("Grouping column(s) not found in plt_long and will be skipped: ",
          paste(missing_groupings, collapse = ", "))
}
groupings <- intersect(groupings, names(plt_long))
message("make-all-barplots groupings: ", if (length(groupings)) paste(groupings, collapse = ", ") else "none")
metrics <- c("pct","abs")                # will map to pct_mean / abs_mean below
cut_q   <- 0.999
keep_only_ordered <- TRUE
```

```{r}
#| label: make-all-barplots-helper
#| message: false
#| warning: false
#| echo: false
#| cache: false
#| results: "hold"

plot_change_bars <- function(df, group_col, metric = c("pct","abs"),
                             include_global = FALSE,
                             out_dir = NULL, out_stub = NULL,
                             global_outline = "black",   # <-- outline color for Global
                             global_fill    = NULL) {    # <-- set e.g. "#444444" if you also want a different fill

  metric <- match.arg(metric)
  ycol   <- rlang::sym(if (metric == "pct") "pct_mean" else "abs_mean")

  regs <- agg_change(
    plt_long        = df,
    group_col       = group_col,
    cut_q           = 0.999,
    drop_zeros      = TRUE,
    svc_order       = svc_order,
    svc_order_only  = keep_only_ordered,
    include_global  = include_global
  )

  # sanity guards: need data and the target column
  if (!nrow(regs)) {
    message("No data returned for ", group_col, " (", metric, "); skipping.")
    return(invisible(NULL))
  }
  if (!rlang::as_string(ycol) %in% names(regs)) {
    message("Missing column ", rlang::as_string(ycol), " in agg_change output for ", group_col, "; skipping.")
    return(invisible(NULL))
  }

  # Clean + facet order
  regs <- regs |>
    dplyr::filter(!is.na(service)) |>
    dplyr::mutate(service = forcats::fct_relevel(as.character(service), !!!svc_order, after = Inf))

  # Make grouping factor & push "Global" to the rightmost position
  gsym <- rlang::sym(group_col)
  regs <- regs |>
    dplyr::mutate(
      grp_chr   = as.character(!!gsym),
      is_global = grp_chr == "Global"
    )

  lvl <- sort(unique(regs$grp_chr))
  if ("Global" %in% lvl) lvl <- c(setdiff(lvl, "Global"), "Global")  # shove to end
  regs <- regs |> dplyr::mutate(.grp = factor(grp_chr, levels = lvl))

  p <- ggplot2::ggplot(regs, ggplot2::aes(x = .grp, y = !!ycol)) +
    ggplot2::geom_col() +
    # Overlay the Global bar so it has a subtle outline (and optional fill)
    {
      gdat <- dplyr::filter(regs, is_global)
      if (nrow(gdat)) {
        if (is.null(global_fill)) {
          ggplot2::geom_col(
            data = gdat, fill = NA, color = global_outline, linewidth = 0.8
          )
        } else {
          ggplot2::geom_col(
            data = gdat, fill = global_fill, color = global_outline, linewidth = 0.8
          )
        }
      } else NULL
    } +
    ggplot2::facet_wrap(
      ~ service, ncol = 3, nrow = 3, scales = "free_y", drop = TRUE
    ) +
    ggplot2::labs(
      x = group_col,
      y = if (metric == "pct") "Mean |Δ| (%), trimmed" else "Mean |Δ| (units), trimmed",
      title = paste0("Aggregate change by ", group_col,
                     if (include_global) " (with Global reference)" else "")
    ) +
    ggplot2::theme_minimal(base_size = 12) +
    ggplot2::theme(
      plot.background   = ggplot2::element_rect(fill = "white", color = NA),
      panel.background  = ggplot2::element_rect(fill = "white", color = NA),
      strip.background  = ggplot2::element_rect(fill = "#f3f4f6", color = NA),
      strip.text        = ggplot2::element_text(face = "bold"),
      axis.text.x       = ggplot2::element_text(angle = 45, hjust = 1, vjust = 1),
      panel.grid.minor  = ggplot2::element_blank()
    )

  # Save
  if (is.null(out_dir)) out_dir <- out_plots()
  dir.create(file.path(out_dir, metric, group_col), recursive = TRUE, showWarnings = FALSE)
  if (is.null(out_stub)) {
    out_stub <- paste0("bars_", tolower(group_col), "_", metric,
                       if (include_global) "_wglobal" else "")
  }
  final_path <- file.path(out_dir, metric, group_col, paste0(out_stub, ".png"))
  tryCatch({
    ragg::agg_png(final_path, width = 12, height = 8, units = "in", res = 300, background = "white")
    print(p)
    grDevices::dev.off()
    message("Saved: ", normalizePath(final_path))
  }, error = function(e) {
    message("ERROR while saving ", final_path, ": ", e$message)
    if (grDevices::dev.cur() > 1) grDevices::dev.off()
  })
}
```

```{r}
#| label: make-all-barplots-run
#| message: false
#| warning: false
#| echo: false
#| cache: false
#| results: "hold"

if (length(groupings) == 0) {
  warning("No grouping columns found in plt_long; skipping bar plots.")
} else {
  for (gc in groupings) {
    for (m in metrics) {
      plot_change_bars(plt_long, group_col = gc, metric = m,
                       include_global = FALSE)
      plot_change_bars(plt_long, group_col = gc, metric = m,
                       include_global = TRUE)
    }
  }

  # ---- run: standalone GLOBAL charts (one bar per service) ------------------
  # (We fake a single grouping column called "global" with a single level.)
  plt_global <- plt_long |>
    dplyr::mutate(global = "Global")

  for (m in metrics) {
    plot_change_bars(plt_global, group_col = "global", metric = m,
                     include_global = FALSE)
  }
}

latest_dir_bars <- file.path("outputs","plots","latest","bars")
dir.create(latest_dir_bars, recursive = TRUE, showWarnings = FALSE)
all_new_bars <- list.files(out_plots(), pattern = "bars_.*\\.png$",
                           recursive = TRUE, full.names = TRUE)
if (length(all_new_bars)) {
  invisible(file.copy(all_new_bars, latest_dir_bars, overwrite = TRUE))
}
```

```{r}
#| label: display-barplots
#| echo: false
#| results: 'asis'
#| cache: false
bar_pngs <- list.files(file.path("outputs","plots","latest","bars"),
                       pattern = "bars_.*\\.png$",
                       full.names = TRUE)
if (length(bar_pngs)) {
  knitr::include_graphics(sort(bar_pngs))
} else {
  knitr::asis_output("> No bar plots were generated; check upstream chunks.")
}
```

## Hotspot violin plots

Summarize hotspot distributions by group using saved PNGs; skip computation if group columns are absent. Helper `run_hotspot_violins_by()` now lives in `R/hotspot_violins.R`, so we just call it from this report.

```{r}
#| label: make-hotspot-violins
#| message: false
#| warning: false
#| echo: false
#| cache: false
#| results: "hold"

stopifnot(exists("plt_long"))

groupings <- if (!is.null(HOTS_CFG$groupings) && length(HOTS_CFG$groupings) > 0) {
  HOTS_CFG$groupings
} else {
  c("income_grp","region_wb","continent","region_un","WWF_biome")
}
missing_groupings <- setdiff(groupings, names(plt_long))
if (length(missing_groupings)) {
  warning("Grouping column(s) not found in plt_long and will be skipped: ",
          paste(missing_groupings, collapse = ", "))
}
groupings <- intersect(groupings, names(plt_long))
message("make-hotspot-violins groupings: ", if (length(groupings)) paste(groupings, collapse = ", ") else "none")
violin_order <- levels(plt_long$service)
if (is.null(violin_order)) {
  violin_order <- unique(plt_long$service)
}
violin_order <- as.character(violin_order)

if (length(groupings) == 0) {
  warning("No grouping columns found in plt_long; skipping hotspot violins.")
} else {
  for (gc in groupings) {
    message("Rendering hotspot violins for: ", gc)
    run_hotspot_violins_by(
      df_long          = plt_long,
      group_col         = gc,
      loss              = HOTS_CFG$loss,
      gain              = HOTS_CFG$gain,
      pct_cutoff        = HOTS_CFG$pct_cutoff,
      threshold_mode    = HOTS_CFG$threshold_mode,
      svc_order         = violin_order,
      cut_q             = 0.999,
      keep_only_ordered = TRUE
    )
  }
}

latest_dir_violins <- file.path("outputs","plots","latest","violins")
dir.create(latest_dir_violins, recursive = TRUE, showWarnings = FALSE)
all_new_violins <- list.files(out_plots(), pattern = "violins_.*\\.png$",
                              recursive = TRUE, full.names = TRUE)
if (length(all_new_violins)) {
  invisible(file.copy(all_new_violins, latest_dir_violins, overwrite = TRUE))
}

```

```{r}
#| label: display-violins
#| echo: false
#| results: 'asis'
#| cache: false
violin_pngs <- list.files(file.path("outputs","plots","latest","violins"),
                          pattern = "violins_.*\\.png$",
                          full.names = TRUE)
if (length(violin_pngs)) {
  knitr::include_graphics(sort(violin_pngs))
} else {
  knitr::asis_output("> No violin plots were generated; check upstream chunks.")
}
```
