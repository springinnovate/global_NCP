---
title: "Preliminary Intervention Assessment NbS for the state of Espírito Santo, Brazil"
author: "Jerónimo Rodríguez-Escobar"
output:
  pdf_document: default
  word_document: default
  html_document:
    df_print: paged
editor_options:
  markdown:
    wrap: 72
---
```{r prep environment, eval=TRUE, include=FALSE}
packs <- c('terra', 'purrr', 'landscapemetrics', 'sf','dplyr',
           'here', 'gdalUtilities', 'jsonlite', 'devtools', 'stringr',
           'parallel', 'dplyr', 'tidyr', 'ggplot2', 'janitor', 'forcats', 'foreign',  'exactextractr', 'kableExtra', 'knitr')
sapply(packs, require, character.only = TRUE, quietly=TRUE)
rm(packs)
align_rasters <- function(raster_list, template, resample_method = "bilinear") {
  lapply(raster_list, function(r) {
    if (!compareGeom(r, template, stopOnError = FALSE)) {
      message("Aligning raster: ", names(r))
      # Resample to align with the template
      resample(r, template, method = resample_method)
    } else {
      # Return raster as is if already aligned
      message("Raster already aligned: ", names(r))
      r
    }
  })
}

normalize_raster <- function(r) {
  min_val <- min(values(r), na.rm = TRUE)
  max_val <- max(values(r), na.rm = TRUE)
  (r - min_val) / (max_val - min_val)
}

process_intervention_area <- function(raster_list) {
  # Normalize each raster in the list
  normalized_rasters <- lapply(raster_list, normalize_raster)
  # Combine the normalized rasters by summing them
  combined_raster <- do.call(sum, normalized_rasters)
  return(combined_raster)}

```

# 1. Introduction

This report presents a preliminary approach to estimate potential ecosystem service provision gains derived from restoration across five study areas prioritized in WWF's Nature-Based Solutions Originating Platform (NbS-OP)and optimize restoration interventions. 

Ecosystem services for which global modeling is possible.
Capture a range of values of nature that are produced and delivered through unique phenomena
 (e.g., hydrologic flows, coastal storms, human travel) such that they are not spatially redundant with each other. (Mandle et al )
)

We evaluated following ecosystem services:
 
- Nitrogen Export 
- Sediment Retention 
- Pollination 
- Coastal Protection  
- Nature Access.

## 1.2 Objectives

- Identify high-value pixels for restoration purposes.
- Estimate potential gains in ecosystem service (ES) provision if a target surface (30.200ha) is restored to a natural vegetation state within the intervention area. 

## 1.3 Theoretical Assumptions


- All ecosystem services are equally valuable.
- Restoration likelihood is distributed uniformly across the pixels prioritized for restoration.
- The total area to restore is known in advance, the exact location of the restoration action within the potential restoration area is not determined yet, as it is contingent on variables such as: The willingness of landowners and managers to participate in the project and the ability to secure control over land during the intended intervention duration.


The use of stratified random sampling ensures that representative of the entire population (i.e., all pixels with restoration potential within the AOI). By assessing the results from multiple repetitions, the overall estimates are less susceptible to the influence of individual sample variations and provide a more accurate representation of the true population values.  
  
## 2.1 Study Area

This analysis encompasses the totality of Espírito Santo State, (4'630.792 ha) on Eastern Brazil. A more detailed contextualization of the region, including its geographic, environmental, demographic, and economic aspects, and how it integrates into the broader Symbiosis project can be included here. For this exercise, the total area to restore is 30,200 ha.




## 2.1.1 

```{r filter municiplalities}
poly <- st_read(here("Interventions","espirito_santo", "forest_combined_project_boundary_CAR.shp"))

poly <- st_make_valid(poly)
poly <- poly %>% group_by(municipio) %>% summarize()

sel <- c("Agua Doce do Norte", "Barra de Sao Francisco", "Boa Esperanca", "Conceicao da Barra","Ecoporanga",
         "Mantenopolis", "Montanha", "Mucurici", "Nova Venecia", "Pedro Canario", "Pinheiros", "Ponto Belo",
         "Sao Mateus", "Vila Pavao")

poly <- poly %>% filter(municipio %in% sel)
st_write(poly, here("Interventions", "espirito_santo", "municipalities_f.shp"))
```


**Note:** i think this might not be necessary anymore !
```{r create tmp, eval=FALSE, include=FALSE}
library(here)
# add backgrounds/templates to align 
path_lc <- "/home/jeronimo/OneDrive/Global_ES_mapping/ESA_LC"
# load reclassified land cover map
tf <- file.path(path_lc, list.files(path_lc, pattern= "Rec"))
lc <- lapply(tf,rast)
lc <- lc[[1]]
# create rcl matrix
rcl <- matrix(c(
  0, Inf, 0   # Any value greater than 0 becomes 1
), ncol = 3, byrow = TRUE)

#create background pixels, subsitute all by 0
tmp <- lapply(lc, function(r){
  r <- classify(r[[1]], rcl)
})
tmp <- tmp[[1]]
rm(lc)
```


```{r prepare Esp Santo Land Covers, eval=FALSE, include=FALSE}

lc <- rast(here("ESA_LC", "all_ESA_LC_Rec_2020.tif"))
poly <-st_read("/home/jeronimo/Documents/WWF_nbs_op/Interventions/Brazil/Espirito_Santo_Albers.shp")
poly <- st_transform(poly, crs(lc))
plot(poly$geometry)
lc <- lc %>% crop(poly) %>% mask(poly)
writeRaster(lc, here("Interventions", "Brazil_intervention", "LC_ES_2020.tif"), overwrite=TRUE)
```
------------------------------------------------------------------------
![Espirito Santo2020 ESA Land Covers (reclassified) and Restoration Priority Areas](/home/jeronimo/OneDrive/WWF_nbs_op/Interventions/Espirito_Santo_LC1.png)



# 2. Methods
## 2.1 Input Data

-   **Ecosystem Service Data:** Chaplin-Kramer et al. (2022) [Mapping the planet’s critical natural assets](https://www.nature.com/articles/s41559-022-01934-5). Data derived using InVEST, a suite of spatially explicit models that map and quantify nature's contributions to people. InVEST was developed by the Natural Capital Project, a partnership among Stanford University, the University of Minnesota, The Nature Conservancy, and the World Wildlife Fund.

-   **Restoration Potential:** [Adjusted Griscom restoration grided data](https://zenodo.org/records/883444)

Two sets of data were used, the first one representing the baseline for the ecosystem service provision estimated for 2020, and a second one representing  potential increase in ecosystem service provision if an area is restored to its potential natural vegetation, except for urban/built-up areas. The following ecosystem services were considered:


1.  Nitrogen Export. Derived from the Nitrogen retention modeled using the [**InVEST Nutrient Delivery Ratio**](http://data.naturalcapitalproject.org/invest-releases/3.5.0/userguide/ndr.html).
    Expressed in kg/pixel/year

2.  Sediment Retention. Derived using [**InVEST SDR: Sediment Delivery Ration**](https://storage.googleapis.com/releases.naturalcapitalproject.org/invest-userguide/latest/en/sdr.html).
    Values in ton/pixel/year

3.  Pollination. Derived from [**InVEST SDR: Pollinator Abundance Model**](https://storage.googleapis.com/releases.naturalcapitalproject.org/invest-userguide/latest/en/croppollination.html).
    Units represent Polllination Change in people fed on HABitat. More information in
    [**Chaplin-Kramer, et al.
    2022**](https://static-content.springer.com/esm/art%3A10.1038%2Fs41559-022-01934-5/MediaObjects/41559_2022_1934_MOESM1_ESM.pdf)
    
4.  Coastal Protection. Unitless measure, refers to a derived vulnerability index. [**InVEST Coastal Vulnerability Model**](https://storage.googleapis.com/releases.naturalcapitalproject.org/invest-userguide/latest/en/coastal_vulnerability.html)

5.  Nature Access represented as [**the number of people within 1 hour travel of natural and semi-natural lands**](https://github.com/springinnovate/distance-to-hab-with-friction) (Chaplin-Kramer et al,
    2022).


![Modeled 2020 ES Baseline](/home/jeronimo/OneDrive/WWF_nbs_op/output_maps/Baselines_ESANTO.png)

- Calculate the Sample Size: Based on the resolution of the raster and the
desired AOI, the required number of pixels to be sampled is calculated.
This ensures that the total area covered by the sampled pixels
corresponds to the defined AOI.

- Perform repeated stratified random sampling:  Random sampling of pixels within the defined AOI. The sampling process is repeated 30 times (Bootstrapping) to estimate the sampling distribution of a statistic.

Calculate Summary Statistics: For each repetition, the mean, standard
deviation, and 95% confidence intervals are calculated for each band in
the raster dataset. This provides a measure of the central tendency and
variability of the sampled data.

Synthesize Results: The results from all repetitions are combined to
calculate an overall mean and confidence interval for each band. This
provides a more robust estimate of the expected values, effectively
correcting for potential outliers and reducing the influence of
individual sample variations.


The model can be refined by incorporating additional parameters, such as minimum distance to boundaries, distance between points, topography, or inhabited areas. By definition, coastal risk protection only occurs at the coast; and this has to be kept in mind for example by setting sampling weights for the different  services or derived from population density data. This approach provides a distribution of possible values and allows for the calculation of confidence intervals. By synthesizing the results from multiple repetitions, the estimates are less susceptible to individual sample variations.

## 2.3 Processing Environment 

Spatial Raster Processing Tools: The `terra`, `dplyr`, and `sf` packages in **R** were used for analysis. Data visualization was performed using `ggplot2`.

## 3. Results

```{r crop rest ES, include=FALSE}

tiffes <- file.path(
  here("Interventions", "Brazil_intervention"),
  list.files(
    here("Interventions", "Brazil_intervention"),
    pattern = "BRAZIL,*\\.tif$"
  )
)
tiffes_rest <- tiffes[-c(5,7)]

tiffes <- file.path(
  here("cropped_raster_data"),
  list.files(
    here("cropped_raster_data"),
    pattern = "BRAZIL,*\\.tif$"
  )
)

tiffes <- tiffes[c(6,8,11,16,20)] #just keep pollination - AG,
Service <- c("Nitrogen Retention", "Sediment Retention", "Pollination", "Coastal Protection" , "Nature Access")
```

## 2.3 Processing Environment 

Spatial Raster Processing Tools: The `terra`, `dplyr`, and `sf` packages in **R** were used for analysis. Data visualization was performed using `ggplot2`.



```{r apply obtain baseline output, eval=FALSE, include=FALSE}

# Step 1: Extract file names, product names, and country names
file_names <- basename(tiffes)  # Extract file names from paths

# Extract product names and country names
product_names <- sub("_[A-Z]+\\.tif$", "", file_names)  # Remove "_COUNTRY.tif" to get product name
country_names <- sub(".*_(.*?)\\.tif$", "\\1", file_names)  # Extract country name from file name

# Step 2: Create a dataframe to organize the information
file_info <- data.frame(
  FilePath = tiffes,
  Product = product_names,
  Country = country_names,
  stringsAsFactors = FALSE
)

# Step 4: Extract the sorted file paths
tiffes <- file_info$FilePath

baseES <- lapply(tiffes, rast)

griscom <- rast("/home/jeronimo/OneDrive/WWF_nbs_op/Interventions/Brazil_intervention/SS_griscom.tif") #(wgs)
bkg_ee <- rast("/home/jeronimo/OneDrive/WWF_nbs_op/Interventions/Brazil_intervention/esp_santo_bkg.tif")
griscom <- project(griscom, crs(bkg_ee), res=30, threads=24)
griscom <- round(griscom)
bkg_2 <- project(bkg_ee, baseES[[2]], threads=24)

tot <- freq(bkg_ee)

baseES <- align_rasters(baseES, bkg_2)


# crop mask for the intervention area 
baseES <- lapply(baseES, function(r){
  r <- crop(r,bkg_2)
  ext(r) <- round(ext(r), 4)
  #r <- align(r, bkg_2)
  r <- mask(r,bkg_2)
})

serv_bra <- baseES 
serv_bra <- lapply(serv_bra,trim)

summary <- lapply(serv_bra, function(r) {
  list(
    sum = global(r, "sum", na.rm = TRUE),
    mean = global(r, "mean", na.rm = TRUE)
  )
})

summary<- lapply(summary, function(df){
  df <- do.call(cbind,df)
  })
Service <- c(Service[4], Service[1], Service[2], Service[5], Service[3]) 
summary <- do.call(rbind, summary)
band <- rownames(summary)  
summary <- cbind(band,summary)
summary <- cbind(Service,summary)
summary <- as_tibble(summary)
summary <- summary %>% rename(Sum = sum) %>% rename(Mean=mean)
```

## load restoration data
```{r apply mask AOI AP, eval=FALSE, include=FALSE}

# Step 1: Extract file names, product names, and country names
file_names <- basename(tiffes_rest)  # Extract file names from paths

# Extract product names and country names
product_names <- sub("_[A-Z]+\\.tif$", "", file_names)  # Remove "_COUNTRY.tif" to get product name
country_names <- sub(".*_(.*?)\\.tif$", "\\1", file_names)  # Extract country name from file name

# Step 2: Create a dataframe to organize the information
file_info <- data.frame(
  FilePath = tiffes_rest,
  Product = product_names,
  Country = country_names,
  stringsAsFactors = FALSE
)

# Step 4: Extract the sorted file paths
tiffes <- file_info$FilePath

baseES_r <- lapply(tiffes, rast)


baseES_r <- align_rasters(baseES_r, bkg_ee)

# crop mask for the intervention area 
baseES_r <- lapply(baseES_r, function(r){
  r <- crop(r,bkg_ee)
  ext(r) <- round(ext(r), 4)
  r <- mask(r,bkg_ee)
})
```
```{r sampling target areas Yucatan, eval=FALSE, include=FALSE}
serv_1 <- do.call(c,baseES_r) 
# rest_m <- rast(here('Interventions', 'Mex_intervention', 'Mex_griscom.tif'))
# rcl <- matrix(c(
#   -Inf, 0, 0,  # Any value from -Infinity to 0 remains 0
#   0, Inf, 1   # Any value from 0 to Infinity becomes 1
# ), ncol = 3, byrow = TRUE)
# rest_m <- classify(rest_m, rcl)
# 
# serv_1 <- project(serv_1, bkg_ee, method='bilinear', threads=24)
# serv_1 <- merge(serv_1,bkg_ee)
# 
# rest_m <- terra::project(rest_m, serv_1, threads=24)
# rest_m <- round(rest_m, digits=0)
# serv_1 <- mask(serv_1,rest_m, maskvalues=0)
#Calculate the number of pixels needed for 30,000 hectares
pixel_area <- 30 * 30  # Area of a single pixel in square meters (30m resolution)
hectare_area <- 10000  # Area of one hectare in square meters
pixels_needed <- round((30200 * hectare_area) / pixel_area)

# Count total pixels Griscom intervnetio narea
tot <- freq(bkg_ee)
perc_rest <- pixels_needed/tot$count[1]*100

# Number of repetitions
n_repetitions <- 30
# Function to perform the sampling and calculations
sample_and_calculate <- function(i, raster, pixels_needed) {
  # Sample pixels and directly extract values (without na.rm)
  sample_values <- spatSample(raster, size = pixels_needed, 
                              method = "random", 
                              na.rm = FALSE,  
                              as.points = FALSE, 
                              xy = FALSE,
                              values = TRUE) 

  # Remove rows where ALL values are NA
  sample_values <- sample_values[rowSums(is.na(sample_values)) != ncol(sample_values), ]

  # If not enough samples after removing NAs, resample
  if (nrow(sample_values) < pixels_needed) {
    sample_values <- rbind(
      sample_values,
      spatSample(raster, size = pixels_needed - nrow(sample_values),
                 method = "random", na.rm = TRUE, 
                 as.points = FALSE, xy = FALSE, values = TRUE)
    )
  }

  # Calculate summary statistics
  band_stats <- apply(sample_values, 2, function(x) { 
    mean_val <- mean(x)
    sd_val <- sd(x)
    n_val <- length(x)
    se_val <- sd_val / sqrt(n_val)
    margin_error <- qt(0.975, df = n_val - 1) * se_val
    lower_ci <- mean_val - margin_error
    upper_ci <- mean_val + margin_error
    return(c(mean = mean_val, lower_ci = lower_ci, upper_ci = upper_ci))
  })

  band_stats_df <- as.data.frame(t(band_stats))
  band_stats_df$repetition <- i

  # Calculate sum of pixel values for each band
  band_sums <- colSums(sample_values) 
  band_stats_df$sum <- band_sums

  return(band_stats_df)
}

# Using mclapply (parallel processing)
num_cores <- 10
results_list <- mclapply(1:n_repetitions, sample_and_calculate, 
                         raster = serv_1, 
                         pixels_needed = pixels_needed,
                         mc.cores = num_cores) 

results_list <- lapply(results_list, function(df){
  df <- df %>% mutate(band=rownames(df))
})
# Combine all results into a single data frame
all_results <- as_tibble(do.call(rbind, results_list))

# Combine all results into a single data frame
all_results <- as_tibble(do.call(rbind, results_list))


# Add new columns with the service names and units.
all_results <- all_results %>%
  mutate(Service = case_when(
    band == "cv_habitat_value_Sc3v1-ESAmod2_v2_md5_64082b" ~ "Coastal Protection",
    band == "nature_access_diff_Sc3v1_PNVnoag-esa2020" ~ "Nature Access",
    band == "nitrogen_ESAmod2-Sc3v1_md5_024a36" ~ "Nitrogen Retention",
    band == "pollination_ppl_fed_on_ag_10s_Sc3v1_PNVnoag-esa2020_md5_405c88" ~ "Pollination",
    band == "pollination_ppl_fed_on_hab_Sc3v1_PNV_no_ag-ESA_md5_576790" ~ "Pollination",
    band == "sediment_ESAmod2-Sc3v1_md5_149078" ~ "Sediment Retention",
    # ... add more cases for other bands ...
    TRUE ~ band  # Keep the original band name if no match
  ))

all_results <- all_results %>%
  mutate(units = case_when(
    band == "cv_habitat_value_Sc3v1-ESAmod2_v2_md5_64082b" ~ "Risk Reduction Index",
    band == "nature_access_diff_Sc3v1_PNVnoag-esa2020" ~ "People within 1 hour",
    band == "nitrogen_ESAmod2-Sc3v1_md5_024a36" ~ "Nitrogen Export (kg/ha/year)",
    band == "pollination_ppl_fed_on_ag_10s_Sc3v1_PNVnoag-esa2020_md5_405c88" ~ "Pollination (equivalent people fed)",
    band == "pollination_ppl_fed_on_hab_Sc3v1_PNV_no_ag-ESA_md5_576790" ~ "Pollination",
    band == "sediment_ESAmod2-Sc3v1_md5_149078" ~ "Sediment Export (ton/kg/year)",
    # ... add more cases for other bands ...
    TRUE ~ band  # Keep the original band name if no match
  ))

all_results <- all_results %>%
  mutate(color = case_when(
    band == "cv_habitat_value_Sc3v1-ESAmod2_v2_md5_64082b" ~ "#9e9ac8",
    band == "nature_access_diff_Sc3v1_PNVnoag-esa2020" ~ "#A57C00",
    band == "nitrogen_ESAmod2-Sc3v1_md5_024a36" ~ "#2c944c",
    band == "pollination_ppl_fed_on_ag_10s_Sc3v1_PNVnoag-esa2020_md5_405c88" ~ "#dd1c77",
    band == "pollination_ppl_fed_on_hab_Sc3v1_PNV_no_ag-ESA_md5_576790" ~ "#dd1b56",
    band == "sediment_ESAmod2-Sc3v1_md5_149078" ~ "#08306b",
    # ... add more cases for other bands ...
    TRUE ~ band  # Keep the original band name if no match
  ))


#drop the columnwit hthe raster name
all_results$band <- NULL
summary$band <- NULL
all_results <- left_join(all_results,summary)

#Get Percentages!!!

all_results <- all_results %>% mutate(perc_sum= sum/Sum*100) %>% mutate(perc_mean=mean/Mean*100)

# Get a final Column with the final percentages for services (move the access from mean)
# Add the "Final" column based on the rule
all_results <- all_results %>%
  mutate(Final = case_when(
    Service == "Nature Access" ~ perc_mean,  # If "Service" is "Nature Access", use "perc_mean"
    TRUE ~ perc_sum  # For all other cases, use "perc_sum"
  ))


all_results <- all_results %>% mutate()


save(all_results, file= here("Interventions", "Brazil_intervention", "all_res_bra.RData"))
```

## 3.1 EStimated ES Gain through Restoration

The estimated gains in ecosystem service provision, (%) are synthetized in following table
```{r table outputs, echo=FALSE}
load(here("Interventions", "Brazil_intervention", "all_res_bra.RData"))


sumy <- all_results %>% group_by(Service) %>% 
  summarise(mean_final = mean(perc_sum, na.rm = TRUE),        # Mean of Final column
    sd_final = sd(perc_sum, na.rm = TRUE),            # Standard deviation
    iqr_final = IQR(perc_sum, na.rm = TRUE),          # Interquartile range (optional)
    .groups = "drop"
  )

final_summary <- all_results %>%
  group_by(Service) %>%
  summarise(
    mean_final = mean(Final, na.rm = TRUE), 
    lower_ci = quantile(Final, probs = 0.025, na.rm = TRUE),  # 2.5th percentile
    upper_ci = quantile(Final, probs = 0.975, na.rm = TRUE),  # 97.5th percentile
    .groups = "drop"
  )
# Assuming your 'all_results' data frame has the columns 'Service', 'units', and 'color'



final_summary2 <- all_results %>%
  group_by(Service) %>%
  summarise(
    mean_final = mean(perc_sum, na.rm = TRUE), 
    lower_ci = quantile(perc_sum, probs = 0.025, na.rm = TRUE),  # 2.5th percentile
    upper_ci = quantile(perc_sum, probs = 0.975, na.rm = TRUE),  # 97.5th percentile
    .groups = "drop"
  )

final_summary2 <- final_summary2 %>%
  mutate(across(where(is.numeric), ~ round(., 2)))

final_summary2 %>%
  kbl(
    col.names = c("Ecosystem Service", "Mean (%)", "Lower CI (%)", "Upper CI (%)"),
    caption = "Estimated ES Provision Gain in %  with Confidence Intervals",
    align = "c"
  ) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "responsive"),
    full_width = FALSE,
    position = "center"
  )

write.csv(final_summary2, file=here("Interventions", "Brazil_intervention", "summary_interventionBra2.csv"))
```

### 3.2 Result Visualization

```{r plot E Santo outpus, echo=FALSE}

load(here("Interventions", "Brazil_intervention", "all_res_bra.RData"))

# Generate the ggplot object
plot <- ggplot(all_results %>% filter(band!='pollination_ppl_fed_on_hab_Sc3v1_PNV_no_ag-ESA_md5_576790'), aes(y = perc_sum, fill = color)) +
  geom_boxplot() +
  labs(title = str_wrap("Potential in ES gain - Espirito Santo", width = 50), 
       y = "Estimated ES provision gain (%)") +
  theme_bw() +
  theme(
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank(),
    axis.title.x = element_blank(),
    strip.background = element_blank(),
    strip.text = element_text(face = "bold"),
    legend.position = "none"  # Remove legend since color is already mapped
  ) +
  scale_fill_identity() + 
  facet_wrap(~ Service, scales = "free_y", labeller = labeller(Service = label_wrap_gen(width = 10))) +  
  scale_y_continuous(labels = function(x) {
    if (max(x, na.rm = TRUE) > 100000) {
      paste0(format(x / 1000, big.mark = ".", decimal.mark = ","), "k")
    } else {
      format(x, big.mark = ".", decimal.mark = ",")
    }
  }) 
plot
```



![Maximal Increase Potential per service](/home/jeronimo/OneDrive/WWF_nbs_op/output_maps/Max_10_es.png)


References
Bivand, R. S., Pebesma, E. J., & Gómez-Rubio, V. (2013). Applied
spatial data analysis with R (2nd ed.). Springer.
Cochran, W. G. (1977). Sampling techniques (3rd ed.). John Wiley & Sons.
Lohr, S. L. (2010). Sampling: Design and analysis (2nd ed.).
Brooks/Cole. 1\
Natural Capital Project (2024). InVEST 0.0. Stanford University, University of Minnesota, Chinese Academy of Sciences, The Nature Conservancy, World Wildlife Fund, Stockholm Resilience Centre and the Royal Swedish Academy of Sciences. *https://naturalcapitalproject.stanford.edu/software/invest*