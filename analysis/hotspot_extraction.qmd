---
title: "Hotspot Extraction"
format: html
editor: visual
---

```{r setup, message=FALSE, warning=FALSE}
#| label: setup
#| message: false
#| warning: false

# Core tidy + spatial
library(dplyr)
library(tidyr)
library(purrr)
library(stringr)
library(forcats)
library(ggplot2)
library(scales)
library(sf)
library(terra)
library(exactextractr)

# Plot helpers
library(viridisLite)
library(ggnewscale)
library(ragg)

# Dev/project helpers
library(devtools)   # for load_all()

# Optional viewers (enable only if you use them)
# library(httpgd)
# library(leaflet)
# library(htmltools)

# ---- Global options / performance ---------------------------------------
options(dplyr.summarise.inform = FALSE)
sf::sf_use_s2(TRUE)
Sys.setenv(GDAL_NUM_THREADS = "ALL_CPUS", PROJ_NETWORK = "ON")
terraOptions(tempdir = file.path(tempdir(), "terra_tmp"))

set.seed(1)

# ---- Project wiring ------------------------------------------------------
# Load package-style functions from R/ (if this is a package-ish repo)
devtools::load_all(quiet = TRUE)

# Paths helper (set GLOBAL_NCP_DATA in ~/.Renviron first)
source("../R/paths.R")

# ---- Python (enable when needed) ----------------------------------------
# library(reticulate)
# use_virtualenv("/home/jeronimo/venvs/coastal_snap_env", required = TRUE)

```

# Append countryand biome data to the sytnesiss vector for subregional analysis 


```{r load country gpkg, eval = FALSE}
# ---- Purpose --------------------------------------------------------------

# Attach country & biome attributes to the 10 km grid (sf_f) so we can group

# hotspots by subregions (income_grp, region_wb, BIOME, etc.).

# NOTE: We’ll test/execute this later once paths are finalized. For now,

# this chunk documents the exact steps and makes paths configurable.

# ---- Preconditions --------------------------------------------------------

# 1) sf_f (grid polygons) already in memory with at least: fid, c_fid, geometry

# 2) paths.R is sourced earlier, providing a function data_dir() that points to

# ~/data/global_ncp (or your chosen location via GLOBAL_NCP_DATA env var).

stopifnot(inherits(sf_f, "sf"))
stopifnot(all(c("fid", "c_fid") %in% names(sf_f)))

# Optional: make polygon ops consistent/correct on the sphere

# options(sf_use_s2 = TRUE)

# ---- Inputs ---------------------------------------------------------------

ct_path  <- file.path(data_dir(), "vectors", "cartographic_ee_ee_r264_correspondence.gpkg")
bio_path <- file.path(data_dir(), "vectors", "Biome.gpkg")

stopifnot(file.exists(ct_path), file.exists(bio_path))

ct <- sf::st_read(ct_path, quiet = TRUE) |>
dplyr::select(id, ee_r264_name, iso3, continent, income_grp, region_un, region_wb, subregion)

biomes <- sf::st_read(bio_path, quiet = TRUE) |>
dplyr::select(BIOME, WWF_biome)

# ---- CRS harmonization ----------------------------------------------------

crs_grid <- sf::st_crs(sf_f)
if (!sf::st_crs(ct) == crs_grid)     ct     <- sf::st_transform(ct, crs_grid)
if (!sf::st_crs(biomes) == crs_grid) biomes <- sf::st_transform(biomes, crs_grid)

# ---- Lightweight template (keeps geometry) --------------------------------

sf_template <- sf_f |>
dplyr::select(fid, c_fid)  # <— only keys + geometry

# ---- Representative point per cell (faster/robust attr join) --------------

# Prefer point-on-surface over centroid for oddly-shaped cells.

pts <- sf::st_point_on_surface(sf_template)

# ---- Spatial joins --------------------------------------------------------

# If you ever need "nearest polygon" instead of "within", use:

# pts_ct <- sf::st_join(pts, ct, join = st_nearest_feature)

pts_ct    <- sf::st_join(pts, ct,     left = TRUE)
pts_biome <- sf::st_join(pts, biomes, left = TRUE)

# ---- Drop geometry and merge attrs by fid ---------------------------------

pts_ctdf <- sf::st_drop_geometry(pts_ct)
pts_bmdf <- sf::st_drop_geometry(pts_biome)

out_attrs <- pts_ctdf |>
dplyr::left_join(pts_bmdf, by = "fid", suffix = c("", "_biome"))

# Sanity: enforce uniqueness by fid (defensive; should already be 1:1)

if (anyDuplicated(out_attrs$fid)) {
out_attrs <- out_attrs |>
dplyr::arrange(fid) |>
dplyr::distinct(fid, .keep_all = TRUE)
}

# ---- Bring attributes back to the grid ------------------------------------

sf_f_joined <- sf_f |>
dplyr::left_join(out_attrs, by = "fid")

stopifnot(nrow(sf_f_joined) == nrow(sf_f), inherits(sf_f_joined, "sf"))

# ---- Output (idempotent write) --------------------------------------------

out_gpkg <- file.path(data_dir(), "processed", "10k_change_calc.gpkg")
dir.create(dirname(out_gpkg), recursive = TRUE, showWarnings = FALSE)
if (file.exists(out_gpkg)) file.remove(out_gpkg)
sf::st_write(sf_f_joined, out_gpkg, quiet = TRUE)

# TODO (later): benchmark polygon-on-polygon join for QA; verify sample cells

# visually in QGIS; confirm iso3/income_grp/BIOME coverage stats.
```

####################### START HERE

# 1 Hotspot Extraction

## 1.1 Prepare Data for Analysis

The spatial objects with the anecessary  attributes are loaded and reformatted for analysis and chart preparation, that requires to **pivot** the input vector files into the long format, with one row per service/cell combination.

```{r pivot}
#| eval: true
#| include: true
# ---- Produce plt_long once (skip if already present) ---------------- ----

if (!exists("plt_long", inherits = TRUE)) {

gpkg <- file.path(data_dir(), "processed", "10k_change_calc.gpkg")
stopifnot(file.exists(gpkg))

sf_f <- sf::st_read(gpkg, quiet = TRUE)

# Ensure fid exists (idempotent)

if (!"fid" %in% names(sf_f)) {
sf_f$fid <- seq_len(nrow(sf_f))
}

plt <- sf::st_drop_geometry(sf_f)

# IDs + change columns

id_cols  <- c("fid", "c_fid")
chg_cols <- grep("_(abs|pct)_chg$", names(plt), value = TRUE)

# Socio/grouping columns = everything else

socio_vars <- setdiff(names(plt), c(id_cols, chg_cols))

# Long -> Wide (abs_chg / pct_chg)

plt_long <- plt |>
tidyr::pivot_longer(
cols = tidyselect::all_of(chg_cols),
names_to = c("service", "chg_type"),
names_pattern = "^(.*)_(abs|pct)_chg$",
values_to = "chg_value"
) |>
dplyr::mutate(service = stringr::str_remove(service, "_mean$")) |>
tidyr::pivot_wider(
names_from  = chg_type,
values_from = chg_value,
names_vary  = "slowest"
) |>
dplyr::rename(abs_chg = abs, pct_chg = pct) |>
dplyr::select(fid, c_fid, service, abs_chg, pct_chg, dplyr::any_of(socio_vars)) |>
dplyr::filter(!is.na(c_fid)) |>
dplyr::filter(!(is.infinite(abs_chg) | is.infinite(pct_chg))) |>
dplyr::filter(!is.na(abs_chg) | !is.na(pct_chg))

# Service renaming via lookup (easy to extend)

service_lookup <- c(
sed_export     = "Sed_export",
n_export       = "N_export",
n_retention    = "N_retention",
nature_access  = "Nature_Access",
pollination    = "Pollination",
usle           = "USLE",
n_ret_ratio    = "N_Ret_Ratio",
sed_ret_ratio  = "Sed_Ret_Ratio",
Rt_ratio       = "C_Risk_Red_Ratio",
Rt             = "C_Risk",
Rt_service     = "C_Prot_service",
Rt_nohab       = "Rt_nohab"
)
plt_long <- plt_long |>
dplyr::mutate(service = dplyr::recode(service, !!!service_lookup, .default = service))

# Canonical ordering (don’t drop anything here)

service_levels <- c(
"Nature_Access","N_export","N_retention","N_Ret_Ratio",
"Sed_export","USLE","Sed_Ret_Ratio","Rt_nohab",
"C_Risk","C_Prot_service","C_Risk_Red_Ratio","Pollination"
)
plt_long <- plt_long |>
dplyr::mutate(service = forcats::fct_relevel(service, !!!service_levels, after = Inf))

message(glue::glue("plt_long ready: {nrow(plt_long)} rows across {dplyr::n_distinct(plt_long$service)} services"))
}

```


# Wrapper: extract hotpots per group 


```{r extract hotposts_group}

# group_cols is a character vector like c("income_grp") or c("region_wb")
extract_hotspots_by <- function(df_long, group_cols,
                                loss, gain,
                                value_col = "abs_chg",
                                pct_cutoff = 0.05,
                                threshold_mode = "percent") {

  stopifnot(all(group_cols %in% names(df_long)))

  df_long %>%
    select(fid, service, all_of(group_cols), all_of(value_col), c_fid) %>%
    rename(.value = {{ value_col }}) %>%  # standardize name for mapping
    nest(data = -all_of(group_cols)) %>%
    mutate(
      res = map(
        data,
        ~ extract_hotspots(
            df            = rename(.x, !!value_col := .value),
            value_col     = value_col,
            pct_cutoff    = pct_cutoff,
            threshold_mode= threshold_mode,
            rule_mode     = "vectors",
            loss_services = loss,
            gain_services = gain,
            id_cols       = c("c_fid")      # carry c_fid to summaries
          )
      )
    ) %>%
    transmute(
      !!!syms(group_cols),
      hotspots_df     = map(res, "hotspots_df"),
      non_hotspots_df = map(res, "non_hotspots_df"),
      summary_df      = map(res, "summary_df"),
      binary_matrix   = map(res, "binary_matrix")
    )
}


```


# Sanity Vheck Pivoted Data


```{r sanity chek}
# ---- Quick sanity --------------------------------------------------------

stopifnot(exists("plt_long"))

# Peek a few rows & structure

dplyr::glimpse(head(plt_long, 5), width = 80)

# Counts per service (helps spot weird sparsity)

plt_long |>
dplyr::count(service, name = "rows") |>
dplyr::arrange(dplyr::desc(rows)) |>
print(n = 50)
```

```{r run wrapper}
# ---- Config you already used (keep) -------------------------------------

loss <- c("Nature_Access","Pollination","N_Ret_Ratio","Sed_Ret_Ratio","C_Risk_Red_Ratio")
gain <- c("Sed_export","N_export","C_Risk")

# Target facet order

facet_core <- c(
"C_Risk","N_export","Sed_export",
"C_Risk_Red_Ratio","N_Ret_Ratio","Sed_Ret_Ratio",
"Pollination","Nature_Access"
)

# Helper: run wrapper and produce ONE mixed-metric violin per grouping

run_mixed_violin_by <- function(group_col,
out_stub,
upper_cut = 0.999,  # 99.9% trim
plot_n   = 300000L   # sampling cap for speed
){
stopifnot(group_col %in% names(plt_long))

message("==> Mixed-metric violins by: ", group_col)

# 1) Run hotspots for ABS & PCT once

by_abs <- extract_hotspots_by(plt_long, group_col, loss, gain, value_col = "abs_chg")
by_pct <- extract_hotspots_by(plt_long, group_col, loss, gain, value_col = "pct_chg")

# 2) Tidy value tables (fid × service × group)

abs_vals <- by_abs |>
dplyr::transmute(
!!group_col := .data[[group_col]],
vals = purrr::map(hotspots_df, ~ dplyr::select(.x, fid, service, abs_chg))
) |>
tidyr::unnest(vals)

pct_vals <- by_pct |>
dplyr::transmute(
!!group_col := .data[[group_col]],
vals = purrr::map(hotspots_df, ~ dplyr::select(.x, fid, service, pct_chg))
) |>
tidyr::unnest(vals)

# 3) Join measures so each (fid,service,group) can pick its metric

vals <- dplyr::full_join(
abs_vals, pct_vals,
by = c(group_col, "fid", "service")
)

# 4) Build chosen metric:

# - Nature_Access -> use pct_chg

# - others        -> use abs_chg

vals <- vals |>
dplyr::mutate(
metric    = dplyr::if_else(service == "Nature_Access", "pct", "abs"),
y         = dplyr::if_else(metric == "pct", pct_chg, abs_chg),
# nice facet label (only rename Access)
service_lab = dplyr::if_else(service == "Nature_Access", "Access", as.character(service)),
# keep group factor stable
!!group_col := as.factor(.data[[group_col]])
) |>
dplyr::filter(!is.na(.data[[group_col]]), !is.na(y), y != 0)

# 5) Trim outliers per-service (upper quantile)

vals <- vals |>
dplyr::group_by(service) |>
dplyr::mutate(y_upper = stats::quantile(y, probs = upper_cut, na.rm = TRUE)) |>
dplyr::ungroup() |>
dplyr::filter(y <= y_upper)

# 6) Optional sampling to keep render fast

if (nrow(vals) > plot_n) {
vals <- dplyr::slice_sample(vals, n = plot_n)
}

# 7) Facet order: core list first, all others afterward

all_services <- unique(vals$service)
extra <- setdiff(all_services, facet_core)
facet_levels <- c(facet_core, extra)
vals <- vals |>
dplyr::mutate(
service = forcats::fct_relevel(service, !!!facet_levels, after = 0L),
# ensure label vector matches the same order
service_lab = factor(service_lab,
levels = dplyr::recode(facet_levels,
"Nature_Access" = "Access", .default = facet_levels))
)

# 8) Plot: violins only (no boxplots), same styling as before

p <- ggplot2::ggplot(vals, ggplot2::aes(x = y, y = .data[[group_col]])) +
ggplot2::geom_violin(trim = TRUE, scale = "width") +
ggplot2::coord_flip() +
ggplot2::facet_wrap(~ service_lab, ncol = 3, scales = "free_x") +
ggplot2::labs(
title    = paste0("Hotspot change by ", group_col),
subtitle = "Metric rule: absolute change for all services except Access (percent change).\nValues trimmed at the 99.9th percentile; zeros and NAs removed.",
x        = NULL,
y        = NULL
) +
ggplot2::theme_minimal(base_size = 11) +
ggplot2::theme(
axis.text.x = ggplot2::element_text(size = 8, angle = 45, hjust = 1),
panel.grid.minor = ggplot2::element_blank()
)

# 9) Save inside repo

out_dir <- file.path("outputs", "plots")
dir.create(out_dir, recursive = TRUE, showWarnings = FALSE)
out_path <- file.path(out_dir, paste0(out_stub, "_mixed_metric_violins.png"))
ggplot2::ggsave(out_path, p, width = 12, height = 8, dpi = 300)

message("   saved: ", out_path)
invisible(out_path)
}

# ---- Run for each grouping you care about --------------------------------

run_mixed_violin_by("region_wb", "regionwb")
run_mixed_violin_by("BIOME",     "biome")
run_mixed_violin_by("continent", "continent")
run_mixed_violin_by("region_un", "regionun")
run_mixed_violin_by("income_grp","incomegrp")


```
