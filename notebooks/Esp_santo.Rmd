---
title: "Preliminary Intervention Assessment NBS for the state of Espírito Santo, Brazil"
author: "Jerónimo Rodríguez-Escobar"
output:
  word_document: default
  pdf_document: default
  html_document:
    df_print: paged
editor_options:
  markdown:
    wrap: 72
---

# 1. Introduction

This report presents a preliminary approach to estimate potential ecosystem service gains derived from restoration in the state of Espírito Santo, Brazil. The analysis is conducted at a spatial resolution of 30 meters.


```{r prep environment, eval=TRUE, include=FALSE}
packs <- c('terra', 'purrr', 'landscapemetrics', 'sf','dplyr',
           'here', 'gdalUtilities', 'jsonlite', 'devtools', 'stringr',
           'parallel', 'dplyr', 'tidyr', 'ggplot2', 'janitor', 'forcats', 'foreign')
sapply(packs, require, character.only = TRUE, quietly=TRUE)
rm(packs)
align_rasters <- function(raster_list, template, resample_method = "bilinear") {
  lapply(raster_list, function(r) {
    if (!compareGeom(r, template, stopOnError = FALSE)) {
      message("Aligning raster: ", names(r))
      # Resample to align with the template
      resample(r, template, method = resample_method)
    } else {
      # Return raster as is if already aligned
      message("Raster already aligned: ", names(r))
      r
    }
  })
}

normalize_raster <- function(r) {
  min_val <- min(values(r), na.rm = TRUE)
  max_val <- max(values(r), na.rm = TRUE)
  (r - min_val) / (max_val - min_val)
}

process_intervention_area <- function(raster_list) {
  # Normalize each raster in the list
  normalized_rasters <- lapply(raster_list, normalize_raster)
  # Combine the normalized rasters by summing them
  combined_raster <- do.call(sum, normalized_rasters)
  return(combined_raster)
}
```

## 1.2 Objectives

This analysis has two objectives:
- Identify high-value pixels for restoration purposes.
- Estimate potential gains in ecosystem service (ES) provision if a target area (preliminarily 30,200 ha) is restored to natural vegetation within the State of Espírito Santo.

## 1.3 Theoretical Assumptions

This analysis is based on the following assumptions:

- All ecosystem services are equally valuable.
- Restoration likelihood is distributed uniformly across the intervention areas.
- The restoration target area is 30,200 ha. The exact location of restoration efforts within the state is not yet determined, as it depends on factors such as:
  - The willingness of landowners and managers to participate in the project.
  - The ability to secure control over land during the project duration.
  - The spatial configuration effects incorporated during the modeling of ecosystem service gains.
  - Confidence intervals provide robust estimates under random distribution scenarios.
---------------------------------------------------------------------

# 2. Materials and Methods

## 2.1 Study Area

This analysis encompasses the totality of Espírito Santo State, located on the Brazilian Atlantic coast. A more detailed contextualization of the region, including its geographic, environmental, demographic, and economic aspects, and how it integrates into the broader Symbiosis project can be included here. For this exercise, the total area to restore is 30,200 ha.

------------------------------------------------------------------------

## 2.2 Input Data

-   **Ecosystem Service Data:** Chaplin-Kramer et al. (2022) [Mapping the planet’s critical natural assets](https://www.nature.com/articles/s41559-022-01934-5). Data were derived using InVEST, a suite of spatially explicit models that map and quantify nature's contributions to people. InVEST was developed by the Natural Capital Project, a partnership among Stanford University, the University of Minnesota, The Nature Conservancy, and the World Wildlife Fund

-   **Restoration Potential:** [Adjusted Griscom restoration grided data](https://zenodo.org/records/883444)

Spatial grids (raster data in GeoTIFF format) were used, where pixel values reflect estimated gains, measured in units specific to each ecosystem service. These gains represent the potential increase in ecosystem service provision if an area is restored to its potential natural vegetation, except for urban/built-up areas. The following ecosystem services were considered:

1.  Coastal Protection. Unitless measure, refers to a derived vulnerability index. [**InVEST Coastal Vulnerability Model**](https://storage.googleapis.com/releases.naturalcapitalproject.org/invest-userguide/latest/en/coastal_vulnerability.html)

2.  Nitrogen Export. Derived from the Nitrogen retention modeled using the [**InVEST Nutrient Delivery Ratio**](http://data.naturalcapitalproject.org/invest-releases/3.5.0/userguide/ndr.html).
    Expressed in kg/pixel/year

3.  Sediment Retention. Derived using [**InVEST SDR: Sediment Delivery Ration**](https://storage.googleapis.com/releases.naturalcapitalproject.org/invest-userguide/latest/en/sdr.html).
    Values in ton/pixel/year

4.  Pollination. Derived from [**InVEST SDR: Pollinator Abundance Model**](https://storage.googleapis.com/releases.naturalcapitalproject.org/invest-userguide/latest/en/croppollination.html).
    Units represent Polllination Change in people fed on HABitat. More information in
    [**Chaplin-Kramer, et al.
    2022**](https://static-content.springer.com/esm/art%3A10.1038%2Fs41559-022-01934-5/MediaObjects/41559_2022_1934_MOESM1_ESM.pdf)

5.  Nature Access represented as [**the number of people within 1 hour travel of natural and semi-natural lands**](https://github.com/springinnovate/distance-to-hab-with-friction) (Chaplin-Kramer et al,
    2022).


## 2.3 Processing Environment 

Spatial Raster Processing Tools: The `terra`, `dplyr`, and `sf` packages in **R** were used for analysis. Data visualization was performed using `ggplot2`.

### 2.4 Normalization of Ecosystem Service Restoration Data 

Raster data were normalized using the following formula to bring values to a common standard:
$$
\text{Normalized Value} = \frac{\text{Raster Value} - \text{Min Value}}{\text{Max Value} - \text{Min Value}}
$$

Where: 
- $\text{Raster Value}$ is the value of a given pixel. 
- $\text{Min Value}$ and $\text{Max Value}$ represent the minimum and maximum observed values across the raster dataset.

# 2.5 Stratified Random Sampling to Estimate Total Ecosystem Service Gains

A stratified random sampling approach was employed to estimate total gains in ES service provision given a total intervention area of 30,200 ha. The model can be refined by incorporating additional parameters, such as minimum distance to boundaries, distance between points, topography, or inhabited areas. By definition, coastal risk protection only occurs at the coast; and this has to be kept in mind for example by setting sampling weights for the different  services or derived from population density data. This approach provides a distribution of possible values and allows for the calculation of confidence intervals. By synthesizing the results from multiple repetitions, the estimates are less susceptible to individual sample variations.

# 2.6 Data Alignment

All raster datasets were aligned to the same spatial resolution, coordinate reference system (CRS), and origin. The global ESA Land Cover Classification Raster for 2020 (CRS: WGS-84) was used as a template. The final results were then reprojected to the South America Albers Equal Area Conic CRS


### 3.2.3 Prepare Templates to Align the Data

To perform the analysis, all the raster datasets need to be brought to the same spatial resolution, crs and aligned  to the same origin. We used the global ESA Land Cover Classification Raster for 2020 (CRS: WGS-84)

```{r create tmp, eval=FALSE, include=FALSE}
library(here)
# add backgrounds/templates to align 
path_lc <- here('ESA_LC') 
# load reclassified land cover map
tf <- file.path(path_lc, list.files(path_lc, pattern= "Rec"))
lc <- lapply(tf,rast)
lc <- lc[[1]]
# create rcl matrix
rcl <- matrix(c(
  0, Inf, 0   # Any value greater than 0 becomes 1
), ncol = 3, byrow = TRUE)

#create background pixels, subsitute all by 0
tmp <- lapply(lc, function(r){
  r <- classify(r[[1]], rcl)
})
tmp <- tmp[[1]]
rm(lc)
```

------------------------------------------------------------------------

# 4 Processing

## 4.1 Target Layers
The target layers used for this analysis were: Coastal Protection, Nitrogen Export, Sediment Retention, and Pollination.
```{r select ES diff  data, include=FALSE}
#Restoration:
area <-c("BRAZIL", "MEXICO") 


tiffes <- file.path(
  here("cropped_raster_data"),
  list.files(
    here("cropped_raster_data"),
    pattern = "MEXICO,*\\.tif$"
  )
)
tiffes <- tiffes[c(1,11,15,18,22)] #just keep pollination - HAB,
#tiffes <- tiffes[-2]
```

## 4.2 Normalization and Combination of Ecosystem Service Provision Gains 

The target layers were normalized and combined into a single raster. This raster serves as a proxy for total ES provision, assuming all services are equally valuable. This approach allows for the identification of the spatial distribution of potential ecosystem service gains. Nature Access was excluded from this combined layer because its pixel values represent the number of people who gain access to each pixel, which could result in counting the same people multiple times if multiple pixels are restored near each other.

```{r apply mask AOI AP, eval=FALSE, include=FALSE}

# Step 1: Extract file names, product names, and country names
file_names <- basename(tiffes)  # Extract file names from paths

# Extract product names and country names
product_names <- sub("_[A-Z]+\\.tif$", "", file_names)  # Remove "_COUNTRY.tif" to get product name
country_names <- sub(".*_(.*?)\\.tif$", "\\1", file_names)  # Extract country name from file name

# Step 2: Create a dataframe to organize the information
file_info <- data.frame(
  FilePath = tiffes,
  Product = product_names,
  Country = country_names,
  stringsAsFactors = FALSE
)

# Step 3: Sort the dataframe by Country first, then by Product
file_info <- file_info %>%
  arrange(Country, Product)

# Step 4: Extract the sorted file paths
tiffes <- file_info$FilePath

baseES <- lapply(tiffes, rast)

tmp <- crop(tmp, baseES[[1]])
 

baseES <- lapply(baseES, function(r) {
  if (!compareGeom(r, tmp, stopOnError = FALSE)) {
    message("Aligning raster: ", names(r))
    resample(r, tmp, method = "bilinear")
    } else {
      message("Raster already aligned: ", names(r))
      r
      }
    })
#### This is only necessary if we are working with a subset of the area, need to extract by a smaller polygon. Right now we only need that for Espirito Santo
# poly <- st_read(here("Interventions", "Brazil_int_areas", "Espirito_Santo_Albers.shp"))
# pol_wgs <- st_transform(poly, crs=crs(baseES[[1]]))
# serv_bra <- lapply(baseES, function(r){
#   r <- crop(r,pol_wgs)
#   r <- mask(r, pol_wgs)
#   }) 
# 
# # ust assign this vrariable name, sowe don't need to edit the whole thing 
serv_bra <- baseES

serv_bra <- lapply(serv_bra,normalize_raster)
serv_bra <- do.call(c, serv_bra)

tmp <- mask(tmp, pol_wgs)
tmp <- trim(tmp)

serv_bra  <- merge(serv_bra , tmp)
    
    # Sum the layers of the merged raster
    serv_bra  <- app(serv_bra, sum)

writeRaster(serv_bra, paste0(here("restoration_combined"),'/', 'BRA_ES_sum2.tif'))
```


## 4.3 Optimization to Identify Priority Areas

Pixels representing the highest aggregated ES gains were extracted from the combined raster, totaling 30,200 ha, to identify priority areas for restoration. This optimization process represents a second run of the analysis and considers the combined value of Coastal Protection, Nitrogen Export, Sediment Retention, and Pollination.

## 4.4 Sampling and Synthesis of Results
Stratified random sampling was performed on the optimized raster to estimate the expected restoration gains, assuming randomly selected pixels are extracted from the potential restoration areas. This initial assessment provides insight into potential ES gains associated with the restoration efforts.

```{r sampling target areas brazil, eval=FALSE, include=FALSE}
serv_1 <- rast(here("Interventions", "Brazil_intervention",'/', 'serv_BRAZIL.tif'))
rest_m <- rast(here('Interventions', 'Brazil_intervention', 'SS_griscom.tif'))
rcl <- matrix(c(
  -Inf, 0, 0,  # Any value from -Infinity to 0 remains 0
  0, Inf, 1   # Any value from 0 to Infinity becomes 1
), ncol = 3, byrow = TRUE)
rest_m <- classify(rest_m, rcl)

rest_m <-project(rest_m, serv_1)
rest_m <- terra::resample(rest_m, serv_1)
serv_1 <- mask(serv_1,rest_m, maskvalues=0)
#Calculate the number of pixels needed for 30,000 hectares
pixel_area <- 30 * 30  # Area of a single pixel in square meters (30m resolution)
hectare_area <- 10000  # Area of one hectare in square meters
pixels_needed <- round((30200 * hectare_area) / pixel_area)

# Number of repetitions
n_repetitions <- 30
# Function to perform the sampling and calculations
sample_and_calculate <- function(i, raster, pixels_needed) {
  # Sample pixels and directly extract values (without na.rm)
  sample_values <- spatSample(raster, size = pixels_needed, 
                              method = "random", 
                              na.rm = FALSE,  
                              as.points = FALSE, 
                              xy = FALSE,
                              values = TRUE) 

  # Remove rows where ALL values are NA
  sample_values <- sample_values[rowSums(is.na(sample_values)) != ncol(sample_values), ]

  # If not enough samples after removing NAs, resample
  if (nrow(sample_values) < pixels_needed) {
    sample_values <- rbind(
      sample_values,
      spatSample(raster, size = pixels_needed - nrow(sample_values),
                 method = "random", na.rm = TRUE, 
                 as.points = FALSE, xy = FALSE, values = TRUE)
    )
  }

  # Calculate summary statistics
  band_stats <- apply(sample_values, 2, function(x) { 
    mean_val <- mean(x)
    sd_val <- sd(x)
    n_val <- length(x)
    se_val <- sd_val / sqrt(n_val)
    margin_error <- qt(0.975, df = n_val - 1) * se_val
    lower_ci <- mean_val - margin_error
    upper_ci <- mean_val + margin_error
    return(c(mean = mean_val, lower_ci = lower_ci, upper_ci = upper_ci))
  })

  band_stats_df <- as.data.frame(t(band_stats))
  band_stats_df$repetition <- i

  # Calculate sum of pixel values for each band
  band_sums <- colSums(sample_values) 
  band_stats_df$sum <- band_sums

  return(band_stats_df)
}

# Using mclapply (parallel processing)
num_cores <- 15 
results_list <- mclapply(1:n_repetitions, sample_and_calculate, 
                         raster = serv_1, 
                         pixels_needed = pixels_needed,
                         mc.cores = num_cores) 

results_list <- lapply(results_list, function(df){
  df <- df %>% mutate(band=rownames(df))
})
# Combine all results into a single data frame
all_results <- as_tibble(do.call(rbind, results_list))


# Add new columns with the service names and units.
all_results <- all_results %>%
  mutate(Service = case_when(
    band == "cv_habitat_value_Sc3v1-ESAmod2_v2_md5_64082b" ~ "Coastal Protection",
    band == "nature_access_diff_Sc3v1_PNVnoag-esa2020" ~ "Nature Access",
    band == "nitrogen_ESAmod2-Sc3v1_md5_024a36" ~ "Nitrogen Export",
    band == "pollination_ppl_fed_on_ag_10s_Sc3v1_PNVnoag-esa2020_md5_405c88" ~ "Pollination",
    band == "pollination_ppl_fed_on_hab_Sc3v1_PNV_no_ag-ESA_md5_576790" ~ "Pollination (people fed on Hab)",
    band == "sediment_ESAmod2-Sc3v1_md5_149078" ~ "Sediment Export",
    # ... add more cases for other bands ...
    TRUE ~ band  # Keep the original band name if no match
  ))

all_results <- all_results %>%
  mutate(units = case_when(
    band == "cv_habitat_value_Sc3v1-ESAmod2_v2_md5_64082b" ~ "Risk Reduction Index",
    band == "nature_access_diff_Sc3v1_PNVnoag-esa2020" ~ "People within 1 hour",
    band == "nitrogen_ESAmod2-Sc3v1_md5_024a36" ~ "Nitrogen Export (kg/ha/year)",
    band == "pollination_ppl_fed_on_ag_10s_Sc3v1_PNVnoag-esa2020_md5_405c88" ~ "Pollination (equivalent people fed)",
    band == "pollination_ppl_fed_on_hab_Sc3v1_PNV_no_ag-ESA_md5_576790" ~ "Pollination (people fed on hab)",
    band == "sediment_ESAmod2-Sc3v1_md5_149078" ~ "Sediment Export (ton/kg/year)",
    # ... add more cases for other bands ...
    TRUE ~ band  # Keep the original band name if no match
  ))

all_results <- all_results %>%
  mutate(color = case_when(
    band == "cv_habitat_value_Sc3v1-ESAmod2_v2_md5_64082b" ~ "#7a0177",
    band == "nature_access_diff_Sc3v1_PNVnoag-esa2020" ~ "#A57C00",
    band == "nitrogen_ESAmod2-Sc3v1_md5_024a36" ~ "#2c944c",
    band == "pollination_ppl_fed_on_ag_10s_Sc3v1_PNVnoag-esa2020_md5_405c88" ~ "#dd1c77",
    band == "pollination_ppl_fed_on_hab_Sc3v1_PNV_no_ag-ESA_md5_576790" ~ "#dd1b56",
    band == "sediment_ESAmod2-Sc3v1_md5_149078" ~ "#08306b",
    # ... add more cases for other bands ...
    TRUE ~ band  # Keep the original band name if no match
  ))
save(all_results, file= here("Interventions", "Brazil_intervention", "all_res_bra.RData"))
```

### 4.5 Result Visualization

```{r plot brazil outpus, echo=FALSE}
load(here("Interventions", "Brazil_intervention", "all_res_bra.RData"))
df <-all_results %>%  filter(band!="nature_access_diff_Sc3v1_PNVnoag-esa2020") %>% filter(band!= "pollination_ppl_fed_on_ag_10s_Sc3v1_PNVnoag-esa2020_md5_405c88")
# Assuming your 'all_results' data frame has the columns 'Service', 'units', and 'color'
# Assuming your 'all_results' data frame has the columns 'Service', 'units', and 'color'

# Generate the ggplot object
plot <- ggplot(df, aes(y = sum, fill = color)) +
  geom_boxplot() +
  labs(title = str_wrap("Total estimated service change in units for the target intervention area - Espirito Santo", width = 50), 
       y = "Total Sum Value") +
  theme_bw() +
  theme(
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank(),
    axis.title.x = element_blank(),
    strip.background = element_blank(),
    strip.text = element_text(face = "bold"),
    legend.position = "none"  # Remove legend since color is already mapped
  ) +
  scale_fill_identity() + 
  facet_wrap(~ Service, scales = "free_y", labeller = labeller(Service = label_wrap_gen(width = 10))) +  
  scale_y_continuous(labels = function(x) {
    if (max(x, na.rm = TRUE) > 100000) {
      paste0(format(x / 1000, big.mark = ".", decimal.mark = ","), "k")
    } else {
      format(x, big.mark = ".", decimal.mark = ",")
    }
  }) 
plot
```


# 5 Yucatan

```{r synthesis data Surendra}
###############################################################################
# Script:    process_ES_rasters.R
# Author:    Jeronimo Rodriguez E.
# Date:      2025-01-08
# Purpose:   Read and align multiple SpatRasters, convert them to binary masks,
#            merge and sum layers, then project and normalize the result.
#            Finally, write outputs at 30 m and 100 m resolutions (EPSG:32616).
###############################################################################

# Load required packages
library(terra)
library(here)

# -----------------------------------------------------------------------------
# 1. Load and Inspect Data
# -----------------------------------------------------------------------------
# 'tiffes' is a character vector of file paths (all .tif files).
# Each file is read into a SpatRaster and stored in a list.

baseES <- lapply(tiffes, rast)
# 'tmp' is  another SpatRaster used as the template for alignment.
# Make sure 'tmp' is loaded or defined beforehand.

# Crop 'tmp' to align it with the first raster in 'baseES'
# (This ensures the extents match as closely as possible.)
tmp <- crop(tmp, baseES[[1]])

# -----------------------------------------------------------------------------
# 2. Align All Rasters to the Reference 'tmp'
# -----------------------------------------------------------------------------
# Compare geometry with 'tmp': if different, resample; otherwise keep as-is.
baseES <- lapply(baseES, function(r) {
  if (!compareGeom(r, tmp, stopOnError = FALSE)) {
    message("Aligning raster: ", names(r))
    resample(r, tmp, method = "bilinear")
  } else {
    message("Raster already aligned: ", names(r))
    r
  }
})

# -----------------------------------------------------------------------------
# 3. Convert to Binary Masks (Values > 0 => 1, Otherwise => 0)
# -----------------------------------------------------------------------------
baseES <- lapply(baseES, function(x) ifel(x > 0, 1, 0))

# Create an additional "background" raster by substituting 1 -> 0 
# in one of the existing layers (baseES[[2]] in this case).
tmp <- subst(baseES[[2]], from = 1, to = 0)

# Combine all SpatRasters into a single multi-layer SpatRaster
baseES <- do.call(c, baseES)

# -----------------------------------------------------------------------------
# 4. Trim and Crop Extent
# -----------------------------------------------------------------------------
# Use the 3rd layer to define a minimal bounding extent, then crop.
ext <- trim(baseES[[3]])             # determines the bounding box
baseES <- crop(baseES, ext)          # crop the entire stack to this extent

# Further crop and mask by 'tmp' (the zero-background)
baseES <- crop(baseES, tmp)
baseES <- mask(baseES, tmp)
tmp <- crop(tmp, baseES)             # ensure 'tmp' matches final extent

# -----------------------------------------------------------------------------
# 5. Additional Classification / Background Handling
# -----------------------------------------------------------------------------
# Remove the 2nd layer from 'baseES' for further processing
tt <- baseES[[-2]]

# Create a classification matrix:
#   0 to Inf => 0
# This might invert or zero out certain areas. (Double-check your logic here!)
rcl <- matrix(c(
  0, Inf, 0
), ncol = 3, byrow = TRUE)

# Apply classification to each layer in 'tt'
tt <- lapply(tt, function(r) classify(r, rcl))

# Merge all layers into one SpatRaster
tt <- do.call(merge, tt)

# Mask the original stack by 'tt'
baseES <- mask(baseES, tt)

# Merge the masked 'baseES' with 'tt'
baseES <- merge(baseES, tt)

# -----------------------------------------------------------------------------
# 6. Sum Layers, Project, and Round
# -----------------------------------------------------------------------------
# Sum all layers in 'baseES'
serv_bra <- app(baseES, sum)

# Reproject to EPSG:32616 at 30 m resolution (multi-threaded if available)
serv_bra <- project(serv_bra, "EPSG:32616", res = 30, threads = 30)

# Round values to integers
serv_bra <- round(serv_bra, digits = 0)

# Write the 30 m result
writeRaster(
  serv_bra,
  paste0(here("Interventions", "Mexico_int_areas"), "/", "ES_occurrence.tif"),
  overwrite = TRUE
)

# -----------------------------------------------------------------------------
# 7. Normalize the 30 m Raster
# -----------------------------------------------------------------------------
# 'normalize_raster()' is assumed to be a custom function that scales
# values (e.g., 0–1 or min–max normalization). Make sure it's defined/loaded.
serv_norm <- normalize_raster(serv_bra)

# Write the normalized 30 m output
writeRaster(
  serv_norm,
  paste0(here("Interventions", "Mexico_int_areas"), "/", "ES_occ_norm_30m.tif"),
  overwrite = TRUE
)

# -----------------------------------------------------------------------------
# 8. Resample to 100 m Resolution
# -----------------------------------------------------------------------------
# Create a 100 m SpatRaster template from 'serv_norm'
r100_tmp <- rast(serv_norm)
res(r100_tmp) <- 100  # set desired 100 m resolution

# Resample (near) for categorical or masked data
r100 <- resample(serv_norm, r100_tmp, method = "near")

# Write the normalized 100 m output
writeRaster(
  r100,
  paste0(here("Interventions", "Mexico_int_areas"), "/", "ES_occ_norm_100m.tif"),
  overwrite = TRUE
)

###############################################################################
# End of script
###############################################################################


```

------------------------------------------------------------------------


References
Bivand, R. S., Pebesma, E. J., & Gómez-Rubio, V. (2013). Applied
spatial data analysis with R (2nd ed.). Springer.
Cochran, W. G. (1977). Sampling techniques (3rd ed.). John Wiley & Sons.
Lohr, S. L. (2010). Sampling: Design and analysis (2nd ed.).
Brooks/Cole. 1\
Natural Capital Project (2024). InVEST 0.0. Stanford University, University of Minnesota, Chinese Academy of Sciences, The Nature Conservancy, World Wildlife Fund, Stockholm Resilience Centre and the Royal Swedish Academy of Sciences. *https://naturalcapitalproject.stanford.edu/software/invest*
