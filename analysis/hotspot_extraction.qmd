---
title: "Hotspot Extraction"
format: html
editor: visual
---

```{r setup, message=FALSE, warning=FALSE}
#| label: setup
#| message: false
#| warning: false

# Core tidy + spatial
library(dplyr)
library(tidyr)
library(purrr)
library(stringr)
library(forcats)
library(ggplot2)
library(scales)
library(sf)
library(terra)
library(exactextractr)

# Plot helpers
library(viridisLite)
library(ggnewscale)
library(ragg)

# Dev/project helpers
library(devtools)   # for load_all()

# Optional viewers (enable only if you use them)
# library(httpgd)
# library(leaflet)
# library(htmltools)

# ---- Global options / performance ---------------------------------------
options(dplyr.summarise.inform = FALSE)
sf::sf_use_s2(TRUE)
Sys.setenv(GDAL_NUM_THREADS = "ALL_CPUS", PROJ_NETWORK = "ON")
terraOptions(tempdir = file.path(tempdir(), "terra_tmp"))

set.seed(1)

# ---- Project wiring ------------------------------------------------------
# Load package-style functions from R/ (if this is a package-ish repo)
devtools::load_all(quiet = TRUE)

# Paths helper (set GLOBAL_NCP_DATA in ~/.Renviron first)
source("../R/paths.R")

# ---- Python (enable when needed) ----------------------------------------
# library(reticulate)
# use_virtualenv("/home/jeronimo/venvs/coastal_snap_env", required = TRUE)

```

# Append countryand biome data to the sytnesiss vector for subregional analysis 


```{r load country gpkg, eval = FALSE}
# ---- Purpose --------------------------------------------------------------

# Attach country & biome attributes to the 10 km grid (sf_f) so we can group

# hotspots by subregions (income_grp, region_wb, BIOME, etc.).

# NOTE: We’ll test/execute this later once paths are finalized. For now,

# this chunk documents the exact steps and makes paths configurable.

# ---- Preconditions --------------------------------------------------------

# 1) sf_f (grid polygons) already in memory with at least: fid, c_fid, geometry

# 2) paths.R is sourced earlier, providing a function data_dir() that points to

# ~/data/global_ncp (or your chosen location via GLOBAL_NCP_DATA env var).

stopifnot(inherits(sf_f, "sf"))
stopifnot(all(c("fid", "c_fid") %in% names(sf_f)))

# Optional: make polygon ops consistent/correct on the sphere

# options(sf_use_s2 = TRUE)

# ---- Inputs ---------------------------------------------------------------

ct_path  <- file.path(data_dir(), "vectors", "cartographic_ee_ee_r264_correspondence.gpkg")
bio_path <- file.path(data_dir(), "vectors", "Biome.gpkg")

stopifnot(file.exists(ct_path), file.exists(bio_path))

ct <- sf::st_read(ct_path, quiet = TRUE) |>
dplyr::select(id, ee_r264_name, iso3, continent, income_grp, region_un, region_wb, subregion)

biomes <- sf::st_read(bio_path, quiet = TRUE) |>
dplyr::select(BIOME, WWF_biome)

# ---- CRS harmonization ----------------------------------------------------

crs_grid <- sf::st_crs(sf_f)
if (!sf::st_crs(ct) == crs_grid)     ct     <- sf::st_transform(ct, crs_grid)
if (!sf::st_crs(biomes) == crs_grid) biomes <- sf::st_transform(biomes, crs_grid)

# ---- Lightweight template (keeps geometry) --------------------------------

sf_template <- sf_f |>
dplyr::select(fid, c_fid)  # <— only keys + geometry

# ---- Representative point per cell (faster/robust attr join) --------------

# Prefer point-on-surface over centroid for oddly-shaped cells.

pts <- sf::st_point_on_surface(sf_template)

# ---- Spatial joins --------------------------------------------------------

# If you ever need "nearest polygon" instead of "within", use:

# pts_ct <- sf::st_join(pts, ct, join = st_nearest_feature)

pts_ct    <- sf::st_join(pts, ct,     left = TRUE)
pts_biome <- sf::st_join(pts, biomes, left = TRUE)

# ---- Drop geometry and merge attrs by fid ---------------------------------

pts_ctdf <- sf::st_drop_geometry(pts_ct)
pts_bmdf <- sf::st_drop_geometry(pts_biome)

out_attrs <- pts_ctdf |>
dplyr::left_join(pts_bmdf, by = "fid", suffix = c("", "_biome"))

# Sanity: enforce uniqueness by fid (defensive; should already be 1:1)

if (anyDuplicated(out_attrs$fid)) {
out_attrs <- out_attrs |>
dplyr::arrange(fid) |>
dplyr::distinct(fid, .keep_all = TRUE)
}

# ---- Bring attributes back to the grid ------------------------------------

sf_f_joined <- sf_f |>
dplyr::left_join(out_attrs, by = "fid")

stopifnot(nrow(sf_f_joined) == nrow(sf_f), inherits(sf_f_joined, "sf"))

# ---- Output (idempotent write) --------------------------------------------

out_gpkg <- file.path(data_dir(), "processed", "10k_change_calc.gpkg")
dir.create(dirname(out_gpkg), recursive = TRUE, showWarnings = FALSE)
if (file.exists(out_gpkg)) file.remove(out_gpkg)
sf::st_write(sf_f_joined, out_gpkg, quiet = TRUE)

# TODO (later): benchmark polygon-on-polygon join for QA; verify sample cells

# visually in QGIS; confirm iso3/income_grp/BIOME coverage stats.
```

####################### START HERE

# 1 Hotspot Extraction

## 1.1 Prepare Data for Analysis

The spatial objects with the anecessary  attributes are loaded and reformatted for analysis and chart preparation, that requires to **pivot** the input vector files into the long format, with one row per service/cell combination.

```{r pivot}
#| eval: true
#| include: true
lyr_sf <- st_layers("~/data/global_ncp/processed/10k_change_calc.gpkg")
sf_f <- st_read("~/data/global_ncp/processed/10k_change_calc.gpkg") 
# Read change data (finqal summaries) Eventually herer i will need to set up the correct viariabñle names here!  
#add fid a
sf_f$fid <- seq_len(nrow(sf_f)) 
plt <- st_drop_geometry(sf_f)

# get the vars to perform analysis (all that are not "chg"). These are used or the group/subregionaal analyisis and to compare extract the SK testsby demographic/socioeocnomic variable4
socio_vars <- names(plt)[
  names(plt) != c("fid", "c_fid") & 
  !grepl("chg$", names(plt))
]

# Pivot all columns that contain pct_ch, keeping other relevant vars


# socio variables to carry through (adjust to your set) There should b a smarter /more autm,ated way to do this!
socio_vars <- c(
  "GHS_BUILT_S_E2020_mean",
  "fields_mehrabi_2017_mean",
  "hdi_raster_predictions_2020_mean",
  "rast_adm1_gini_disp_2020_mean",
  "rast_gdpTot_1990_2020_30arcsec_2020_sum",
  "GHS_POP_E2020_GLOBE_sum",
  "GlobPOP_Count_30arc_2020_sum",
  "iso3","continent","income_grp","region_un","region_wb","subregion","BIOME","WWF_biome"
)

plt_long <- plt %>%
  # 1) Long pivot on *_abs_chg / *_pct_chg columns
  pivot_longer(
    cols = matches("_(abs|pct)_chg$"),
    names_to = c("service", "chg_type"),
    names_pattern = "^(.*)_(abs|pct)_chg$",
    values_to = "chg_value"
  ) %>%
  # OPTIONAL: normalize service labels if you want to drop a trailing "_mean"
  mutate(service = str_remove(service, "_mean$")) %>%
  # 2) Go wide to get two columns: abs_chg, pct_chg
  pivot_wider(
    names_from = chg_type,
    values_from = chg_value,
    names_vary = "slowest"
  ) %>%
  # after pivot_wider we have columns "abs" and "pct" -> rename
  rename(abs_chg = abs, pct_chg = pct) %>%
  # 3) Reorder/select the columns you need
  select(
    fid, c_fid, service, abs_chg, pct_chg,
    any_of(socio_vars)
  ) %>%
  # 4) Filters (tweak as neededs)
  filter(!is.na(c_fid), !is.na(iso3), !is.na(BIOME)) %>%
  filter(!(is.infinite(pct_chg) | is.infinite(abs_chg))) %>%
  # keep rows where at least one metric exists
  filter(!is.na(pct_chg) | !is.na(abs_chg))

# this should be updated on an earlier stage when i extract the data, not here). I am not sure how to deal with this. But enterimghthe names manually isnot very prasctival, too hardcoded and limits flexibility. 

  plt_long <- plt_long %>% mutate(service = case_when(
   service == "sed_export" ~ "Sed_export",
   service == "n_export" ~ "N_export",
   service == "n_retention" ~ "N_retention",
   service == "nature_access" ~ "Nature_Access",
   service == "pollination" ~ "Pollination",
   service == "usle" ~ "USLE",
   service == "n_ret_ratio" ~ "N_Ret_Ratio",
   service == "sed_ret_ratio" ~ "Sed_Ret_Ratio",
   service == "Rt_ratio" ~ "C_Risk_Red_Ratio",
   service == "Rt" ~ "C_Risk",
   service == "Rt_service" ~ "C_Prot_service",
   TRUE ~ service
   ))
  
  

# Set service levels one single time and for all. Don't drop some variables here, filter afterwards, it can be difficult/annoying to recover!!!
service_levels <- c("Nature_Access","N_export","N_retention", "N_Ret_Ratio", "Sed_export", "USLE", "Sed_Ret_Ratio", "Rt_nohab","C_Risk","C_Prot_service", "C_Risk_Red_Ratio", "Pollination") 

```


# Wrapper: extract hotpots per group 


```{r extract hotposts_group}

# group_cols is a character vector like c("income_grp") or c("region_wb")
extract_hotspots_by <- function(df_long, group_cols,
                                loss, gain,
                                value_col = "abs_chg",
                                pct_cutoff = 0.05,
                                threshold_mode = "percent") {

  stopifnot(all(group_cols %in% names(df_long)))

  df_long %>%
    select(fid, service, all_of(group_cols), all_of(value_col), c_fid) %>%
    rename(.value = {{ value_col }}) %>%  # standardize name for mapping
    nest(data = -all_of(group_cols)) %>%
    mutate(
      res = map(
        data,
        ~ extract_hotspots(
            df            = rename(.x, !!value_col := .value),
            value_col     = value_col,
            pct_cutoff    = pct_cutoff,
            threshold_mode= threshold_mode,
            rule_mode     = "vectors",
            loss_services = loss,
            gain_services = gain,
            id_cols       = c("c_fid")      # carry c_fid to summaries
          )
      )
    ) %>%
    transmute(
      !!!syms(group_cols),
      hotspots_df     = map(res, "hotspots_df"),
      non_hotspots_df = map(res, "non_hotspots_df"),
      summary_df      = map(res, "summary_df"),
      binary_matrix   = map(res, "binary_matrix")
    )
}


```

```{r run wrapper}

loss <- c("Nature_Access","Pollination","N_Ret_Ratio","Sed_Ret_Ratio","C_Risk_Red_Ratio")
gain <- c("Sed_export","N_export","C_Risk")

# ---- Config you already used ----
focus_services <- c(
  "Nature_Access","N_export","N_retention","Sed_export",
  "N_Ret_Ratio","Sed_Ret_Ratio","C_Risk","C_Risk_Red_Ratio",
  "Pollination","USLE"
)
plot_n <- 300000L

# ---- Generic runner for a single grouping column ----
run_hotspot_plots_by <- function(group_col, out_stub) {
  message("==> Running plots by: ", group_col)

  # 1) run wrapper once for ABS and once for PCT
  by_abs <- extract_hotspots_by(plt_long, group_col, loss, gain, value_col = "abs_chg")
  by_pct <- extract_hotspots_by(plt_long, group_col, loss, gain, value_col = "pct_chg")

  # 2) tidy value tables (fid × service × group)
  
    transmute(!!group_col := .data[[group_col]],
              vals = map(hotspots_df, ~ dplyr::select(.x, fid, service, abs_chg))) %>%
    unnest(vals)

  pct_vals <- by_pct %>%
    transmute(!!group_col := .data[[group_col]],
              vals = map(hotspots_df, ~ dplyr::select(.x, fid, service, pct_chg))) %>%
    unnest(vals)

  # 3) join so each (fid, service,group) has abs &/or pct
  vals_joined <- full_join(
    abs_vals, pct_vals,
    by = c(group_col, "fid", "service")
  )

  # 4) focus services + sample for plotting speed
  vals_sample <- vals_joined %>%
    filter(service %in% focus_services) %>%
    filter(!is.na(.data[[group_col]])) %>%
    { if (nrow(.) > plot_n) slice_sample(., n = plot_n) else . } %>%
    mutate(!!group_col := as.factor(.data[[group_col]]))

  # 5a) ABS plot (mirror of your income plot)
  p_abs <- ggplot(vals_sample, aes(x = abs_chg, y = .data[[group_col]])) +
    geom_violin(trim = TRUE, scale = "width") +
    geom_boxplot(width = 0.15, outlier.alpha = 0.15) +
    coord_flip() +
    facet_wrap(~ service, scales = "free_y") +
    labs(title = paste0("Absolute change in hotspots by ", group_col),
         x = NULL, y = "Absolute change (service units)") +
    theme_minimal(base_size = 11) +
    theme(axis.text.x = element_text(size = 8, angle = 45, hjust = 1))

  # 5b) PCT plot (identical style)
  p_pct <- ggplot(vals_sample %>% tidyr::drop_na(pct_chg),
                  aes(x = pct_chg, y = .data[[group_col]])) +
    geom_violin(trim = TRUE, scale = "width") +
    geom_boxplot(width = 0.15, outlier.alpha = 0.15) +
    coord_flip() +
    facet_wrap(~ service, scales = "free_y") +
    labs(title = paste0("Percent change in hotspots by ", group_col),
         x = NULL, y = "Percent change (%)") +
    theme_minimal(base_size = 11) +
    theme(axis.text.x = element_text(size = 8, angle = 45, hjust = 1))

  # 6) save
  dir.create("/home/jeronimo/OneDrive/global_NCP/outputs/plots", recursive = TRUE, showWarnings = FALSE)
  ggsave(file.path("/home/jeronimo/OneDrive/global_NCP/outputs/plots",
                   paste0(out_stub, "_abs_change_violins.png")),
         p_abs, width = 12, height = 8, dpi = 300)
  ggsave(file.path("/home/jeronimo/OneDrive/global_NCP/outputs/plots",
                   paste0(out_stub, "_pct_change_violins.png")),
         p_pct, width = 12, height = 8, dpi = 300)

  invisible(list(abs_plot = p_abs, pct_plot = p_pct))
}

# ---- Run for each grouping ----
run_hotspot_plots_by("region_wb", "regionwb")
run_hotspot_plots_by("BIOME",     "biome")
run_hotspot_plots_by("continent", "continent")
run_hotspot_plots_by("region_un", "regionun")
run_hotspot_plots_by("income_grp", "incomegrp")

```
