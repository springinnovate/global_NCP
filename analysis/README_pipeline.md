# Executive Summary

> **Status Note:** This pipeline is designed for the **10 km grid** approach. Future analyses may pivot to direct raster summarization (see `zonal_stats_toolkit`).

::: note
**What is this pipeline?**

This workflow brings together global data on ecosystem services, land cover, and people to help us understand where nature is changing, who is affected, and where action is most needed. It combines data processing, change detection, and hotspot mapping in a way that is transparent and reproducible.
:::

**Why does it matter?**

By identifying areas of rapid change or high importance, this pipeline supports better decision-making for conservation, policy, and sustainable development.

# Global NCP Analysis Pipeline

## Glossary

- **AOO**: Area of Occupancy. A standard 10 km grid used for spatial analysis.
- **ES**: Ecosystem Services. Benefits people obtain from nature (e.g., pollination, water quality).
- **GPKG**: GeoPackage. A file format for storing geographic data.
- **Hotspot**: A grid cell or area showing unusually high or low change in ecosystem services.
- **Zonal statistics**: Calculations that summarize raster data (like satellite images) within the boundaries of polygons (like grid cells).
- **Beneficiary**: People or groups who benefit from ecosystem services.
- **KS analysis**: Kolmogorov-Smirnov test, a statistical method to compare distributions.
- **Raster**: A grid of cells (pixels), each with a value representing information such as land cover or ES.
- **Polygon**: A shape representing an area on a map (e.g., a grid cell, country, or region).
- **Change detection**: Identifying how something (like ES) has changed over time.

## Conceptual Workflow (Step-by-Step)

1. **Prepare the grid and input data**: Start with a global 10 km grid and gather all relevant data layers (nature, people, services).
2. **Summarize data by grid cell**: Use zonal statistics to calculate values for each cell.
3. **Calculate change**: Compare values between years to see where and how much things have changed.
4. **Identify hotspots**: Flag cells with the biggest changes (positive or negative) for each service.
5. **Combine and analyze**: Group hotspots, link to beneficiaries, and run statistical tests.
6. **Visualize and interpret**: Create maps, charts, and summaries to communicate results.

::: tip
For a technical deep dive, see the main README.md and the Quarto notebooks in the analysis/ folder.
:::

## TODO: Recommended Visuals and Flowcharts

- Conceptual diagram of the pipeline (from data to decision)
- Example map of hotspots
- Flowchart of data processing steps
- Before/after change maps for a key service
- Infographic showing how beneficiaries are linked to ES change

# Global NCP Analysis Pipeline

## Pipeline Overview

This workflow synthesizes the zonal summary statistics generated by the Python pipeline into a single, unified database. It calculates bi-temporal change, identifies hotspots, and prepares the data for statistical analysis.

- Inputs: IUCN AOO 10 km equal-area grid (land-only, with admin/biome attributes), ES rasters (1992/2020), coastal protection points (rasterized), and beneficiary rasters.
- Data roots: raw data in `/home/jeronimo/data/global_ncp/raw`; synth outputs in `/home/jeronimo/data/global_ncp/interim`; consolidated outputs and hotspots in `/home/jeronimo/data/global_ncp/processed`.
- Steps: rasterize coastal points → extract zonal stats (mean/sum per service/year via `summary_pipeline_landgrid.py` in Docker) → wrap dateline + move `10k_grid_synth_*` to `interim/` → consolidate (services+beneficiaries+coastal) → compute abs/pct change → hotspot extraction → KS analysis.
- Coastal protection: summarize Rt and Rt_ratio per grid cell (optional Rt_serv_ch for comparison).
- Outputs: `10k_grid_synth_*` in interim; consolidated `10k_change_calc.gpkg` in processed (intermediate `10k_grid_ES_change_benef.gpkg` is optional); hotspot GPKGs and tables.
- TODO: add a `keep_fields` option to the summary pipeline YAMLs so we can preserve only needed grid attributes (instead of all).
- TODO: Investigate correlation between large increases in valid pixel counts (QAQC mismatches >5%) and land use change (e.g., reclamation, drying water bodies).

## Data Processing Pipeline

### Zonal Statistics for Gridded ES Services

Geosharding-based pipeline to extract zonal statistics (mean or sum, depending on the service) from modeled global ES raster layers for two years (1992-2020) to the 10 km grid (or any poygon vector file). Values are labeled and appended as new columns in an output vector dataset (gpkg)

### Coastal Protection Aggregation

This dataset comes originally as a vector included in this analysis three key variables for each year: *convert into math notation*

-   Rt: Actual Risk Level
-   Rt_nohab: Potential Risk Level if no ecosystem (expected to remain constant over time, but necessary to calculate the next ones)
-   Rt_nohab - Rt = Rt_service: This difference is the actual value of the service provided (the potential-the observed Risk) = Provided service
-   (Rt_nohab-Rt)/Rt: Coastal risk reduction ratio

Computed mean and max per grid cell for each coastal protection metric.

### Bi-temporal Change Calculation

Applied compute_change() function to derive absolute and percentage changes for all variables, using consistent naming conventions (\_abs_chg, \_pct_chg). Percentage change uses the earliest year as the baseline, so zero baselines yield Inf/NaN and should be handled downstream.

### Reshaping Data for Hotspot Detection

Converted the dataset to long format (plt_long) with columns: fid, c_fid, service, and pct_chg.

### Hotspot Identification

Defined loss/damage services and gain services.

Identified hotspots as grid cells in the bottom 5% (losses) or top 5% (gains) per service. The developed function can extract any threshold, and the inverses. It is also posssible to set the variables for which an increase is an improvement (goods) to which an increase is a deterioration (damage), and set groups of variables, aka *combos* to count the number of variables for which a cell is a hotspot. ( Binary columns explicitly indicating whether a cell is a hotpot for each variable analized is included, as well as columns indicating the type of hotpot (damage/service loss).

### Hotspot Grouping into Service Combos

Created combos for aggregated hotspot counts:

combo_1 = c("Nature_Access","Pollination","N_export", "Sed_export", "C_Risk"), combo_2 = c("Nature_Access","Pollination", "N_Ret_Ratio", "Sed_Ret_Ratio", "C_Risk_Red_Ratio")

Calculated counts per combo and total hotspot count.

### Final Integration and Output

Generated binary columns (0/1) per service for hotspot presence.

Joined hotspot attributes back to the 10 km grid sf object.

Produced final geopackage file with:

Per-service hotspot flags.

Total hotspot count.

Counts for each combo

A column listing all hotspot services per grid cell.

### Outputs

Final gpkg with the summary stats for each year for all variables plus socio economic data. Final gpkg object containing all hotspot-related attributes for each 10 km grid cell.

Map outputs prepared in Qis (one for the hotspots for each variable) and for the *combos*

Flexible structure allows filtering for losses only, per-service mapping, or aggregated combo-based analyses.