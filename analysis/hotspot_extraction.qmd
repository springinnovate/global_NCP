---
title: "Hotspot Extraction"
format: html
editor: visual
---

```{r setup, message=FALSE, warning=FALSE}
library(terra)
library(sf)
library(dplyr)
library(ggplot2)
library(tidyr)
library(purrr)
library(diffeR)
library(here)
library(stringr)
library(tidytext)
library(rlang)
library(tidyr)
library(forcats)
library(scales)
library(RColorBrewer)
library(htmltools)
library(leaflet)
library(devtools)
library(reticulate)
library(exactextractr)
library(httpgd)
library(ggnewscale)   # allows multiple fill scales
library(viridisLite)
library(ragg)
load_all()

#source the helper functions
# set venv focr Python
use_virtualenv("/home/jeronimo/venvs/coastal_snap_env", required = TRUE)
#inpath <- '/Users/rodriguez/Library/CloudStorage/OneDrive-WorldWildlifeFund,Inc/global_NCP/output_data'

```

# Load country data

Add the key columns to identify the countries and get the groupings done 
(already did this, but we need to be sure it is working correctly). All thjoinms performed here are based either on the c_fid or in fid or are spatial joins, we need to make sure it is crrect. I don´t remember exactly how we did it, and will have to re do this part, but we had the sf dataset already with the countr id and fid. It was some work and i should have documented that better , but neverrtheless, you get theidea) 

```{r load country gpkg}

# (0) Preconditions: `sf_f` is already in memory and cleaned
#     It must contain at least: fid (unique id), c_fid, and geometry (polygons)
stopifnot(inherits(sf_f, "sf"))
stopifnot(all(c("fid", "c_fid") %in% names(sf_f)))

# (1) Read country polygons (keep only needed columns)
ct <- st_read(
  "/home/jeronimo/data/global_ncp/vectors/cartographic_ee_ee_r264_correspondence.gpkg",
  quiet = TRUE
) |>
  select(id, ee_r264_name, iso3, continent, income_grp, region_un, region_wb, subregion)

# (2) Read biomes (WWF biomes), keep id & label columns only
biomes <- st_read(
  "/home/jeronimo/data/global_ncp/vectors/Biome.gpkg",
  quiet = TRUE
) |>
  select(BIOME, WWF_biome)

# (3) Harmonize CRS (transform both polygon layers to match the grid CRS)
crs_grid <- st_crs(sf_f)
if (st_crs(ct) != crs_grid)     ct     <- st_transform(ct, crs_grid)
if (st_crs(biomes) != crs_grid) biomes <- st_transform(biomes, crs_grid)

# (4) Build a lightweight template from the grid (only keys you need)
sf_template <- sf_f |>
  select(fid, c_fid) # keeps geometry (grid cells)

# (5) One representative point per cell (robust for concave polygons)
#     This is much faster/safer than polygon-on-polygon joins for attribution.
pts <- st_point_on_surface(sf_template)

# (6) Spatial join attributes onto points
#     NOTE: DO NOT drop geometry on `ct`/`biomes` before this step.
#     Keep defaults: left = TRUE (keeps all pts), largest = FALSE (strict within).
#     If you want "closest polygon" behavior, use `st_join(..., join = st_nearest_feature)`
pts_ct    <- st_join(pts, ct,     left = TRUE)
pts_biome <- st_join(pts, biomes, left = TRUE)

# (7) Drop point geometry to get a pure attribute table keyed by fid
pts_ctdf <- pts_ct    |> st_drop_geometry()
pts_bmdf <- pts_biome |> st_drop_geometry()

# (8) Merge country + biome attributes (both are 1 row per fid)
#     Keep suffixes clean in case of name collisions.
out_attrs <- pts_ctdf |>
  left_join(pts_bmdf, by = "fid", suffix = c("", "_biome"))

# (Optional) sanity: ensure uniqueness by `fid`
if (any(duplicated(out_attrs$fid))) {
  # If duplicates ever appear, collapse to first occurrence
  out_attrs <- out_attrs |>
    arrange(fid) |>
    distinct(fid, .keep_all = TRUE)
}

# (9) Bring attributes back to the original grid (preserve grid geometry)
sf_f_joined <- sf_f |>
  left_join(out_attrs, by = "fid")

# (10) Quick checks
stopifnot(nrow(sf_f_joined) == nrow(sf_f))
stopifnot(inherits(sf_f_joined, "sf"))

# (11) Write result (overwrite safely)
out_path <- "~/data/global_ncp/processed/10k_change_calc.gpkg"
if (file.exists(out_path)) file.remove(out_path)
st_write(sf_f_joined, out_path, quiet = TRUE)

```

####################### START HERE

# 1 Hotspot Extraction

## 1.1 Prepare Data for Analysis

The spatial objects with the anecessary  attributes are loaded and reformatted for analysis and chart preparation, that requires to **pivot** the input vector files into the long format, with one row per service/cell combination.

```{r pivot}
#| eval: true
#| include: true
lyr_sf <- st_layers("~/data/global_ncp/processed/10k_change_calc.gpkg")
sf_f <- st_read("~/data/global_ncp/processed/10k_change_calc.gpkg") 
# Read change data (finqal summaries) Eventually herer i will need to set up the correct viariabñle names here!  
#add fid a
sf_f$fid <- seq_len(nrow(sf_f)) 
plt <- st_drop_geometry(sf_f)

# get the vars to perform analysis (all that are not "chg"). These are used or the group/subregionaal analyisis and to compare extract the SK testsby demographic/socioeocnomic variable4
socio_vars <- names(plt)[
  names(plt) != c("fid", "c_fid") & 
  !grepl("chg$", names(plt))
]

# Pivot all columns that contain pct_ch, keeping other relevant vars


# socio variables to carry through (adjust to your set) There should b a smarter /more autm,ated way to do this!
socio_vars <- c(
  "GHS_BUILT_S_E2020_mean",
  "fields_mehrabi_2017_mean",
  "hdi_raster_predictions_2020_mean",
  "rast_adm1_gini_disp_2020_mean",
  "rast_gdpTot_1990_2020_30arcsec_2020_sum",
  "GHS_POP_E2020_GLOBE_sum",
  "GlobPOP_Count_30arc_2020_sum",
  "iso3","continent","income_grp","region_un","region_wb","subregion","BIOME","WWF_biome"
)

plt_long <- plt %>%
  # 1) Long pivot on *_abs_chg / *_pct_chg columns
  pivot_longer(
    cols = matches("_(abs|pct)_chg$"),
    names_to = c("service", "chg_type"),
    names_pattern = "^(.*)_(abs|pct)_chg$",
    values_to = "chg_value"
  ) %>%
  # OPTIONAL: normalize service labels if you want to drop a trailing "_mean"
  mutate(service = str_remove(service, "_mean$")) %>%
  # 2) Go wide to get two columns: abs_chg, pct_chg
  pivot_wider(
    names_from = chg_type,
    values_from = chg_value,
    names_vary = "slowest"
  ) %>%
  # after pivot_wider we have columns "abs" and "pct" -> rename
  rename(abs_chg = abs, pct_chg = pct) %>%
  # 3) Reorder/select the columns you need
  select(
    fid, c_fid, service, abs_chg, pct_chg,
    any_of(socio_vars)
  ) %>%
  # 4) Filters (tweak as neededs)
  filter(!is.na(c_fid), !is.na(iso3), !is.na(BIOME)) %>%
  filter(!(is.infinite(pct_chg) | is.infinite(abs_chg))) %>%
  # keep rows where at least one metric exists
  filter(!is.na(pct_chg) | !is.na(abs_chg))

# this should be updated on an earlier stage when i extract the data, not here). I am not sure how to deal with this. But enterimghthe names manually isnot very prasctival, too hardcoded and limits flexibility. 

  plt_long <- plt_long %>% mutate(service = case_when(
   service == "sed_export" ~ "Sed_export",
   service == "n_export" ~ "N_export",
   service == "n_retention" ~ "N_retention",
   service == "nature_access" ~ "Nature_Access",
   service == "pollination" ~ "Pollination",
   service == "usle" ~ "USLE",
   service == "n_ret_ratio" ~ "N_Ret_Ratio",
   service == "sed_ret_ratio" ~ "Sed_Ret_Ratio",
   service == "Rt_ratio" ~ "C_Risk_Red_Ratio",
   service == "Rt" ~ "C_Risk",
   service == "Rt_service" ~ "C_Prot_service",
   TRUE ~ service
   ))
  
  

# Set service levels one single time and for all. Don't drop some variables here, filter afterwards, it can be difficult/annoying to recover!!!
service_levels <- c("Nature_Access","N_export","N_retention", "N_Ret_Ratio", "Sed_export", "USLE", "Sed_Ret_Ratio", "Rt_nohab","C_Risk","C_Prot_service", "C_Risk_Red_Ratio", "Pollination") 

```


# Wrapper: extract hotpots per group 


```{r extract hotposts_group}

# group_cols is a character vector like c("income_grp") or c("region_wb")
extract_hotspots_by <- function(df_long, group_cols,
                                loss, gain,
                                value_col = "abs_chg",
                                pct_cutoff = 0.05,
                                threshold_mode = "percent") {

  stopifnot(all(group_cols %in% names(df_long)))

  df_long %>%
    select(fid, service, all_of(group_cols), all_of(value_col), c_fid) %>%
    rename(.value = {{ value_col }}) %>%  # standardize name for mapping
    nest(data = -all_of(group_cols)) %>%
    mutate(
      res = map(
        data,
        ~ extract_hotspots(
            df            = rename(.x, !!value_col := .value),
            value_col     = value_col,
            pct_cutoff    = pct_cutoff,
            threshold_mode= threshold_mode,
            rule_mode     = "vectors",
            loss_services = loss,
            gain_services = gain,
            id_cols       = c("c_fid")      # carry c_fid to summaries
          )
      )
    ) %>%
    transmute(
      !!!syms(group_cols),
      hotspots_df     = map(res, "hotspots_df"),
      non_hotspots_df = map(res, "non_hotspots_df"),
      summary_df      = map(res, "summary_df"),
      binary_matrix   = map(res, "binary_matrix")
    )
}


```

```{r run wrapper}

loss <- c("Nature_Access","Pollination","N_Ret_Ratio","Sed_Ret_Ratio","C_Risk_Red_Ratio")
gain <- c("Sed_export","N_export","C_Risk")

# ---- Config you already used ----
focus_services <- c(
  "Nature_Access","N_export","N_retention","Sed_export",
  "N_Ret_Ratio","Sed_Ret_Ratio","C_Risk","C_Risk_Red_Ratio",
  "Pollination","USLE"
)
plot_n <- 300000L

# ---- Generic runner for a single grouping column ----
run_hotspot_plots_by <- function(group_col, out_stub) {
  message("==> Running plots by: ", group_col)

  # 1) run wrapper once for ABS and once for PCT
  by_abs <- extract_hotspots_by(plt_long, group_col, loss, gain, value_col = "abs_chg")
  by_pct <- extract_hotspots_by(plt_long, group_col, loss, gain, value_col = "pct_chg")

  # 2) tidy value tables (fid × service × group)
  
    transmute(!!group_col := .data[[group_col]],
              vals = map(hotspots_df, ~ dplyr::select(.x, fid, service, abs_chg))) %>%
    unnest(vals)

  pct_vals <- by_pct %>%
    transmute(!!group_col := .data[[group_col]],
              vals = map(hotspots_df, ~ dplyr::select(.x, fid, service, pct_chg))) %>%
    unnest(vals)

  # 3) join so each (fid, service,group) has abs &/or pct
  vals_joined <- full_join(
    abs_vals, pct_vals,
    by = c(group_col, "fid", "service")
  )

  # 4) focus services + sample for plotting speed
  vals_sample <- vals_joined %>%
    filter(service %in% focus_services) %>%
    filter(!is.na(.data[[group_col]])) %>%
    { if (nrow(.) > plot_n) slice_sample(., n = plot_n) else . } %>%
    mutate(!!group_col := as.factor(.data[[group_col]]))

  # 5a) ABS plot (mirror of your income plot)
  p_abs <- ggplot(vals_sample, aes(x = abs_chg, y = .data[[group_col]])) +
    geom_violin(trim = TRUE, scale = "width") +
    geom_boxplot(width = 0.15, outlier.alpha = 0.15) +
    coord_flip() +
    facet_wrap(~ service, scales = "free_y") +
    labs(title = paste0("Absolute change in hotspots by ", group_col),
         x = NULL, y = "Absolute change (service units)") +
    theme_minimal(base_size = 11) +
    theme(axis.text.x = element_text(size = 8, angle = 45, hjust = 1))

  # 5b) PCT plot (identical style)
  p_pct <- ggplot(vals_sample %>% tidyr::drop_na(pct_chg),
                  aes(x = pct_chg, y = .data[[group_col]])) +
    geom_violin(trim = TRUE, scale = "width") +
    geom_boxplot(width = 0.15, outlier.alpha = 0.15) +
    coord_flip() +
    facet_wrap(~ service, scales = "free_y") +
    labs(title = paste0("Percent change in hotspots by ", group_col),
         x = NULL, y = "Percent change (%)") +
    theme_minimal(base_size = 11) +
    theme(axis.text.x = element_text(size = 8, angle = 45, hjust = 1))

  # 6) save
  dir.create("/home/jeronimo/OneDrive/global_NCP/outputs/plots", recursive = TRUE, showWarnings = FALSE)
  ggsave(file.path("/home/jeronimo/OneDrive/global_NCP/outputs/plots",
                   paste0(out_stub, "_abs_change_violins.png")),
         p_abs, width = 12, height = 8, dpi = 300)
  ggsave(file.path("/home/jeronimo/OneDrive/global_NCP/outputs/plots",
                   paste0(out_stub, "_pct_change_violins.png")),
         p_pct, width = 12, height = 8, dpi = 300)

  invisible(list(abs_plot = p_abs, pct_plot = p_pct))
}

# ---- Run for each grouping ----
run_hotspot_plots_by("region_wb", "regionwb")
run_hotspot_plots_by("BIOME",     "biome")
run_hotspot_plots_by("continent", "continent")
run_hotspot_plots_by("region_un", "regionun")
run_hotspot_plots_by("income_grp", "incomegrp")

```
