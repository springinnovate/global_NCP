---
title: "Hotspot Sandbox (experiments)"
subtitle: "Lightweight playground; mirror main configs, keep chunks off by default"
author: "Jerónimo Rodríguez Escobar"
format:
  html:
    toc: true
    number-sections: true
    code-fold: true
    theme: cosmo
editor: source
---

::: callout-warning
Use `analysis/hotspot_extraction.qmd` for the **canonical** run. This sandbox is for quick experiments (tweaking cutoffs, trying a different input, prototyping plots) without touching the main report. Heavy chunks are `eval: false` by default—flip them on when you actually need them.
:::

## Setup

```{r}
#| label: setup
#| message: false
#| warning: false
#| echo: false

library(dplyr)
library(tidyr)
library(ggplot2)
library(sf)
library(here)
library(ragg)

library(devtools)
source(here::here("R","paths.R"))
knitr::opts_knit$set(root.dir = here::here())
devtools::load_all(quiet = TRUE)

options(dplyr.summarise.inform = FALSE)
set.seed(1)
```

## Config (match main analysis)

```{r}
#| label: config
#| echo: true

`%||%` <- function(x, y) if (is.null(x)) y else x

HOTS_CFG <- list(
  pct_cutoff      = 0.05,
  threshold_mode  = "percent",
  rule_mode       = "vectors",
  loss_services   = c("Nature_Access","Pollination","N_Ret_Ratio","Sed_Ret_Ratio","C_Risk_Red_Ratio"),
  gain_services   = c("Sed_export","N_export","C_Risk"),
  combos = list(
    deg_combo = c("Nature_Access","Pollination","N_export","Sed_export","C_Risk"),
    rec_combo = c("Nature_Access","Pollination","N_Ret_Ratio","Sed_Ret_Ratio","C_Risk_Red_Ratio")
  ),
  svc_order = c(
    "C_Risk","N_export","Sed_export",
    "C_Risk_Red_Ratio","N_Ret_Ratio","Sed_Ret_Ratio",
    "Pollination","Nature_Access"
  ),
  include_services = NULL  # NULL = use all in svc_order
)

# Canonical service mapping (match main report)
if (!exists("canonical_lookup", inherits = TRUE)) {
  canonical_lookup <- c(
    sed_export       = "Sed_export",
    n_export         = "N_export",
    n_retention      = "N_retention",
    nature_access    = "Nature_Access",
    pollination      = "Pollination",
    usle             = "USLE",
    n_ret_ratio      = "N_Ret_Ratio",
    sed_ret_ratio    = "Sed_Ret_Ratio",
    rt_ratio         = "C_Risk_Red_Ratio",
    rt               = "C_Risk",
    c_risk           = "C_Risk",
    c_risk_red_ratio = "C_Risk_Red_Ratio",
    rt_service       = "C_Prot_service",
    rt_nohab         = "Rt_nohab"
  )
}

# Sandbox output roots (keep experiments separate from canonical outputs)
sandbox_plot_root <- file.path("outputs", "plots", "sandbox_signed")
sandbox_tbl_root  <- file.path("outputs", "tables", "sandbox_signed")
```

## Signed bars experiments (trim vs no-trim)

Use this section to test trimming and sign-flip behavior without touching the main report. Outputs go to `outputs/plots/sandbox_signed/` and `outputs/tables/sandbox_signed/`.

```{r}
#| label: cleanup-sandbox-outputs
#| eval: false
#| message: false
#| warning: false

if (dir.exists(sandbox_plot_root)) {
  unlink(sandbox_plot_root, recursive = TRUE, force = TRUE)
}
if (dir.exists(sandbox_tbl_root)) {
  unlink(sandbox_tbl_root, recursive = TRUE, force = TRUE)
}
dir.create(sandbox_plot_root, recursive = TRUE, showWarnings = FALSE)
dir.create(sandbox_tbl_root, recursive = TRUE, showWarnings = FALSE)
```

```{r}
#| label: signed-bars-data
#| eval: false
#| message: false
#| warning: false

services  <- HOTS_CFG$svc_order
groupings <- c("income_grp","region_wb","continent","region_un","WWF_biome")
cut_q <- 0.999
handle_inf <- "na"  # options: "na", "cap"
verbose <- TRUE

vmsg <- function(...) if (isTRUE(verbose)) message(...)

gpkg <- file.path(data_dir(), "processed", "10k_change_calc.gpkg")
stopifnot(file.exists(gpkg))

vmsg("Reading: ", gpkg, " [layer: 10k_change_calc]")
sf_f <- sf::st_read(gpkg, layer = "10k_change_calc", quiet = TRUE)
sf_f <- sf::st_drop_geometry(sf_f)
if (!"fid" %in% names(sf_f)) sf_f$fid <- seq_len(nrow(sf_f))
if (!"c_fid" %in% names(sf_f)) {
  if ("c_fid.x" %in% names(sf_f)) sf_f <- dplyr::rename(sf_f, c_fid = c_fid.x)
  else if ("c_fid.y" %in% names(sf_f)) sf_f <- dplyr::rename(sf_f, c_fid = c_fid.y)
  else if ("id" %in% names(sf_f))      sf_f <- dplyr::rename(sf_f, c_fid = id)
}
sf_f <- dplyr::select(sf_f, -dplyr::any_of(c("c_fid.x","c_fid.y")))

chg_cols <- grep("_(abs|pct)_chg$", names(sf_f), value = TRUE)
services_raw   <- unique(sub("_(abs|pct)_chg$", "", chg_cols))
services_clean <- stringr::str_remove(services_raw, "_mean$")
services_lower <- tolower(services_clean)
svc_map <- tibble::tibble(
  col_base  = c(services_raw, services_clean),
  canonical = dplyr::recode(c(services_lower, services_lower),
                            !!!canonical_lookup, .default = c(services_clean, services_clean))
) |>
  dplyr::distinct() |>
  dplyr::mutate(col_pct = paste0(col_base, "_pct_chg"),
                col_abs = paste0(col_base, "_abs_chg"))

agg_by_group <- function(df, services, groupings, cut_q = 0.999,
                         handle_inf = c("na","cap"), drop_zero = FALSE) {
  handle_inf <- match.arg(handle_inf)
  groupings <- intersect(groupings, names(df))
  vmsg("Groupings available: ", paste(groupings, collapse = ", "))
  out <- list()
  for (g in groupings) {
    vmsg("  Grouping: ", g)
    for (svc in services) {
      map_rows <- dplyr::filter(svc_map, canonical == svc)
      if (!nrow(map_rows)) next
      cols_pct <- map_rows$col_pct[map_rows$col_pct %in% names(df)]
      cols_abs <- map_rows$col_abs[map_rows$col_abs %in% names(df)]
      if (!length(cols_pct) && !length(cols_abs)) next

      add_one <- function(col, metric) {
        v <- df[[col]]
        if (metric == "pct" && any(is.infinite(v))) {
          if (handle_inf == "na") v[is.infinite(v)] <- NA_real_
        }
        if (isTRUE(drop_zero)) v[v == 0] <- NA_real_
        cap <- stats::quantile(abs(v), cut_q, na.rm = TRUE)
        v_trim <- pmax(pmin(v, cap), -cap)
        tibble::tibble(
          service = svc,
          group   = df[[g]],
          metric  = metric,
          val     = v_trim
        )
      }

      rows <- list()
      if (length(cols_pct)) rows[[length(rows)+1]] <- add_one(cols_pct[1], "pct")
      if (length(cols_abs)) rows[[length(rows)+1]] <- add_one(cols_abs[1], "abs")
      rows <- dplyr::bind_rows(rows)
      if (!nrow(rows)) next
      rows <- rows |>
        dplyr::filter(!is.na(group)) |>
        dplyr::group_by(service, metric, group) |>
        dplyr::summarise(mean_chg = mean(val, na.rm = TRUE), .groups = "drop") |>
        dplyr::mutate(grouping = g)
      out[[length(out)+1]] <- rows
    }
  }
  dplyr::bind_rows(out)
}

signed_keep0 <- agg_by_group(sf_f, services, groupings, cut_q = cut_q,
                             handle_inf = handle_inf, drop_zero = FALSE)
signed_drop0 <- agg_by_group(sf_f, services, groupings, cut_q = cut_q,
                             handle_inf = handle_inf, drop_zero = TRUE)
signed_keep0_no_trim <- agg_by_group(sf_f, services, groupings, cut_q = 1,
                                     handle_inf = handle_inf, drop_zero = FALSE)
signed_drop0_no_trim <- agg_by_group(sf_f, services, groupings, cut_q = 1,
                                     handle_inf = handle_inf, drop_zero = TRUE)
```

```{r}
#| label: signed-bars-global-refs
#| eval: false
#| message: false
#| warning: false

compute_global_refs <- function(df, services, cut_q = 0.999,
                                handle_inf = c("na","cap"), drop_zero = FALSE) {
  handle_inf <- match.arg(handle_inf)
  out <- list()
  for (svc in services) {
    map_rows <- dplyr::filter(svc_map, canonical == svc)
    if (!nrow(map_rows)) next
    for (metric in c("pct","abs")) {
      cols <- if (metric == "pct") map_rows$col_pct else map_rows$col_abs
      cols <- cols[cols %in% names(df)]
      if (!length(cols)) next
      v <- df[[cols[1]]]
      if (metric == "pct" && any(is.infinite(v))) {
        if (handle_inf == "na") v[is.infinite(v)] <- NA_real_
      }
      if (isTRUE(drop_zero)) v[v == 0] <- NA_real_
      cap <- stats::quantile(abs(v), cut_q, na.rm = TRUE)
      v_trim <- pmax(pmin(v, cap), -cap)
      out[[length(out)+1]] <- tibble::tibble(
        service = svc,
        metric  = metric,
        ref     = mean(v_trim, na.rm = TRUE)
      )
    }
  }
  dplyr::bind_rows(out)
}

glob_keep0 <- compute_global_refs(sf_f, services, cut_q = cut_q,
                                  handle_inf = handle_inf, drop_zero = FALSE)
glob_drop0 <- compute_global_refs(sf_f, services, cut_q = cut_q,
                                  handle_inf = handle_inf, drop_zero = TRUE)
glob_keep0_no_trim <- compute_global_refs(sf_f, services, cut_q = 1,
                                          handle_inf = handle_inf, drop_zero = FALSE)
glob_drop0_no_trim <- compute_global_refs(sf_f, services, cut_q = 1,
                                          handle_inf = handle_inf, drop_zero = TRUE)
```

```{r}
#| label: signed-bars-plot
#| eval: false
#| message: false
#| warning: false

plot_signed_alt <- function(df, grouping, metric,
                            refs,
                            variant_label = "keep0",
                            variant_desc  = "Zeros kept",
                            out_dir = "outputs/plots/signed_alt") {
  d <- dplyr::filter(df, grouping == !!grouping, metric == !!metric)
  if (!nrow(d)) return(invisible(NULL))
  d$service <- factor(d$service, levels = services)
  d$group   <- factor(d$group, levels = sort(unique(d$group)))
  refs_use <- dplyr::filter(refs, metric == !!metric)
  refs_use$service <- factor(refs_use$service, levels = services)
  p <- ggplot(d, aes(group, mean_chg, fill = group)) +
    geom_col(show.legend = FALSE) +
    geom_hline(yintercept = 0, color = "#7f7f7f", linewidth = 0.6) +
    geom_hline(data = refs_use, aes(yintercept = ref),
               linetype = "dashed", color = "#4a4a4a", linewidth = 0.5) +
    facet_wrap(~ service, scales = "free_y", ncol = 3) +
    labs(title = paste0("Signed mean change (alt) — ", grouping, " [", metric, "]"),
         subtitle = variant_desc,
         x = grouping,
         y = if (metric == "pct") "Mean % change (trimmed, signed)" else "Mean absolute change (trimmed, signed)") +
    theme_minimal(base_size = 12) +
    theme(strip.background = element_rect(fill = "#f3f4f6", color = NA),
          strip.text = element_text(face = "bold"),
          axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))
  dir.create(out_dir, recursive = TRUE, showWarnings = FALSE)
  fp <- file.path(out_dir, paste0("bars_signed_alt_", variant_label, "_", tolower(grouping), "_", metric, ".png"))
  ggsave(fp, p, width = 12, height = 8, dpi = 300, bg = "white")
  message("Saved alt bars: ", fp)
}

for (g in unique(signed_keep0$grouping)) {
  for (m in unique(signed_keep0$metric)) {
    plot_signed_alt(signed_keep0, g, m,
                    refs = glob_keep0,
                    variant_label = "keep0",
                    variant_desc  = "Zeros kept; dashed = global mean",
                    out_dir = file.path(sandbox_plot_root, "signed_alt_keep0"))
    plot_signed_alt(signed_drop0, g, m,
                    refs = glob_drop0,
                    variant_label = "drop0",
                    variant_desc  = "Zeros dropped; dashed = global mean",
                    out_dir = file.path(sandbox_plot_root, "signed_alt_drop0"))
    plot_signed_alt(signed_keep0_no_trim, g, m,
                    refs = glob_keep0_no_trim,
                    variant_label = "keep0_notrim",
                    variant_desc  = "Zeros kept; no trim; dashed = global mean",
                    out_dir = file.path(sandbox_plot_root, "signed_alt_keep0_notrim"))
    plot_signed_alt(signed_drop0_no_trim, g, m,
                    refs = glob_drop0_no_trim,
                    variant_label = "drop0_notrim",
                    variant_desc  = "Zeros dropped; no trim; dashed = global mean",
                    out_dir = file.path(sandbox_plot_root, "signed_alt_drop0_notrim"))
  }
}
```

```{r}
#| label: inspect-sign-flips
#| eval: false

cmp <- signed_keep0 |>
  dplyr::rename(mean_keep_trim = mean_chg) |>
  dplyr::full_join(
    signed_drop0 |> dplyr::rename(mean_drop_trim = mean_chg),
    by = c("grouping","metric","service","group")
  ) |>
  dplyr::full_join(
    signed_keep0_no_trim |> dplyr::rename(mean_keep_notrim = mean_chg),
    by = c("grouping","metric","service","group")
  ) |>
  dplyr::full_join(
    signed_drop0_no_trim |> dplyr::rename(mean_drop_notrim = mean_chg),
    by = c("grouping","metric","service","group")
  ) |>
  dplyr::mutate(
    sign_keep_trim   = sign(mean_keep_trim),
    sign_drop_trim   = sign(mean_drop_trim),
    sign_keep_notrim = sign(mean_keep_notrim),
    sign_drop_notrim = sign(mean_drop_notrim),
    flipped_trim     = sign_keep_trim != sign_drop_trim &
                       !is.na(sign_keep_trim) & !is.na(sign_drop_trim),
    flipped_notrim   = sign_keep_notrim != sign_drop_notrim &
                       !is.na(sign_keep_notrim) & !is.na(sign_drop_notrim)
  )

flips_trim_only <- cmp |> dplyr::filter(flipped_trim == TRUE)
flips_no_trim_only <- cmp |> dplyr::filter(flipped_notrim == TRUE)
```

```{r}
#| label: inspect-sign-flips-examples
#| eval: false

mk_pct_abs <- function(df, suffix) {
  df |> tidyr::pivot_wider(names_from = metric, values_from = mean_chg) |>
    dplyr::mutate(flipped_pct_abs = sign(pct) != sign(abs) & !is.na(pct) & !is.na(abs)) |>
    dplyr::filter(flipped_pct_abs) |>
    dplyr::rename(mean_abs = abs, mean_pct = pct) |>
    dplyr::mutate(source = suffix)
}

flips_keep_trim    <- mk_pct_abs(signed_keep0,         "keep_trim")
flips_drop_trim    <- mk_pct_abs(signed_drop0,         "drop_trim")
flips_keep_notrim  <- mk_pct_abs(signed_keep0_no_trim, "keep_notrim")
flips_drop_notrim  <- mk_pct_abs(signed_drop0_no_trim, "drop_notrim")
```

```{r}
#| label: export-flip-tables
#| eval: false

out_tbl <- sandbox_tbl_root
dir.create(out_tbl, recursive = TRUE, showWarnings = FALSE)

saveRDS(list(flips_keep_trim, flips_drop_trim, flips_keep_notrim, flips_drop_notrim),
        file.path(out_tbl, "flips_pct_abs_all.rds"))
readr::write_csv(dplyr::bind_rows(flips_keep_trim, flips_drop_trim,
                                  flips_keep_notrim, flips_drop_notrim),
                 file.path(out_tbl, "flips_pct_abs_all.csv"))
```

## Flip diagnostics strategies

Use the blocks below to test the three diagnostic strategies for sign flips:

1. **Shared trimming mask:** force pct/abs to use the same subset of cells.
2. **Baseline inspection:** check whether T0 values are near zero or mixed sign.
3. **Aggregate‑then‑percent:** compute pct change after aggregating to group level.

```{r}
#| label: flip-shared-trim-mask
#| eval: false

# Uses the same mask for abs and pct (per service) so trimming is identical.
shared_trim_summary <- function(df, service, group_col, cut_q = 0.999) {
  d <- df |> dplyr::filter(.data$service == !!service, !is.na(.data[[group_col]]))
  if (!nrow(d)) return(tibble::tibble())

  cap_abs <- stats::quantile(abs(d$abs_chg), cut_q, na.rm = TRUE)
  cap_pct <- stats::quantile(abs(d$pct_chg), cut_q, na.rm = TRUE)
  keep <- abs(d$abs_chg) <= cap_abs & abs(d$pct_chg) <= cap_pct

  d |>
    dplyr::filter(keep) |>
    dplyr::group_by(.data[[group_col]]) |>
    dplyr::summarise(
      mean_abs = mean(abs_chg, na.rm = TRUE),
      mean_pct = mean(pct_chg, na.rm = TRUE),
      .groups = "drop"
    )
}

# Example:
# shared_trim_summary(plt_long, service = "Sed_export", group_col = "continent")
```

```{r}
#| label: flip-baseline-inspection
#| eval: false

# Inspect baseline (T0) values for services with flips.
# Requires the full QA dataset with base-year columns.
full_path <- file.path(data_dir(), "processed", "10k_grid_ES_change_benef.gpkg")
if (file.exists(full_path)) {
  full <- sf::st_read(full_path, quiet = TRUE) |> sf::st_drop_geometry()
  # Example: check 1992 baseline for a service
  # base_col <- "global_usle_marine_mod_ESA_1992_mean"
  # summary(full[[base_col]])
  # mean(full[[base_col]] == 0, na.rm = TRUE)
} else {
  message("Full QA dataset not found: ", full_path)
}
```

```{r}
#| label: flip-aggregate-then-percent
#| eval: false

# Compute pct change after aggregation (group mean first, then pct).
agg_then_pct <- function(df, col_1992, col_2020, group_col) {
  df |>
    dplyr::filter(!is.na(.data[[group_col]])) |>
    dplyr::group_by(.data[[group_col]]) |>
    dplyr::summarise(
      mean_1992 = mean(.data[[col_1992]], na.rm = TRUE),
      mean_2020 = mean(.data[[col_2020]], na.rm = TRUE),
      pct_change = dplyr::if_else(mean_1992 != 0,
                                  (mean_2020 - mean_1992) / mean_1992,
                                  NA_real_),
      .groups = "drop"
    )
}

# Example (requires base-year cols in full dataset):
# agg_then_pct(full, "global_usle_marine_mod_ESA_1992_mean",
#              "global_usle_marine_mod_ESA_2020_mean",
#              "continent")
```

## Pivot to long (heavy; off by default)

Rebuild `plt_long` from `processed/10k_change_calc.gpkg`. Turn `eval: true` only if you need a fresh pivot here; otherwise, rely on the main report cache.

```{r}
#| label: pivot
#| eval: false
#| include: false
#| echo: false
#| results: hide
#| cache: true

gpkg <- file.path(data_dir(), "processed", "10k_change_calc.gpkg")
stopifnot(file.exists(gpkg))

sf_f <- sf::st_read(gpkg, quiet = TRUE)
if (!"fid" %in% names(sf_f)) sf_f$fid <- seq_len(nrow(sf_f))
plt <- sf::st_drop_geometry(sf_f)

id_cols  <- c("fid", "c_fid")
chg_cols <- grep("_(abs|pct)_chg$", names(plt), value = TRUE)
socio_vars <- setdiff(names(plt), c(id_cols, chg_cols))

plt_long <- plt |>
  tidyr::pivot_longer(
    cols = tidyselect::all_of(chg_cols),
    names_to = c("service", "chg_type"),
    names_pattern = "^(.*)_(abs|pct)_chg$",
    values_to = "chg_value"
  ) |>
  dplyr::mutate(service = stringr::str_remove(service, "_mean$")) |>
  tidyr::pivot_wider(
    names_from  = chg_type,
    values_from = chg_value,
    names_vary  = "slowest"
  ) |>
  dplyr::rename(abs_chg = abs, pct_chg = pct) |>
  dplyr::select(fid, c_fid, service, abs_chg, pct_chg, dplyr::any_of(socio_vars)) |>
  dplyr::filter(!is.na(c_fid)) |>
  dplyr::filter(!(is.infinite(abs_chg) | is.infinite(pct_chg))) |>
  dplyr::filter(!is.na(abs_chg) | !is.na(pct_chg))

service_lookup <- c(
  sed_export     = "Sed_export",
  n_export       = "N_export",
  n_retention    = "N_retention",
  nature_access  = "Nature_Access",
  pollination    = "Pollination",
  usle           = "USLE",
  n_ret_ratio    = "N_Ret_Ratio",
  sed_ret_ratio  = "Sed_Ret_Ratio",
  Rt_ratio       = "C_Risk_Red_Ratio",
  Rt             = "C_Risk",
  Rt_service     = "C_Prot_service",
  Rt_nohab       = "Rt_nohab"
)
plt_long <- plt_long |>
  dplyr::mutate(service = dplyr::recode(service, !!!service_lookup, .default = service))

extras <- setdiff(unique(plt_long$service), HOTS_CFG$svc_order)
plt_long <- plt_long |>
  dplyr::mutate(service = factor(service, levels = c(HOTS_CFG$svc_order, sort(extras))))
```

## Hotspot extraction (off by default)

Compute hotspots/non-hotspots using the same rules as the main analysis. Turn on when testing different cutoffs or data sources.

```{r}
#| label: extract-hotspots
#| eval: false
#| message: false
#| warning: false

svc_keep <- HOTS_CFG$include_services %||% levels(plt_long$service) %||% unique(plt_long$service)
hs <- extract_hotspots(
  df            = dplyr::filter(plt_long, service %in% svc_keep),
  value_col     = "pct_chg",
  pct_cutoff    = HOTS_CFG$pct_cutoff,
  threshold_mode= HOTS_CFG$threshold_mode,
  rule_mode     = HOTS_CFG$rule_mode,
  loss_services = HOTS_CFG$loss_services,
  gain_services = HOTS_CFG$gain_services,
  combos        = HOTS_CFG$combos,
  id_cols       = c("c_fid")
)

hotspots_df <- hs$hotspots_df
inverse_df  <- hs$non_hotspots_df
```

## Optional: hotspot vs non-hotspot scatters

Quick scatter/ECDF prototypes without touching the main report. Pick one variable, cap points for speed, and facet by top services.

```{r}
#| label: scatter-hot-vs-non
#| eval: false
#| message: false
#| warning: false

stopifnot(exists("hotspots_df"), exists("inverse_df"))

var_id <- "GHS_POP_E2020_GLOBE_sum"
top_k  <- 6
max_n  <- 20000  # cap rows per group for plotting speed

base <- dplyr::bind_rows(
  dplyr::mutate(hotspots_df, group = "hotspot"),
  dplyr::mutate(inverse_df,  group = "nonhotspot")
) |>
  dplyr::select(service, group, val = .data[[var_id]]) |>
  dplyr::filter(is.finite(val))

# pick top-K services by KS D for this var
find_D <- function(d) {
  x <- d$val[d$group=="hotspot"]; y <- d$val[d$group=="nonhotspot"]
  if (length(x) < 2 || length(y) < 2) return(NA_real_)
  suppressWarnings(as.numeric(stats::ks.test(x, y, exact = FALSE)$statistic))
}
top_services <- base |>
  dplyr::group_by(service) |>
  dplyr::summarise(D = find_D(dplyr::cur_data_all()), .groups = "drop") |>
  dplyr::arrange(dplyr::desc(D)) |>
  dplyr::slice_head(n = top_k) |>
  dplyr::pull(service)

dd <- dplyr::filter(base, service %in% top_services)
if (nrow(dd) > max_n) dd <- dd[sample.int(nrow(dd), max_n), , drop = FALSE]

ggplot(dd, aes(x = val, y = group, color = group)) +
  ggrepel::geom_jitter(height = 0.1, alpha = 0.2, size = 0.6, show.legend = FALSE) +
  facet_wrap(~ service, scales = "free_x") +
  scale_color_manual(values = c(nonhotspot = "#2D708E", hotspot = "#D43D51")) +
  labs(
    title = paste("Hotspot vs non-hotspot:", var_id),
    x = var_id, y = NULL
  ) +
  theme_minimal(base_size = 11)
```

Add any other experimental chunks below; keep paths/configs aligned with the main analysis.
